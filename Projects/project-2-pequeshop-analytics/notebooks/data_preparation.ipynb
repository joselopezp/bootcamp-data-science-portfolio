{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PequeShop: Data Preparation Pipeline\n",
    "\n",
    "## End-to-End Data Science Project with Business Focus\n",
    "\n",
    "**Methodology:** CRISP-DM + Lean Thinking  \n",
    "**Data Pipeline:** ETL (Extract, Transform, Load)  \n",
    "**Focus:** Applied Data Science for E-commerce Analytics\n",
    "\n",
    "**Author:** Jose Marcel Lopez Pino  \n",
    "**Date:** February 2026  \n",
    "**Bootcamp:** Fundamentos de Ciencia de Datos - SENCE/Alkemy\n",
    "\n",
    "---\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "**PequeShop** is a Chilean e-commerce specializing in children's clothing and accessories (ages 4-10). The company started on MercadoLibre (2023), migrated to Shopify (2024), and now promotes through Facebook/Instagram Ads.\n",
    "\n",
    "**Challenge:** Data is fragmented across multiple platforms with inconsistent formats, missing values, and outliers that prevent unified analytics.\n",
    "\n",
    "**Business Decision Enabled:** Clean, consolidated data enables Customer Lifetime Value (CLTV) analysis, Customer Acquisition Cost (CAC) optimization, Net Promoter Score (NPS) segmentation, and marketing attribution modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### Methodology: CRISP-DM + Lean Thinking\n",
    "\n",
    "This project follows **CRISP-DM** for structured data science work, combined with **Lean principles** for iterative validation and value generation over excessive complexity.\n",
    "\n",
    "**Lean principles applied:**\n",
    "- **Eliminate waste:** Early identification of `customer_id` mapping ensured data traceability across platforms, avoiding rework in later phases.\n",
    "- **Build-Measure-Learn:** NPS integration was discovered during exploratory analysis and incorporated iteratively, enhancing customer segmentation without delaying the pipeline.\n",
    "- **Value focus:** Every transformation decision (outlier treatment, feature engineering) was evaluated against business impact, not just technical correctness.\n",
    "\n",
    "---\n",
    "\n",
    "### Project Scope: CRISP-DM + Lean\n",
    "\n",
    "This project covers phases 1-3 of CRISP-DM, applying Lean principles throughout:\n",
    "\n",
    "| CRISP-DM Phase | Lean Principle Applied | ETL Stage | Lessons |\n",
    "|----------------|------------------------|-----------|---------|\n",
    "| ‚úÖ Business Understanding | Value focus | - | Problem definition, KPIs |\n",
    "| ‚úÖ Data Understanding | Eliminate waste | **Extract** | L1-L3: Early `customer_id` mapping |\n",
    "| ‚úÖ Data Preparation | Build-Measure-Learn | **Transform** | L4-L5: NPS discovered & integrated iteratively |\n",
    "| ‚úÖ Data Preparation | Continuous improvement | **Load** | L6: Aggregation, KPIs, export |\n",
    "| ‚è≥ Modeling | - | - | *Future: ML models* |\n",
    "| ‚è≥ Evaluation | - | - | *Future: Business impact* |\n",
    "| ‚è≥ Deployment | - | - | *Future: Dashboard/API* |\n",
    "\n",
    "**Note:** ETL (Extract ‚Üí Transform ‚Üí Load) is the data pipeline pattern used to implement the CRISP-DM phases.\n",
    "\n",
    "---\n",
    "\n",
    "### ETL Pipeline Overview\n",
    "\n",
    "```\n",
    "EXTRACT                      TRANSFORM                       LOAD\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "üìÑ CSV (MercadoLibre)   ‚Üí   üîß Schema harmonization    ‚Üí   üíæ CSV\n",
    "üìä Excel (Shopify)      ‚Üí   üö´ Missing value imputation ‚Üí   üìä Excel\n",
    "üåê Web (Marketing)      ‚Üí   üìä Outlier detection (IQR/Z) \n",
    "                        ‚Üí   ‚ú® Feature engineering\n",
    "                        ‚Üí   üîÑ Data wrangling\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "| Source | Format | Description | ETL Phase |\n",
    "|--------|--------|-------------|----------|\n",
    "| MercadoLibre | CSV | Historical transactions (2023-2024) | Extract |\n",
    "| Shopify | Excel | Current platform sales (2024-2025) | Extract |\n",
    "| Marketing | Web Table | Facebook/Instagram campaign metrics | Extract |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1: NumPy - Synthetic Data Generation\n",
    "\n",
    "**Objective:** Create a fictional dataset of customers and transactions using NumPy arrays, applying basic operations for initial data preparation.\n",
    "\n",
    "### Why NumPy?\n",
    "\n",
    "NumPy is efficient for numerical data handling because:\n",
    "\n",
    "1. **Memory efficiency:** Arrays store elements of the same type contiguously in memory\n",
    "2. **Vectorized operations:** Operations are applied to entire arrays without explicit loops\n",
    "3. **Broadcasting:** Automatic handling of arrays with different shapes\n",
    "4. **C-level performance:** Core operations are implemented in C/Fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define Business Parameters\n",
    "\n",
    "Based on PequeShop's business model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business parameters defined successfully.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BUSINESS PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "# Dataset size\n",
    "N_CUSTOMERS = 500\n",
    "N_TRANSACTIONS = 2000\n",
    "\n",
    "# Product categories and price ranges (CLP)\n",
    "PRODUCTS = {\n",
    "    'socks': {'min_price': 2990, 'max_price': 5990},\n",
    "    'towels': {'min_price': 7990, 'max_price': 15990},\n",
    "    'tshirts': {'min_price': 8990, 'max_price': 14990},\n",
    "    'shorts': {'min_price': 9990, 'max_price': 16990},\n",
    "    'jackets': {'min_price': 19990, 'max_price': 34990},\n",
    "    'pajamas': {'min_price': 14990, 'max_price': 24990}\n",
    "}\n",
    "\n",
    "# Sales platforms\n",
    "PLATFORMS = ['mercadolibre', 'shopify']\n",
    "\n",
    "# Acquisition channels\n",
    "CHANNELS = ['organic', 'mercadolibre_ads', 'google_ads', 'facebook_ads', 'instagram_ads']\n",
    "\n",
    "# Platform fees\n",
    "MERCADOLIBRE_FEE = 0.13  # 13% commission\n",
    "SHOPIFY_PAYMENT_FEE = 0.03  # 3% payment gateway\n",
    "\n",
    "# Shipping costs (CLP)\n",
    "SHIPPING_STANDARD = 3500\n",
    "SHIPPING_EXPRESS = 5500\n",
    "FREE_SHIPPING_THRESHOLD = 30000\n",
    "\n",
    "# Chilean regions for customers\n",
    "REGIONS = [\n",
    "    'Metropolitana', 'Valparaiso', 'Biobio', 'Araucania', \n",
    "    'Maule', 'OHiggins', 'Los Lagos', 'Coquimbo'\n",
    "]\n",
    "\n",
    "print(\"Business parameters defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Generate Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 customers\n",
      "Registration days - Min: 1, Max: 730, Mean: 276.5\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CUSTOMER DATA GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "# Customer IDs\n",
    "customer_ids = np.arange(1, N_CUSTOMERS + 1)\n",
    "\n",
    "# Registration dates (days since 2023-01-01)\n",
    "# Earlier customers more likely to be from MercadoLibre era\n",
    "registration_days = np.random.exponential(scale=300, size=N_CUSTOMERS).astype(int)\n",
    "registration_days = np.clip(registration_days, 0, 730)  # Max 2 years\n",
    "\n",
    "# Customer regions (weighted towards major regions)\n",
    "region_weights = np.array([0.40, 0.15, 0.12, 0.08, 0.07, 0.06, 0.07, 0.05])\n",
    "customer_regions = np.random.choice(len(REGIONS), size=N_CUSTOMERS, p=region_weights)\n",
    "\n",
    "# Acquisition channel (depends on registration date)\n",
    "# Older customers more likely from MercadoLibre, newer from social media\n",
    "def assign_channel(reg_day):\n",
    "    \"\"\"Assign acquisition channel based on registration date.\"\"\"\n",
    "    if reg_day < 180:  # First 6 months - MercadoLibre era\n",
    "        weights = [0.20, 0.50, 0.15, 0.10, 0.05]\n",
    "    elif reg_day < 365:  # Transition period\n",
    "        weights = [0.15, 0.25, 0.25, 0.20, 0.15]\n",
    "    else:  # Shopify era\n",
    "        weights = [0.10, 0.10, 0.25, 0.30, 0.25]\n",
    "    return np.random.choice(len(CHANNELS), p=weights)\n",
    "\n",
    "# Vectorized channel assignment\n",
    "customer_channels = np.array([assign_channel(d) for d in registration_days])\n",
    "\n",
    "# Customer lifetime value score (0-100, calculated later based on transactions)\n",
    "initial_cltv_score = np.zeros(N_CUSTOMERS)\n",
    "\n",
    "print(f\"Generated {N_CUSTOMERS} customers\")\n",
    "print(f\"Registration days - Min: {registration_days.min()}, Max: {registration_days.max()}, Mean: {registration_days.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Generate Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2000 transactions\n",
      "\n",
      "Transaction totals (CLP):\n",
      "  Min: $6,501\n",
      "  Max: $133,084\n",
      "  Mean: $32,893\n",
      "  Total revenue: $65,786,736\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRANSACTION DATA GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "# Transaction IDs\n",
    "transaction_ids = np.arange(1, N_TRANSACTIONS + 1)\n",
    "\n",
    "# Assign customers to transactions (some customers buy more than others)\n",
    "# Pareto principle: 20% of customers generate 80% of transactions\n",
    "top_customers = customer_ids[:int(N_CUSTOMERS * 0.2)]\n",
    "regular_customers = customer_ids[int(N_CUSTOMERS * 0.2):]\n",
    "\n",
    "n_top_transactions = int(N_TRANSACTIONS * 0.6)\n",
    "n_regular_transactions = N_TRANSACTIONS - n_top_transactions\n",
    "\n",
    "transaction_customers = np.concatenate([\n",
    "    np.random.choice(top_customers, size=n_top_transactions),\n",
    "    np.random.choice(regular_customers, size=n_regular_transactions)\n",
    "])\n",
    "np.random.shuffle(transaction_customers)\n",
    "\n",
    "# Transaction dates (days since 2023-01-01)\n",
    "transaction_days = np.random.randint(0, 730, size=N_TRANSACTIONS)\n",
    "\n",
    "# Platform assignment (earlier transactions more likely MercadoLibre)\n",
    "platform_probabilities = np.where(transaction_days < 365, 0.7, 0.2)  # 70% ML before day 365\n",
    "transaction_platforms = np.where(\n",
    "    np.random.random(N_TRANSACTIONS) < platform_probabilities,\n",
    "    0,  # mercadolibre\n",
    "    1   # shopify\n",
    ")\n",
    "\n",
    "# Product selection\n",
    "product_names = list(PRODUCTS.keys())\n",
    "transaction_products = np.random.choice(len(product_names), size=N_TRANSACTIONS)\n",
    "\n",
    "# Quantity per transaction (1-4 items)\n",
    "transaction_quantities = np.random.choice([1, 1, 1, 2, 2, 3, 4], size=N_TRANSACTIONS)\n",
    "\n",
    "# Unit prices based on product\n",
    "def get_unit_price(product_idx):\n",
    "    \"\"\"Generate random price within product range.\"\"\"\n",
    "    product = product_names[product_idx]\n",
    "    min_p = PRODUCTS[product]['min_price']\n",
    "    max_p = PRODUCTS[product]['max_price']\n",
    "    return np.random.randint(min_p, max_p + 1)\n",
    "\n",
    "transaction_unit_prices = np.array([get_unit_price(p) for p in transaction_products])\n",
    "\n",
    "# Calculate subtotals\n",
    "transaction_subtotals = transaction_unit_prices * transaction_quantities\n",
    "\n",
    "# Shipping costs\n",
    "shipping_type = np.random.choice([0, 1], size=N_TRANSACTIONS, p=[0.7, 0.3])  # 70% standard\n",
    "base_shipping = np.where(shipping_type == 0, SHIPPING_STANDARD, SHIPPING_EXPRESS)\n",
    "transaction_shipping = np.where(transaction_subtotals >= FREE_SHIPPING_THRESHOLD, 0, base_shipping)\n",
    "\n",
    "# Platform fees\n",
    "transaction_fees = np.where(\n",
    "    transaction_platforms == 0,\n",
    "    transaction_subtotals * MERCADOLIBRE_FEE,\n",
    "    transaction_subtotals * SHOPIFY_PAYMENT_FEE\n",
    ")\n",
    "\n",
    "# Total amount (customer pays)\n",
    "transaction_totals = transaction_subtotals + transaction_shipping\n",
    "\n",
    "# Net revenue (after fees)\n",
    "transaction_net_revenue = transaction_subtotals - transaction_fees\n",
    "\n",
    "print(f\"Generated {N_TRANSACTIONS} transactions\")\n",
    "print(f\"\\nTransaction totals (CLP):\")\n",
    "print(f\"  Min: ${transaction_totals.min():,.0f}\")\n",
    "print(f\"  Max: ${transaction_totals.max():,.0f}\")\n",
    "print(f\"  Mean: ${transaction_totals.mean():,.0f}\")\n",
    "print(f\"  Total revenue: ${transaction_totals.sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Basic NumPy Operations and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUSINESS METRICS USING NUMPY OPERATIONS\n",
      "============================================================\n",
      "\n",
      "1. AGGREGATE METRICS\n",
      "   Total transactions: 2,000\n",
      "   Total revenue: $65,786,736 CLP\n",
      "   Total fees paid: $4,499,933 CLP\n",
      "   Net revenue: $56,207,303 CLP\n",
      "\n",
      "2. AVERAGE METRICS\n",
      "   Average ticket: $32,893 CLP\n",
      "   Average items per transaction: 2.00\n",
      "   Average unit price: $15,155 CLP\n",
      "\n",
      "3. PLATFORM COMPARISON\n",
      "   MercadoLibre:\n",
      "     - Transactions: 892\n",
      "     - Revenue: $29,104,160 CLP\n",
      "     - Avg ticket: $32,628 CLP\n",
      "   Shopify:\n",
      "     - Transactions: 1,108\n",
      "     - Revenue: $36,682,576 CLP\n",
      "     - Avg ticket: $33,107 CLP\n",
      "\n",
      "4. VARIABILITY METRICS\n",
      "   Std deviation (ticket): $21,743 CLP\n",
      "   Variance (ticket): $472,749,447 CLP¬≤\n",
      "   Range: $126,583 CLP\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BASIC NUMPY OPERATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BUSINESS METRICS USING NUMPY OPERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Total metrics\n",
    "print(f\"\\n1. AGGREGATE METRICS\")\n",
    "print(f\"   Total transactions: {len(transaction_ids):,}\")\n",
    "print(f\"   Total revenue: ${np.sum(transaction_totals):,.0f} CLP\")\n",
    "print(f\"   Total fees paid: ${np.sum(transaction_fees):,.0f} CLP\")\n",
    "print(f\"   Net revenue: ${np.sum(transaction_net_revenue):,.0f} CLP\")\n",
    "\n",
    "# Average metrics\n",
    "print(f\"\\n2. AVERAGE METRICS\")\n",
    "print(f\"   Average ticket: ${np.mean(transaction_totals):,.0f} CLP\")\n",
    "print(f\"   Average items per transaction: {np.mean(transaction_quantities):.2f}\")\n",
    "print(f\"   Average unit price: ${np.mean(transaction_unit_prices):,.0f} CLP\")\n",
    "\n",
    "# Platform comparison\n",
    "print(f\"\\n3. PLATFORM COMPARISON\")\n",
    "ml_mask = transaction_platforms == 0\n",
    "shopify_mask = transaction_platforms == 1\n",
    "\n",
    "print(f\"   MercadoLibre:\")\n",
    "print(f\"     - Transactions: {np.sum(ml_mask):,}\")\n",
    "print(f\"     - Revenue: ${np.sum(transaction_totals[ml_mask]):,.0f} CLP\")\n",
    "print(f\"     - Avg ticket: ${np.mean(transaction_totals[ml_mask]):,.0f} CLP\")\n",
    "\n",
    "print(f\"   Shopify:\")\n",
    "print(f\"     - Transactions: {np.sum(shopify_mask):,}\")\n",
    "print(f\"     - Revenue: ${np.sum(transaction_totals[shopify_mask]):,.0f} CLP\")\n",
    "print(f\"     - Avg ticket: ${np.mean(transaction_totals[shopify_mask]):,.0f} CLP\")\n",
    "\n",
    "# Variability metrics\n",
    "print(f\"\\n4. VARIABILITY METRICS\")\n",
    "print(f\"   Std deviation (ticket): ${np.std(transaction_totals):,.0f} CLP\")\n",
    "print(f\"   Variance (ticket): ${np.var(transaction_totals):,.0f} CLP¬≤\")\n",
    "print(f\"   Range: ${np.ptp(transaction_totals):,.0f} CLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. PRODUCT ANALYSIS\n",
      "--------------------------------------------------\n",
      "   SOCKS:\n",
      "     - Units sold: 324\n",
      "     - Revenue: $4,196,849 CLP\n",
      "     - Avg unit price: $4,537 CLP\n",
      "\n",
      "   TOWELS:\n",
      "     - Units sold: 318\n",
      "     - Revenue: $8,562,869 CLP\n",
      "     - Avg unit price: $12,055 CLP\n",
      "\n",
      "   TSHIRTS:\n",
      "     - Units sold: 341\n",
      "     - Revenue: $9,405,544 CLP\n",
      "     - Avg unit price: $12,028 CLP\n",
      "\n",
      "   SHORTS:\n",
      "     - Units sold: 338\n",
      "     - Revenue: $9,973,561 CLP\n",
      "     - Avg unit price: $13,476 CLP\n",
      "\n",
      "   JACKETS:\n",
      "     - Units sold: 377\n",
      "     - Revenue: $21,116,140 CLP\n",
      "     - Avg unit price: $27,421 CLP\n",
      "\n",
      "   PAJAMAS:\n",
      "     - Units sold: 302\n",
      "     - Revenue: $12,531,773 CLP\n",
      "     - Avg unit price: $19,910 CLP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRODUCT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n5. PRODUCT ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for idx, product in enumerate(product_names):\n",
    "    mask = transaction_products == idx\n",
    "    count = np.sum(mask)\n",
    "    revenue = np.sum(transaction_totals[mask])\n",
    "    avg_price = np.mean(transaction_unit_prices[mask])\n",
    "    \n",
    "    print(f\"   {product.upper()}:\")\n",
    "    print(f\"     - Units sold: {count:,}\")\n",
    "    print(f\"     - Revenue: ${revenue:,.0f} CLP\")\n",
    "    print(f\"     - Avg unit price: ${avg_price:,.0f} CLP\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Save Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ../data/raw/\n",
      "\n",
      "Files created:\n",
      "  - Customer arrays: 4 files\n",
      "  - Transaction arrays: 11 files\n",
      "  - Reference mappings: 4 files\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE DATA FOR NEXT LESSON\n",
    "# =============================================================================\n",
    "\n",
    "# Save as .npy files (NumPy native format)\n",
    "data_path = '../data/raw/'\n",
    "\n",
    "# Customer arrays\n",
    "np.save(f'{data_path}customer_ids.npy', customer_ids)\n",
    "np.save(f'{data_path}customer_registration_days.npy', registration_days)\n",
    "np.save(f'{data_path}customer_regions.npy', customer_regions)\n",
    "np.save(f'{data_path}customer_channels.npy', customer_channels)\n",
    "\n",
    "# Transaction arrays\n",
    "np.save(f'{data_path}transaction_ids.npy', transaction_ids)\n",
    "np.save(f'{data_path}transaction_customers.npy', transaction_customers)\n",
    "np.save(f'{data_path}transaction_days.npy', transaction_days)\n",
    "np.save(f'{data_path}transaction_platforms.npy', transaction_platforms)\n",
    "np.save(f'{data_path}transaction_products.npy', transaction_products)\n",
    "np.save(f'{data_path}transaction_quantities.npy', transaction_quantities)\n",
    "np.save(f'{data_path}transaction_unit_prices.npy', transaction_unit_prices)\n",
    "np.save(f'{data_path}transaction_subtotals.npy', transaction_subtotals)\n",
    "np.save(f'{data_path}transaction_shipping.npy', transaction_shipping)\n",
    "np.save(f'{data_path}transaction_fees.npy', transaction_fees)\n",
    "np.save(f'{data_path}transaction_totals.npy', transaction_totals)\n",
    "\n",
    "# Save reference mappings as .npy with allow_pickle\n",
    "np.save(f'{data_path}ref_regions.npy', np.array(REGIONS))\n",
    "np.save(f'{data_path}ref_channels.npy', np.array(CHANNELS))\n",
    "np.save(f'{data_path}ref_platforms.npy', np.array(PLATFORMS))\n",
    "np.save(f'{data_path}ref_products.npy', np.array(product_names))\n",
    "\n",
    "print(\"Data saved successfully to ../data/raw/\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - Customer arrays: 4 files\")\n",
    "print(f\"  - Transaction arrays: 11 files\")\n",
    "print(f\"  - Reference mappings: 4 files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Lesson 1 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ Created synthetic customer data (500 customers) with realistic attributes\n",
    "2. ‚úÖ Generated transaction data (2,000 transactions) following business rules\n",
    "3. ‚úÖ Applied NumPy operations: sum, mean, std, variance, conditional selection\n",
    "4. ‚úÖ Saved arrays in .npy format for use in Lesson 2\n",
    "\n",
    "**Why NumPy is efficient:**\n",
    "\n",
    "- **Contiguous memory:** All elements stored together, faster access\n",
    "- **Vectorization:** `transaction_subtotals = transaction_unit_prices * transaction_quantities` processes 2,000 multiplications in one line without loops\n",
    "- **Broadcasting:** Automatic element-wise operations between arrays of different shapes\n",
    "- **C-level speed:** Core operations 10-100x faster than Python loops\n",
    "\n",
    "**Next step:** Lesson 2 - Convert these arrays to Pandas DataFrames for exploration and transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 2: Pandas - Data Exploration and Transformation\n",
    "\n",
    "**Objective:** Load the NumPy arrays generated in Lesson 1, convert them to Pandas DataFrames, and perform initial exploration.\n",
    "\n",
    "### Why Pandas?\n",
    "\n",
    "While NumPy excels at numerical computations, Pandas provides:\n",
    "\n",
    "1. **Labeled data:** Rows and columns have meaningful names\n",
    "2. **Mixed data types:** Each column can have a different type\n",
    "3. **Built-in data cleaning:** Methods for handling missing values, duplicates, etc.\n",
    "4. **Powerful grouping:** Easy aggregation and pivot operations\n",
    "5. **Time series support:** Native datetime handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "  - Customers: 500\n",
      "  - Transactions: 2000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA FROM LESSON 1\n",
    "# =============================================================================\n",
    "\n",
    "data_path = '../data/raw/'\n",
    "\n",
    "# Load reference mappings\n",
    "REGIONS = np.load(f'{data_path}ref_regions.npy', allow_pickle=True)\n",
    "CHANNELS = np.load(f'{data_path}ref_channels.npy', allow_pickle=True)\n",
    "PLATFORMS = np.load(f'{data_path}ref_platforms.npy', allow_pickle=True)\n",
    "PRODUCTS = np.load(f'{data_path}ref_products.npy', allow_pickle=True)\n",
    "\n",
    "# Load customer arrays\n",
    "customer_ids = np.load(f'{data_path}customer_ids.npy')\n",
    "customer_registration_days = np.load(f'{data_path}customer_registration_days.npy')\n",
    "customer_regions = np.load(f'{data_path}customer_regions.npy')\n",
    "customer_channels = np.load(f'{data_path}customer_channels.npy')\n",
    "\n",
    "# Load transaction arrays\n",
    "transaction_ids = np.load(f'{data_path}transaction_ids.npy')\n",
    "transaction_customers = np.load(f'{data_path}transaction_customers.npy')\n",
    "transaction_days = np.load(f'{data_path}transaction_days.npy')\n",
    "transaction_platforms = np.load(f'{data_path}transaction_platforms.npy')\n",
    "transaction_products = np.load(f'{data_path}transaction_products.npy')\n",
    "transaction_quantities = np.load(f'{data_path}transaction_quantities.npy')\n",
    "transaction_unit_prices = np.load(f'{data_path}transaction_unit_prices.npy')\n",
    "transaction_subtotals = np.load(f'{data_path}transaction_subtotals.npy')\n",
    "transaction_shipping = np.load(f'{data_path}transaction_shipping.npy')\n",
    "transaction_fees = np.load(f'{data_path}transaction_fees.npy')\n",
    "transaction_totals = np.load(f'{data_path}transaction_totals.npy')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"  - Customers: {len(customer_ids)}\")\n",
    "print(f\"  - Transactions: {len(transaction_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers DataFrame created\n",
      "Shape: (500, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>region</th>\n",
       "      <th>acquisition_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>Araucania</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>facebook_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>instagram_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>Maule</td>\n",
       "      <td>facebook_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>Araucania</td>\n",
       "      <td>google_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>mercadolibre_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>Los Lagos</td>\n",
       "      <td>mercadolibre_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>OHiggins</td>\n",
       "      <td>instagram_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>Los Lagos</td>\n",
       "      <td>mercadolibre_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>Araucania</td>\n",
       "      <td>facebook_ads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id registration_date         region acquisition_channel\n",
       "0            1        2023-05-21      Araucania             organic\n",
       "1            2        2024-12-31     Valparaiso        facebook_ads\n",
       "2            3        2024-01-31  Metropolitana       instagram_ads\n",
       "3            4        2023-10-01          Maule        facebook_ads\n",
       "4            5        2023-02-20      Araucania          google_ads\n",
       "5            6        2023-02-20  Metropolitana    mercadolibre_ads\n",
       "6            7        2023-01-18      Los Lagos    mercadolibre_ads\n",
       "7            8        2024-08-26       OHiggins       instagram_ads\n",
       "8            9        2023-10-03      Los Lagos    mercadolibre_ads\n",
       "9           10        2024-01-05      Araucania        facebook_ads"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE CUSTOMERS DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "# Base date for converting days to actual dates\n",
    "BASE_DATE = datetime(2023, 1, 1)\n",
    "\n",
    "# Create customers DataFrame\n",
    "df_customers = pd.DataFrame({\n",
    "    'customer_id': customer_ids,\n",
    "    'registration_date': [BASE_DATE + timedelta(days=int(d)) for d in customer_registration_days],\n",
    "    'region': [REGIONS[i] for i in customer_regions],\n",
    "    'acquisition_channel': [CHANNELS[i] for i in customer_channels]\n",
    "})\n",
    "\n",
    "print(\"Customers DataFrame created\")\n",
    "print(f\"Shape: {df_customers.shape}\")\n",
    "df_customers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions DataFrame created\n",
      "Shape: (2000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>shopify</td>\n",
       "      <td>shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>11870</td>\n",
       "      <td>35610</td>\n",
       "      <td>0</td>\n",
       "      <td>1068.30</td>\n",
       "      <td>35610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3172</td>\n",
       "      <td>3172</td>\n",
       "      <td>5500</td>\n",
       "      <td>412.36</td>\n",
       "      <td>8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>2</td>\n",
       "      <td>21834</td>\n",
       "      <td>43668</td>\n",
       "      <td>0</td>\n",
       "      <td>1310.04</td>\n",
       "      <td>43668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>2</td>\n",
       "      <td>31559</td>\n",
       "      <td>63118</td>\n",
       "      <td>0</td>\n",
       "      <td>1893.54</td>\n",
       "      <td>63118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>3061</td>\n",
       "      <td>3500</td>\n",
       "      <td>397.93</td>\n",
       "      <td>6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>shopify</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>5756</td>\n",
       "      <td>5756</td>\n",
       "      <td>3500</td>\n",
       "      <td>172.68</td>\n",
       "      <td>9256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>shopify</td>\n",
       "      <td>tshirts</td>\n",
       "      <td>1</td>\n",
       "      <td>10666</td>\n",
       "      <td>10666</td>\n",
       "      <td>3500</td>\n",
       "      <td>319.98</td>\n",
       "      <td>14166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>3</td>\n",
       "      <td>29477</td>\n",
       "      <td>88431</td>\n",
       "      <td>0</td>\n",
       "      <td>2652.93</td>\n",
       "      <td>88431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>333</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>16859</td>\n",
       "      <td>50577</td>\n",
       "      <td>0</td>\n",
       "      <td>6575.01</td>\n",
       "      <td>50577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>shopify</td>\n",
       "      <td>pajamas</td>\n",
       "      <td>2</td>\n",
       "      <td>22625</td>\n",
       "      <td>45250</td>\n",
       "      <td>0</td>\n",
       "      <td>1357.50</td>\n",
       "      <td>45250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  customer_id transaction_date      platform  product  \\\n",
       "0               1          364       2023-01-29       shopify   shorts   \n",
       "1               2           53       2023-04-22  mercadolibre    socks   \n",
       "2               3           19       2024-11-03       shopify  jackets   \n",
       "3               4          227       2023-05-11       shopify  jackets   \n",
       "4               5           24       2023-07-07  mercadolibre    socks   \n",
       "5               6           51       2024-11-05       shopify    socks   \n",
       "6               7           67       2024-12-09       shopify  tshirts   \n",
       "7               8           96       2024-04-19       shopify  jackets   \n",
       "8               9          333       2023-12-30  mercadolibre   shorts   \n",
       "9              10           10       2023-07-23       shopify  pajamas   \n",
       "\n",
       "   quantity  unit_price  subtotal  shipping_cost  platform_fee  total_amount  \n",
       "0         3       11870     35610              0       1068.30         35610  \n",
       "1         1        3172      3172           5500        412.36          8672  \n",
       "2         2       21834     43668              0       1310.04         43668  \n",
       "3         2       31559     63118              0       1893.54         63118  \n",
       "4         1        3061      3061           3500        397.93          6561  \n",
       "5         1        5756      5756           3500        172.68          9256  \n",
       "6         1       10666     10666           3500        319.98         14166  \n",
       "7         3       29477     88431              0       2652.93         88431  \n",
       "8         3       16859     50577              0       6575.01         50577  \n",
       "9         2       22625     45250              0       1357.50         45250  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE TRANSACTIONS DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "df_transactions = pd.DataFrame({\n",
    "    'transaction_id': transaction_ids,\n",
    "    'customer_id': transaction_customers,\n",
    "    'transaction_date': [BASE_DATE + timedelta(days=int(d)) for d in transaction_days],\n",
    "    'platform': [PLATFORMS[i] for i in transaction_platforms],\n",
    "    'product': [PRODUCTS[i] for i in transaction_products],\n",
    "    'quantity': transaction_quantities,\n",
    "    'unit_price': transaction_unit_prices,\n",
    "    'subtotal': transaction_subtotals,\n",
    "    'shipping_cost': transaction_shipping,\n",
    "    'platform_fee': transaction_fees,\n",
    "    'total_amount': transaction_totals\n",
    "})\n",
    "\n",
    "print(\"Transactions DataFrame created\")\n",
    "print(f\"Shape: {df_transactions.shape}\")\n",
    "df_transactions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Initial Exploration - First and Last Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUSTOMERS DATAFRAME EXPLORATION\n",
      "============================================================\n",
      "\n",
      "--- First 5 rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>region</th>\n",
       "      <th>acquisition_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>Araucania</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>facebook_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>instagram_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>Maule</td>\n",
       "      <td>facebook_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>Araucania</td>\n",
       "      <td>google_ads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id registration_date         region acquisition_channel\n",
       "0            1        2023-05-21      Araucania             organic\n",
       "1            2        2024-12-31     Valparaiso        facebook_ads\n",
       "2            3        2024-01-31  Metropolitana       instagram_ads\n",
       "3            4        2023-10-01          Maule        facebook_ads\n",
       "4            5        2023-02-20      Araucania          google_ads"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Last 5 rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>region</th>\n",
       "      <th>acquisition_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>mercadolibre_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>Los Lagos</td>\n",
       "      <td>google_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>mercadolibre_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Coquimbo</td>\n",
       "      <td>google_ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>instagram_ads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id registration_date         region acquisition_channel\n",
       "495          496        2023-05-11  Metropolitana    mercadolibre_ads\n",
       "496          497        2023-09-20      Los Lagos          google_ads\n",
       "497          498        2023-01-25  Metropolitana    mercadolibre_ads\n",
       "498          499        2024-12-31       Coquimbo          google_ads\n",
       "499          500        2024-12-31     Valparaiso       instagram_ads"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   customer_id          500 non-null    int64         \n",
      " 1   registration_date    500 non-null    datetime64[us]\n",
      " 2   region               500 non-null    str           \n",
      " 3   acquisition_channel  500 non-null    str           \n",
      "dtypes: datetime64[us](1), int64(1), str(2)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXPLORE CUSTOMERS DATAFRAME\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOMERS DATAFRAME EXPLORATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- First 5 rows ---\")\n",
    "display(df_customers.head())\n",
    "\n",
    "print(\"\\n--- Last 5 rows ---\")\n",
    "display(df_customers.tail())\n",
    "\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRANSACTIONS DATAFRAME EXPLORATION\n",
      "============================================================\n",
      "\n",
      "--- First 5 rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>shopify</td>\n",
       "      <td>shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>11870</td>\n",
       "      <td>35610</td>\n",
       "      <td>0</td>\n",
       "      <td>1068.30</td>\n",
       "      <td>35610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3172</td>\n",
       "      <td>3172</td>\n",
       "      <td>5500</td>\n",
       "      <td>412.36</td>\n",
       "      <td>8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>2</td>\n",
       "      <td>21834</td>\n",
       "      <td>43668</td>\n",
       "      <td>0</td>\n",
       "      <td>1310.04</td>\n",
       "      <td>43668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>2</td>\n",
       "      <td>31559</td>\n",
       "      <td>63118</td>\n",
       "      <td>0</td>\n",
       "      <td>1893.54</td>\n",
       "      <td>63118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>3061</td>\n",
       "      <td>3500</td>\n",
       "      <td>397.93</td>\n",
       "      <td>6561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  customer_id transaction_date      platform  product  \\\n",
       "0               1          364       2023-01-29       shopify   shorts   \n",
       "1               2           53       2023-04-22  mercadolibre    socks   \n",
       "2               3           19       2024-11-03       shopify  jackets   \n",
       "3               4          227       2023-05-11       shopify  jackets   \n",
       "4               5           24       2023-07-07  mercadolibre    socks   \n",
       "\n",
       "   quantity  unit_price  subtotal  shipping_cost  platform_fee  total_amount  \n",
       "0         3       11870     35610              0       1068.30         35610  \n",
       "1         1        3172      3172           5500        412.36          8672  \n",
       "2         2       21834     43668              0       1310.04         43668  \n",
       "3         2       31559     63118              0       1893.54         63118  \n",
       "4         1        3061      3061           3500        397.93          6561  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Last 5 rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>154</td>\n",
       "      <td>2024-07-12</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>3</td>\n",
       "      <td>31127</td>\n",
       "      <td>93381</td>\n",
       "      <td>0</td>\n",
       "      <td>2801.43</td>\n",
       "      <td>93381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>shopify</td>\n",
       "      <td>shorts</td>\n",
       "      <td>1</td>\n",
       "      <td>13559</td>\n",
       "      <td>13559</td>\n",
       "      <td>3500</td>\n",
       "      <td>406.77</td>\n",
       "      <td>17059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>279</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>shopify</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>4256</td>\n",
       "      <td>4256</td>\n",
       "      <td>3500</td>\n",
       "      <td>127.68</td>\n",
       "      <td>7756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>18</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>shopify</td>\n",
       "      <td>towels</td>\n",
       "      <td>1</td>\n",
       "      <td>13301</td>\n",
       "      <td>13301</td>\n",
       "      <td>5500</td>\n",
       "      <td>399.03</td>\n",
       "      <td>18801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>2</td>\n",
       "      <td>29347</td>\n",
       "      <td>58694</td>\n",
       "      <td>0</td>\n",
       "      <td>1760.82</td>\n",
       "      <td>58694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id  customer_id transaction_date platform  product  \\\n",
       "1995            1996          154       2024-07-12  shopify  jackets   \n",
       "1996            1997           74       2024-07-18  shopify   shorts   \n",
       "1997            1998          279       2023-07-06  shopify    socks   \n",
       "1998            1999           18       2024-07-03  shopify   towels   \n",
       "1999            2000           60       2024-03-28  shopify  jackets   \n",
       "\n",
       "      quantity  unit_price  subtotal  shipping_cost  platform_fee  \\\n",
       "1995         3       31127     93381              0       2801.43   \n",
       "1996         1       13559     13559           3500        406.77   \n",
       "1997         1        4256      4256           3500        127.68   \n",
       "1998         1       13301     13301           5500        399.03   \n",
       "1999         2       29347     58694              0       1760.82   \n",
       "\n",
       "      total_amount  \n",
       "1995         93381  \n",
       "1996         17059  \n",
       "1997          7756  \n",
       "1998         18801  \n",
       "1999         58694  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   transaction_id    2000 non-null   int64         \n",
      " 1   customer_id       2000 non-null   int64         \n",
      " 2   transaction_date  2000 non-null   datetime64[us]\n",
      " 3   platform          2000 non-null   str           \n",
      " 4   product           2000 non-null   str           \n",
      " 5   quantity          2000 non-null   int64         \n",
      " 6   unit_price        2000 non-null   int64         \n",
      " 7   subtotal          2000 non-null   int64         \n",
      " 8   shipping_cost     2000 non-null   int64         \n",
      " 9   platform_fee      2000 non-null   float64       \n",
      " 10  total_amount      2000 non-null   int64         \n",
      "dtypes: datetime64[us](1), float64(1), int64(7), str(2)\n",
      "memory usage: 172.0 KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXPLORE TRANSACTIONS DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRANSACTIONS DATAFRAME EXPLORATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- First 5 rows ---\")\n",
    "display(df_transactions.head())\n",
    "\n",
    "print(\"\\n--- Last 5 rows ---\")\n",
    "display(df_transactions.tail())\n",
    "\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "df_transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUSTOMERS - DESCRIPTIVE STATISTICS\n",
      "============================================================\n",
      "\n",
      "--- Numerical columns ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>registration_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>2023-10-04 12:31:40.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>2023-03-24 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>2023-08-04 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>2024-02-27 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>2024-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id           registration_date\n",
       "count   500.000000                         500\n",
       "mean    250.500000  2023-10-04 12:31:40.800000\n",
       "min       1.000000         2023-01-02 00:00:00\n",
       "25%     125.750000         2023-03-24 18:00:00\n",
       "50%     250.500000         2023-08-04 12:00:00\n",
       "75%     375.250000         2024-02-27 18:00:00\n",
       "max     500.000000         2024-12-31 00:00:00\n",
       "std     144.481833                         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Categorical columns ---\n",
      "\n",
      "Region distribution:\n",
      "region\n",
      "Metropolitana    214\n",
      "Valparaiso        73\n",
      "Biobio            67\n",
      "Los Lagos         39\n",
      "Araucania         34\n",
      "Maule             30\n",
      "OHiggins          27\n",
      "Coquimbo          16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Acquisition channel distribution:\n",
      "acquisition_channel\n",
      "mercadolibre_ads    138\n",
      "google_ads          104\n",
      "facebook_ads        103\n",
      "organic              81\n",
      "instagram_ads        74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DESCRIPTIVE STATISTICS - CUSTOMERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOMERS - DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- Numerical columns ---\")\n",
    "display(df_customers.describe())\n",
    "\n",
    "print(\"\\n--- Categorical columns ---\")\n",
    "print(f\"\\nRegion distribution:\")\n",
    "print(df_customers['region'].value_counts())\n",
    "\n",
    "print(f\"\\nAcquisition channel distribution:\")\n",
    "print(df_customers['acquisition_channel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRANSACTIONS - DESCRIPTIVE STATISTICS\n",
      "============================================================\n",
      "\n",
      "--- Numerical columns ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>148.052000</td>\n",
       "      <td>2023-12-30 01:25:40.800000</td>\n",
       "      <td>2.000500</td>\n",
       "      <td>15155.204000</td>\n",
       "      <td>30353.618000</td>\n",
       "      <td>2539.750000</td>\n",
       "      <td>2249.966540</td>\n",
       "      <td>32893.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2994.000000</td>\n",
       "      <td>3001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.030000</td>\n",
       "      <td>6501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2023-06-29 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10329.500000</td>\n",
       "      <td>13025.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>623.527500</td>\n",
       "      <td>17188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>2024-01-01 12:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13773.000000</td>\n",
       "      <td>23640.500000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1357.415000</td>\n",
       "      <td>27450.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>2024-06-25 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20437.500000</td>\n",
       "      <td>42114.500000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>2793.285000</td>\n",
       "      <td>42114.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2024-12-30 00:00:00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>34809.000000</td>\n",
       "      <td>133084.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>17087.720000</td>\n",
       "      <td>133084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>143.913209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.053591</td>\n",
       "      <td>7771.897543</td>\n",
       "      <td>23286.194654</td>\n",
       "      <td>2113.061157</td>\n",
       "      <td>2579.073174</td>\n",
       "      <td>21748.239935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       transaction_id  customer_id            transaction_date     quantity  \\\n",
       "count     2000.000000  2000.000000                        2000  2000.000000   \n",
       "mean      1000.500000   148.052000  2023-12-30 01:25:40.800000     2.000500   \n",
       "min          1.000000     1.000000         2023-01-01 00:00:00     1.000000   \n",
       "25%        500.750000    39.000000         2023-06-29 00:00:00     1.000000   \n",
       "50%       1000.500000    84.000000         2024-01-01 12:00:00     2.000000   \n",
       "75%       1500.250000   247.000000         2024-06-25 00:00:00     3.000000   \n",
       "max       2000.000000   500.000000         2024-12-30 00:00:00     4.000000   \n",
       "std        577.494589   143.913209                         NaN     1.053591   \n",
       "\n",
       "         unit_price       subtotal  shipping_cost  platform_fee   total_amount  \n",
       "count   2000.000000    2000.000000    2000.000000   2000.000000    2000.000000  \n",
       "mean   15155.204000   30353.618000    2539.750000   2249.966540   32893.368000  \n",
       "min     2994.000000    3001.000000       0.000000     90.030000    6501.000000  \n",
       "25%    10329.500000   13025.250000       0.000000    623.527500   17188.000000  \n",
       "50%    13773.000000   23640.500000    3500.000000   1357.415000   27450.500000  \n",
       "75%    20437.500000   42114.500000    3500.000000   2793.285000   42114.500000  \n",
       "max    34809.000000  133084.000000    5500.000000  17087.720000  133084.000000  \n",
       "std     7771.897543   23286.194654    2113.061157   2579.073174   21748.239935  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Platform distribution ---\n",
      "platform\n",
      "shopify         1108\n",
      "mercadolibre     892\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Product distribution ---\n",
      "product\n",
      "jackets    377\n",
      "tshirts    341\n",
      "shorts     338\n",
      "socks      324\n",
      "towels     318\n",
      "pajamas    302\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DESCRIPTIVE STATISTICS - TRANSACTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRANSACTIONS - DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- Numerical columns ---\")\n",
    "display(df_transactions.describe())\n",
    "\n",
    "print(\"\\n--- Platform distribution ---\")\n",
    "print(df_transactions['platform'].value_counts())\n",
    "\n",
    "print(\"\\n--- Product distribution ---\")\n",
    "print(df_transactions['product'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Conditional Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUSINESS QUESTIONS WITH CONDITIONAL FILTERS\n",
      "============================================================\n",
      "\n",
      "1. High-value transactions (>$50,000 CLP): 358\n",
      "   Revenue from high-value: $25,381,355 CLP\n",
      "\n",
      "2. MercadoLibre transactions in 2023: 676\n",
      "\n",
      "3. Shopify transactions in 2024: 788\n",
      "\n",
      "4. Metropolitana customers from Instagram: 35\n",
      "\n",
      "5. Jacket sales with multiple units: 232\n",
      "   Total jackets sold in bulk: 613\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONDITIONAL FILTERS - BUSINESS QUESTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BUSINESS QUESTIONS WITH CONDITIONAL FILTERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Q1: High-value transactions (above 50,000 CLP)\n",
    "high_value = df_transactions[df_transactions['total_amount'] > 50000]\n",
    "print(f\"\\n1. High-value transactions (>$50,000 CLP): {len(high_value)}\")\n",
    "print(f\"   Revenue from high-value: ${high_value['total_amount'].sum():,.0f} CLP\")\n",
    "\n",
    "# Q2: MercadoLibre transactions in 2023\n",
    "ml_2023 = df_transactions[\n",
    "    (df_transactions['platform'] == 'mercadolibre') & \n",
    "    (df_transactions['transaction_date'].dt.year == 2023)\n",
    "]\n",
    "print(f\"\\n2. MercadoLibre transactions in 2023: {len(ml_2023)}\")\n",
    "\n",
    "# Q3: Shopify transactions in 2024\n",
    "shopify_2024 = df_transactions[\n",
    "    (df_transactions['platform'] == 'shopify') & \n",
    "    (df_transactions['transaction_date'].dt.year == 2024)\n",
    "]\n",
    "print(f\"\\n3. Shopify transactions in 2024: {len(shopify_2024)}\")\n",
    "\n",
    "# Q4: Customers from Metropolitana region acquired via Instagram\n",
    "metro_ig = df_customers[\n",
    "    (df_customers['region'] == 'Metropolitana') & \n",
    "    (df_customers['acquisition_channel'] == 'instagram_ads')\n",
    "]\n",
    "print(f\"\\n4. Metropolitana customers from Instagram: {len(metro_ig)}\")\n",
    "\n",
    "# Q5: Jacket sales with quantity > 1\n",
    "jacket_multi = df_transactions[\n",
    "    (df_transactions['product'] == 'jackets') & \n",
    "    (df_transactions['quantity'] > 1)\n",
    "]\n",
    "print(f\"\\n5. Jacket sales with multiple units: {len(jacket_multi)}\")\n",
    "print(f\"   Total jackets sold in bulk: {jacket_multi['quantity'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using query() method for cleaner syntax ---\n",
      "\n",
      "6. Transactions with free shipping: 759\n",
      "   Percentage: 38.0%\n",
      "\n",
      "7. Low-value socks transactions (<$10,000): 123\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED FILTERS - USING QUERY METHOD\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Using query() method for cleaner syntax ---\")\n",
    "\n",
    "# Transactions with free shipping (subtotal >= 30,000)\n",
    "free_shipping = df_transactions.query('shipping_cost == 0')\n",
    "print(f\"\\n6. Transactions with free shipping: {len(free_shipping)}\")\n",
    "print(f\"   Percentage: {len(free_shipping)/len(df_transactions)*100:.1f}%\")\n",
    "\n",
    "# Low-value socks transactions\n",
    "low_socks = df_transactions.query('product == \"socks\" and total_amount < 10000')\n",
    "print(f\"\\n7. Low-value socks transactions (<$10,000): {len(low_socks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Save Preliminary DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved successfully!\n",
      "  - customers_preliminary.csv (500 rows)\n",
      "  - transactions_preliminary.csv (2000 rows)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE DATAFRAMES AS CSV\n",
    "# =============================================================================\n",
    "\n",
    "# Save to raw folder (these are still \"raw\" DataFrames, not yet cleaned)\n",
    "df_customers.to_csv('../data/raw/customers_preliminary.csv', index=False)\n",
    "df_transactions.to_csv('../data/raw/transactions_preliminary.csv', index=False)\n",
    "\n",
    "print(\"DataFrames saved successfully!\")\n",
    "print(f\"  - customers_preliminary.csv ({len(df_customers)} rows)\")\n",
    "print(f\"  - transactions_preliminary.csv ({len(df_transactions)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Lesson 2 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ Loaded NumPy arrays from Lesson 1\n",
    "2. ‚úÖ Converted arrays to Pandas DataFrames with proper column names\n",
    "3. ‚úÖ Transformed day numbers to actual datetime objects\n",
    "4. ‚úÖ Mapped numeric indices to categorical labels (regions, channels, platforms, products)\n",
    "5. ‚úÖ Explored data with head(), tail(), info(), describe()\n",
    "6. ‚úÖ Applied conditional filters to answer business questions\n",
    "7. ‚úÖ Saved preliminary CSVs for next lesson\n",
    "\n",
    "**Key Pandas methods used:**\n",
    "\n",
    "- `pd.DataFrame()` - Create DataFrame from dictionary\n",
    "- `.head()`, `.tail()` - View first/last rows\n",
    "- `.info()` - DataFrame structure and memory usage\n",
    "- `.describe()` - Statistical summary\n",
    "- `.value_counts()` - Frequency distribution\n",
    "- Boolean indexing `df_treated[condition]` - Filter rows\n",
    "- `.query()` - SQL-like filtering syntax\n",
    "- `.to_csv()` - Export to CSV file\n",
    "\n",
    "**Key findings:**\n",
    "\n",
    "- Customer distribution is weighted towards Metropolitana region (as expected)\n",
    "- Platform migration from MercadoLibre to Shopify is visible in the data\n",
    "- Free shipping threshold impacts a significant portion of transactions\n",
    "\n",
    "**Next step:** Lesson 3 - Integrate data from additional sources (Excel and web tables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 3: Data Acquisition from Files\n",
    "\n",
    "**Objective:** Integrate data from diverse sources (CSV, Excel, web tables) and unify them into a single DataFrame for subsequent cleaning.\n",
    "\n",
    "### Data Sources Overview\n",
    "\n",
    "| Source | File | Format | Description |\n",
    "|--------|------|--------|-------------|\n",
    "| MercadoLibre | transactions_preliminary.csv | CSV | Historical transactions from Lesson 2 |\n",
    "| Shopify | shopify_orders_2024.xlsx | Excel | Orders from the Shopify platform |\n",
    "| Marketing | marketing_metrics.html | Web Table | Campaign performance data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded for Lesson 3\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Libraries loaded for Lesson 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load CSV File (MercadoLibre Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MercadoLibre CSV loaded\n",
      "Shape: (892, 11)\n",
      "\n",
      "Columns: ['transaction_id', 'customer_id', 'transaction_date', 'platform', 'product', 'quantity', 'unit_price', 'subtotal', 'shipping_cost', 'platform_fee', 'total_amount']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3172</td>\n",
       "      <td>3172</td>\n",
       "      <td>5500</td>\n",
       "      <td>412.36</td>\n",
       "      <td>8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>3061</td>\n",
       "      <td>3500</td>\n",
       "      <td>397.93</td>\n",
       "      <td>6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>333</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>16859</td>\n",
       "      <td>50577</td>\n",
       "      <td>0</td>\n",
       "      <td>6575.01</td>\n",
       "      <td>50577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>towels</td>\n",
       "      <td>2</td>\n",
       "      <td>14402</td>\n",
       "      <td>28804</td>\n",
       "      <td>5500</td>\n",
       "      <td>3744.52</td>\n",
       "      <td>34304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>jackets</td>\n",
       "      <td>1</td>\n",
       "      <td>23032</td>\n",
       "      <td>23032</td>\n",
       "      <td>3500</td>\n",
       "      <td>2994.16</td>\n",
       "      <td>26532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transaction_id  customer_id transaction_date      platform  product  \\\n",
       "1                2           53       2023-04-22  mercadolibre    socks   \n",
       "4                5           24       2023-07-07  mercadolibre    socks   \n",
       "8                9          333       2023-12-30  mercadolibre   shorts   \n",
       "10              11            5       2023-07-31  mercadolibre   towels   \n",
       "13              14           44       2023-03-14  mercadolibre  jackets   \n",
       "\n",
       "    quantity  unit_price  subtotal  shipping_cost  platform_fee  total_amount  \n",
       "1          1        3172      3172           5500        412.36          8672  \n",
       "4          1        3061      3061           3500        397.93          6561  \n",
       "8          3       16859     50577              0       6575.01         50577  \n",
       "10         2       14402     28804           5500       3744.52         34304  \n",
       "13         1       23032     23032           3500       2994.16         26532  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD CSV - MERCADOLIBRE TRANSACTIONS\n",
    "# =============================================================================\n",
    "\n",
    "df_mercadolibre = pd.read_csv('../data/raw/transactions_preliminary.csv')\n",
    "\n",
    "# Filter only MercadoLibre transactions\n",
    "df_mercadolibre = df_mercadolibre[df_mercadolibre['platform'] == 'mercadolibre'].copy()\n",
    "\n",
    "print(\"MercadoLibre CSV loaded\")\n",
    "print(f\"Shape: {df_mercadolibre.shape}\")\n",
    "print(f\"\\nColumns: {list(df_mercadolibre.columns)}\")\n",
    "df_mercadolibre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load Excel File (Shopify Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopify Excel loaded\n",
      "Shape: (300, 14)\n",
      "\n",
      "Columns: ['Order Number', 'Order Date', 'Customer Email', 'Customer Name', 'Product Title', 'Quantity', 'Unit Price (CLP)', 'Discount', 'Shipping', 'Payment Method', 'Fulfillment Status', 'Region', 'Subtotal', 'Total (CLP)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Number</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer Email</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit Price (CLP)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Shipping</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Fulfillment Status</th>\n",
       "      <th>Region</th>\n",
       "      <th>Subtotal</th>\n",
       "      <th>Total (CLP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS-10000</td>\n",
       "      <td>31/12/2024</td>\n",
       "      <td>cliente370@email.com</td>\n",
       "      <td>Cliente 365</td>\n",
       "      <td>Chaqueta Polar</td>\n",
       "      <td>1</td>\n",
       "      <td>4990</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>Webpay</td>\n",
       "      <td>Fulfilled</td>\n",
       "      <td>RM</td>\n",
       "      <td>4990</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS-10001</td>\n",
       "      <td>17/01/2025</td>\n",
       "      <td>cliente84@email.com</td>\n",
       "      <td>Cliente 154</td>\n",
       "      <td>Calcetines Ni√±o</td>\n",
       "      <td>1</td>\n",
       "      <td>13990</td>\n",
       "      <td>0</td>\n",
       "      <td>3500</td>\n",
       "      <td>Webpay</td>\n",
       "      <td>Fulfilled</td>\n",
       "      <td>X</td>\n",
       "      <td>13990</td>\n",
       "      <td>17490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS-10002</td>\n",
       "      <td>18/11/2024</td>\n",
       "      <td>cliente351@email.com</td>\n",
       "      <td>Cliente 33</td>\n",
       "      <td>Short Verano</td>\n",
       "      <td>1</td>\n",
       "      <td>27990</td>\n",
       "      <td>1500</td>\n",
       "      <td>5500</td>\n",
       "      <td>MercadoPago</td>\n",
       "      <td>Fulfilled</td>\n",
       "      <td>VIII</td>\n",
       "      <td>27990</td>\n",
       "      <td>31990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS-10003</td>\n",
       "      <td>08/04/2024</td>\n",
       "      <td>cliente72@email.com</td>\n",
       "      <td>Cliente 188</td>\n",
       "      <td>Short Verano</td>\n",
       "      <td>1</td>\n",
       "      <td>13990</td>\n",
       "      <td>0</td>\n",
       "      <td>3500</td>\n",
       "      <td>Webpay</td>\n",
       "      <td>Pending</td>\n",
       "      <td>IX</td>\n",
       "      <td>13990</td>\n",
       "      <td>17490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS-10004</td>\n",
       "      <td>18/08/2024</td>\n",
       "      <td>cliente40@email.com</td>\n",
       "      <td>Cliente 393</td>\n",
       "      <td>Chaqueta Polar</td>\n",
       "      <td>1</td>\n",
       "      <td>27990</td>\n",
       "      <td>1000</td>\n",
       "      <td>3500</td>\n",
       "      <td>MercadoPago</td>\n",
       "      <td>Fulfilled</td>\n",
       "      <td>RM</td>\n",
       "      <td>27990</td>\n",
       "      <td>30490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order Number  Order Date        Customer Email Customer Name  \\\n",
       "0     PS-10000  31/12/2024  cliente370@email.com   Cliente 365   \n",
       "1     PS-10001  17/01/2025   cliente84@email.com   Cliente 154   \n",
       "2     PS-10002  18/11/2024  cliente351@email.com    Cliente 33   \n",
       "3     PS-10003  08/04/2024   cliente72@email.com   Cliente 188   \n",
       "4     PS-10004  18/08/2024   cliente40@email.com   Cliente 393   \n",
       "\n",
       "     Product Title  Quantity  Unit Price (CLP)  Discount  Shipping  \\\n",
       "0   Chaqueta Polar         1              4990       500         0   \n",
       "1  Calcetines Ni√±o         1             13990         0      3500   \n",
       "2     Short Verano         1             27990      1500      5500   \n",
       "3     Short Verano         1             13990         0      3500   \n",
       "4   Chaqueta Polar         1             27990      1000      3500   \n",
       "\n",
       "  Payment Method Fulfillment Status Region  Subtotal  Total (CLP)  \n",
       "0         Webpay          Fulfilled     RM      4990         4490  \n",
       "1         Webpay          Fulfilled      X     13990        17490  \n",
       "2    MercadoPago          Fulfilled   VIII     27990        31990  \n",
       "3         Webpay            Pending     IX     13990        17490  \n",
       "4    MercadoPago          Fulfilled     RM     27990        30490  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD EXCEL - SHOPIFY ORDERS\n",
    "# =============================================================================\n",
    "\n",
    "df_shopify = pd.read_excel('../data/raw/shopify_orders_2024.xlsx', sheet_name='Orders')\n",
    "\n",
    "print(\"Shopify Excel loaded\")\n",
    "print(f\"Shape: {df_shopify.shape}\")\n",
    "print(f\"\\nColumns: {list(df_shopify.columns)}\")\n",
    "df_shopify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopify DataFrame Info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   Order Number        300 non-null    str  \n",
      " 1   Order Date          300 non-null    str  \n",
      " 2   Customer Email      297 non-null    str  \n",
      " 3   Customer Name       299 non-null    str  \n",
      " 4   Product Title       300 non-null    str  \n",
      " 5   Quantity            300 non-null    int64\n",
      " 6   Unit Price (CLP)    300 non-null    int64\n",
      " 7   Discount            300 non-null    int64\n",
      " 8   Shipping            300 non-null    int64\n",
      " 9   Payment Method      300 non-null    str  \n",
      " 10  Fulfillment Status  300 non-null    str  \n",
      " 11  Region              298 non-null    str  \n",
      " 12  Subtotal            300 non-null    int64\n",
      " 13  Total (CLP)         300 non-null    int64\n",
      "dtypes: int64(6), str(8)\n",
      "memory usage: 32.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and info\n",
    "print(\"Shopify DataFrame Info:\")\n",
    "df_shopify.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Load Web Table (Marketing Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 table(s) in HTML file\n",
      "\n",
      "Marketing table loaded\n",
      "Shape: (24, 10)\n",
      "\n",
      "Columns: ['Campaign', 'Channel', 'Month', 'Impressions', 'Clicks', 'CTR (%)', 'Spend (CLP)', 'Conversions', 'Revenue (CLP)', 'ROAS']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Month</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>CTR (%)</th>\n",
       "      <th>Spend (CLP)</th>\n",
       "      <th>Conversions</th>\n",
       "      <th>Revenue (CLP)</th>\n",
       "      <th>ROAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer Collection</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Jan-24</td>\n",
       "      <td>125000</td>\n",
       "      <td>3750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>450000</td>\n",
       "      <td>45</td>\n",
       "      <td>1350000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summer Collection</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Jan-24</td>\n",
       "      <td>98000</td>\n",
       "      <td>4410</td>\n",
       "      <td>4.5</td>\n",
       "      <td>380000</td>\n",
       "      <td>52</td>\n",
       "      <td>1560000</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer Collection</td>\n",
       "      <td>Google</td>\n",
       "      <td>Jan-24</td>\n",
       "      <td>85000</td>\n",
       "      <td>2550</td>\n",
       "      <td>3.0</td>\n",
       "      <td>320000</td>\n",
       "      <td>38</td>\n",
       "      <td>1140000</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Back to School</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Feb-24</td>\n",
       "      <td>145000</td>\n",
       "      <td>5075</td>\n",
       "      <td>3.5</td>\n",
       "      <td>520000</td>\n",
       "      <td>62</td>\n",
       "      <td>1860000</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back to School</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Feb-24</td>\n",
       "      <td>112000</td>\n",
       "      <td>5600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>420000</td>\n",
       "      <td>71</td>\n",
       "      <td>2130000</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Back to School</td>\n",
       "      <td>Google</td>\n",
       "      <td>Feb-24</td>\n",
       "      <td>95000</td>\n",
       "      <td>3325</td>\n",
       "      <td>3.5</td>\n",
       "      <td>380000</td>\n",
       "      <td>48</td>\n",
       "      <td>1440000</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fall Essentials</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Apr-24</td>\n",
       "      <td>88000</td>\n",
       "      <td>2640</td>\n",
       "      <td>3.0</td>\n",
       "      <td>280000</td>\n",
       "      <td>33</td>\n",
       "      <td>990000</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fall Essentials</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Apr-24</td>\n",
       "      <td>76000</td>\n",
       "      <td>3420</td>\n",
       "      <td>4.5</td>\n",
       "      <td>250000</td>\n",
       "      <td>41</td>\n",
       "      <td>1230000</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fall Essentials</td>\n",
       "      <td>Google</td>\n",
       "      <td>Apr-24</td>\n",
       "      <td>62000</td>\n",
       "      <td>1860</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200000</td>\n",
       "      <td>25</td>\n",
       "      <td>750000</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Winter Warmth</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Jun-24</td>\n",
       "      <td>135000</td>\n",
       "      <td>4725</td>\n",
       "      <td>3.5</td>\n",
       "      <td>480000</td>\n",
       "      <td>58</td>\n",
       "      <td>2030000</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Campaign    Channel   Month  Impressions  Clicks  CTR (%)  \\\n",
       "0  Summer Collection   Facebook  Jan-24       125000    3750      3.0   \n",
       "1  Summer Collection  Instagram  Jan-24        98000    4410      4.5   \n",
       "2  Summer Collection     Google  Jan-24        85000    2550      3.0   \n",
       "3     Back to School   Facebook  Feb-24       145000    5075      3.5   \n",
       "4     Back to School  Instagram  Feb-24       112000    5600      5.0   \n",
       "5     Back to School     Google  Feb-24        95000    3325      3.5   \n",
       "6    Fall Essentials   Facebook  Apr-24        88000    2640      3.0   \n",
       "7    Fall Essentials  Instagram  Apr-24        76000    3420      4.5   \n",
       "8    Fall Essentials     Google  Apr-24        62000    1860      3.0   \n",
       "9      Winter Warmth   Facebook  Jun-24       135000    4725      3.5   \n",
       "\n",
       "   Spend (CLP)  Conversions  Revenue (CLP)  ROAS  \n",
       "0       450000           45        1350000   3.0  \n",
       "1       380000           52        1560000   4.1  \n",
       "2       320000           38        1140000   3.6  \n",
       "3       520000           62        1860000   3.6  \n",
       "4       420000           71        2130000   5.1  \n",
       "5       380000           48        1440000   3.8  \n",
       "6       280000           33         990000   3.5  \n",
       "7       250000           41        1230000   4.9  \n",
       "8       200000           25         750000   3.8  \n",
       "9       480000           58        2030000   4.2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD HTML TABLE - MARKETING METRICS\n",
    "# =============================================================================\n",
    "\n",
    "# read_html returns a list of DataFrames (one per table found)\n",
    "tables = pd.read_html('../data/raw/marketing_metrics.html')\n",
    "\n",
    "print(f\"Found {len(tables)} table(s) in HTML file\")\n",
    "\n",
    "# Get the first (and only) table\n",
    "df_marketing = tables[0]\n",
    "\n",
    "print(f\"\\nMarketing table loaded\")\n",
    "print(f\"Shape: {df_marketing.shape}\")\n",
    "print(f\"\\nColumns: {list(df_marketing.columns)}\")\n",
    "df_marketing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marketing DataFrame Info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Campaign       24 non-null     str    \n",
      " 1   Channel        24 non-null     str    \n",
      " 2   Month          24 non-null     str    \n",
      " 3   Impressions    24 non-null     int64  \n",
      " 4   Clicks         24 non-null     int64  \n",
      " 5   CTR (%)        24 non-null     float64\n",
      " 6   Spend (CLP)    24 non-null     int64  \n",
      " 7   Conversions    24 non-null     int64  \n",
      " 8   Revenue (CLP)  24 non-null     int64  \n",
      " 9   ROAS           24 non-null     float64\n",
      "dtypes: float64(2), int64(5), str(3)\n",
      "memory usage: 2.0 KB\n",
      "\n",
      "--- Campaign distribution ---\n",
      "Campaign\n",
      "Winter Warmth        4\n",
      "Cyber Monday         4\n",
      "Christmas Magic      4\n",
      "Summer Collection    3\n",
      "Back to School       3\n",
      "Fall Essentials      3\n",
      "Spring Preview       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Channel distribution ---\n",
      "Channel\n",
      "Facebook        7\n",
      "Instagram       7\n",
      "Google          7\n",
      "MercadoLibre    3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore marketing data\n",
    "print(\"Marketing DataFrame Info:\")\n",
    "df_marketing.info()\n",
    "\n",
    "print(\"\\n--- Campaign distribution ---\")\n",
    "print(df_marketing['Campaign'].value_counts())\n",
    "\n",
    "print(\"\\n--- Channel distribution ---\")\n",
    "print(df_marketing['Channel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data Harmonization Challenges\n",
    "\n",
    "Before unifying the data, let's identify the challenges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA HARMONIZATION CHALLENGES\n",
      "============================================================\n",
      "\n",
      "1. COLUMN NAME DIFFERENCES\n",
      "   MercadoLibre: ['transaction_id', 'customer_id', 'transaction_date', 'platform', 'product']...\n",
      "   Shopify: ['Order Number', 'Order Date', 'Customer Email', 'Customer Name', 'Product Title']...\n",
      "\n",
      "2. DATE FORMAT DIFFERENCES\n",
      "   MercadoLibre date sample: 2023-04-22\n",
      "   Shopify date sample: 31/12/2024\n",
      "\n",
      "3. PRODUCT NAME DIFFERENCES\n",
      "   MercadoLibre products: <StringArray>\n",
      "['socks', 'shorts', 'towels']\n",
      "Length: 3, dtype: str...\n",
      "   Shopify products: <StringArray>\n",
      "['Chaqueta Polar', 'Calcetines Ni√±o', 'Short Verano']\n",
      "Length: 3, dtype: str...\n",
      "\n",
      "4. REGION FORMAT DIFFERENCES\n",
      "   Shopify regions: <StringArray>\n",
      "['RM', 'X', 'VIII', 'IX', 'Metr', 'IV', 'V', 'VI', 'VII', 'metr', nan, 'Valp']\n",
      "Length: 12, dtype: str\n",
      "\n",
      "5. NULL VALUES IN SHOPIFY DATA\n",
      "Customer Email    3\n",
      "Customer Name     1\n",
      "Region            2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IDENTIFY DATA HARMONIZATION CHALLENGES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA HARMONIZATION CHALLENGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. COLUMN NAME DIFFERENCES\")\n",
    "print(f\"   MercadoLibre: {list(df_mercadolibre.columns)[:5]}...\")\n",
    "print(f\"   Shopify: {list(df_shopify.columns)[:5]}...\")\n",
    "\n",
    "print(\"\\n2. DATE FORMAT DIFFERENCES\")\n",
    "print(f\"   MercadoLibre date sample: {df_mercadolibre['transaction_date'].iloc[0]}\")\n",
    "print(f\"   Shopify date sample: {df_shopify['Order Date'].iloc[0]}\")\n",
    "\n",
    "print(\"\\n3. PRODUCT NAME DIFFERENCES\")\n",
    "print(f\"   MercadoLibre products: {df_mercadolibre['product'].unique()[:3]}...\")\n",
    "print(f\"   Shopify products: {df_shopify['Product Title'].unique()[:3]}...\")\n",
    "\n",
    "print(\"\\n4. REGION FORMAT DIFFERENCES\")\n",
    "print(f\"   Shopify regions: {df_shopify['Region'].unique()}\")\n",
    "\n",
    "print(\"\\n5. NULL VALUES IN SHOPIFY DATA\")\n",
    "print(df_shopify.isnull().sum()[df_shopify.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Standardize Shopify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopify data standardized\n",
      "Shape: (300, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS-10000</td>\n",
       "      <td>52</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>1</td>\n",
       "      <td>4990</td>\n",
       "      <td>4990</td>\n",
       "      <td>0</td>\n",
       "      <td>149.7</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS-10001</td>\n",
       "      <td>143</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>shopify</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>13990</td>\n",
       "      <td>13990</td>\n",
       "      <td>3500</td>\n",
       "      <td>419.7</td>\n",
       "      <td>17490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS-10002</td>\n",
       "      <td>415</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>shopify</td>\n",
       "      <td>shorts</td>\n",
       "      <td>1</td>\n",
       "      <td>27990</td>\n",
       "      <td>27990</td>\n",
       "      <td>5500</td>\n",
       "      <td>839.7</td>\n",
       "      <td>31990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS-10003</td>\n",
       "      <td>211</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>shopify</td>\n",
       "      <td>shorts</td>\n",
       "      <td>1</td>\n",
       "      <td>13990</td>\n",
       "      <td>13990</td>\n",
       "      <td>3500</td>\n",
       "      <td>419.7</td>\n",
       "      <td>17490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS-10004</td>\n",
       "      <td>386</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>shopify</td>\n",
       "      <td>jackets</td>\n",
       "      <td>1</td>\n",
       "      <td>27990</td>\n",
       "      <td>27990</td>\n",
       "      <td>3500</td>\n",
       "      <td>839.7</td>\n",
       "      <td>30490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id  customer_id transaction_date platform  product  quantity  \\\n",
       "0       PS-10000           52       2024-12-31  shopify  jackets         1   \n",
       "1       PS-10001          143       2025-01-17  shopify    socks         1   \n",
       "2       PS-10002          415       2024-11-18  shopify   shorts         1   \n",
       "3       PS-10003          211       2024-04-08  shopify   shorts         1   \n",
       "4       PS-10004          386       2024-08-18  shopify  jackets         1   \n",
       "\n",
       "   unit_price  subtotal  shipping_cost  platform_fee  total_amount  \n",
       "0        4990      4990              0         149.7          4490  \n",
       "1       13990     13990           3500         419.7         17490  \n",
       "2       27990     27990           5500         839.7         31990  \n",
       "3       13990     13990           3500         419.7         17490  \n",
       "4       27990     27990           3500         839.7         30490  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STANDARDIZE SHOPIFY DATA TO MATCH MERCADOLIBRE FORMAT\n",
    "# =============================================================================\n",
    "\n",
    "# Create a copy for transformation\n",
    "df_shopify_std = df_shopify.copy()\n",
    "\n",
    "# 1. Rename columns to match MercadoLibre format\n",
    "column_mapping = {\n",
    "    'Order Number': 'transaction_id',\n",
    "    'Order Date': 'transaction_date',\n",
    "    'Product Title': 'product',\n",
    "    'Quantity': 'quantity',\n",
    "    'Unit Price (CLP)': 'unit_price',\n",
    "    'Subtotal': 'subtotal',\n",
    "    'Shipping': 'shipping_cost',\n",
    "    'Total (CLP)': 'total_amount',\n",
    "    'Region': 'region'\n",
    "}\n",
    "df_shopify_std = df_shopify_std.rename(columns=column_mapping)\n",
    "\n",
    "# 2. Add platform column\n",
    "df_shopify_std['platform'] = 'shopify'\n",
    "\n",
    "# 3. Convert date format (from DD/MM/YYYY to datetime)\n",
    "df_shopify_std['transaction_date'] = pd.to_datetime(\n",
    "    df_shopify_std['transaction_date'], \n",
    "    format='%d/%m/%Y',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 4. Standardize product names (Spanish to English)\n",
    "product_mapping = {\n",
    "    'Calcetines Ni√±o': 'socks',\n",
    "    'Toalla Playa Disney': 'towels',\n",
    "    'Polera Estampada': 'tshirts',\n",
    "    'Short Verano': 'shorts',\n",
    "    'Chaqueta Polar': 'jackets',\n",
    "    'Pijama Algod√≥n': 'pajamas'\n",
    "}\n",
    "df_shopify_std['product'] = df_shopify_std['product'].map(product_mapping)\n",
    "\n",
    "# 5. Standardize region names\n",
    "region_mapping = {\n",
    "    'RM': 'Metropolitana',\n",
    "    'Metropolitana': 'Metropolitana',\n",
    "    'metropolitana': 'Metropolitana',\n",
    "    'V': 'Valparaiso',\n",
    "    'Valpara√≠so': 'Valparaiso',\n",
    "    'VIII': 'Biobio',\n",
    "    'IX': 'Araucania',\n",
    "    'VII': 'Maule',\n",
    "    'VI': 'OHiggins',\n",
    "    'X': 'Los Lagos',\n",
    "    'IV': 'Coquimbo'\n",
    "}\n",
    "df_shopify_std['region'] = df_shopify_std['region'].map(region_mapping)\n",
    "\n",
    "# 6. Calculate platform fee (3% for Shopify payment gateway)\n",
    "df_shopify_std['platform_fee'] = df_shopify_std['subtotal'] * 0.03\n",
    "\n",
    "# 6.5 Generate customer_id for Shopify (continuing from MercadoLibre max)\n",
    "np.random.seed(789)\n",
    "existing_customers = df_customers['customer_id'].values\n",
    "df_shopify_std['customer_id'] = np.random.choice(existing_customers, size=len(df_shopify_std))\n",
    "\n",
    "# 7. Select and reorder columns to match MercadoLibre\n",
    "columns_to_keep = [\n",
    "    'transaction_id',  'customer_id', 'transaction_date', 'platform', 'product',\n",
    "    'quantity', 'unit_price', 'subtotal', 'shipping_cost', \n",
    "    'platform_fee', 'total_amount'\n",
    "]\n",
    "df_shopify_std = df_shopify_std[columns_to_keep]\n",
    "\n",
    "print(\"Shopify data standardized\")\n",
    "print(f\"Shape: {df_shopify_std.shape}\")\n",
    "df_shopify_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Standardize MercadoLibre Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MercadoLibre data standardized\n",
      "Shape: (892, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3172</td>\n",
       "      <td>3172</td>\n",
       "      <td>5500</td>\n",
       "      <td>412.36</td>\n",
       "      <td>8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>3061</td>\n",
       "      <td>3500</td>\n",
       "      <td>397.93</td>\n",
       "      <td>6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>333</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>16859</td>\n",
       "      <td>50577</td>\n",
       "      <td>0</td>\n",
       "      <td>6575.01</td>\n",
       "      <td>50577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>towels</td>\n",
       "      <td>2</td>\n",
       "      <td>14402</td>\n",
       "      <td>28804</td>\n",
       "      <td>5500</td>\n",
       "      <td>3744.52</td>\n",
       "      <td>34304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>jackets</td>\n",
       "      <td>1</td>\n",
       "      <td>23032</td>\n",
       "      <td>23032</td>\n",
       "      <td>3500</td>\n",
       "      <td>2994.16</td>\n",
       "      <td>26532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transaction_id  customer_id transaction_date      platform  product  \\\n",
       "1                2           53       2023-04-22  mercadolibre    socks   \n",
       "4                5           24       2023-07-07  mercadolibre    socks   \n",
       "8                9          333       2023-12-30  mercadolibre   shorts   \n",
       "10              11            5       2023-07-31  mercadolibre   towels   \n",
       "13              14           44       2023-03-14  mercadolibre  jackets   \n",
       "\n",
       "    quantity  unit_price  subtotal  shipping_cost  platform_fee  total_amount  \n",
       "1          1        3172      3172           5500        412.36          8672  \n",
       "4          1        3061      3061           3500        397.93          6561  \n",
       "8          3       16859     50577              0       6575.01         50577  \n",
       "10         2       14402     28804           5500       3744.52         34304  \n",
       "13         1       23032     23032           3500       2994.16         26532  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STANDARDIZE MERCADOLIBRE DATA\n",
    "# =============================================================================\n",
    "\n",
    "df_ml_std = df_mercadolibre.copy()\n",
    "\n",
    "# Convert date to datetime if not already\n",
    "df_ml_std['transaction_date'] = pd.to_datetime(df_ml_std['transaction_date'])\n",
    "\n",
    "# Select matching columns\n",
    "columns_to_keep = [\n",
    "    'transaction_id', 'customer_id', 'transaction_date', 'platform', 'product',\n",
    "    'quantity', 'unit_price', 'subtotal', 'shipping_cost', \n",
    "    'platform_fee', 'total_amount'\n",
    "]\n",
    "df_ml_std = df_ml_std[columns_to_keep]\n",
    "\n",
    "print(\"MercadoLibre data standardized\")\n",
    "print(f\"Shape: {df_ml_std.shape}\")\n",
    "df_ml_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Unify Transaction Data with concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UNIFIED TRANSACTIONS DATAFRAME\n",
      "============================================================\n",
      "\n",
      "Total rows: 1192\n",
      "  - From MercadoLibre: 892\n",
      "  - From Shopify: 300\n",
      "\n",
      "Date range: 2023-01-01 00:00:00 to 2025-01-30 00:00:00\n",
      "\n",
      "--- Platform distribution ---\n",
      "platform\n",
      "mercadolibre    892\n",
      "shopify         300\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>platform</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>pajamas</td>\n",
       "      <td>3</td>\n",
       "      <td>22008</td>\n",
       "      <td>66024</td>\n",
       "      <td>0</td>\n",
       "      <td>8583.12</td>\n",
       "      <td>66024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>995</td>\n",
       "      <td>54</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>jackets</td>\n",
       "      <td>2</td>\n",
       "      <td>28273</td>\n",
       "      <td>56546</td>\n",
       "      <td>0</td>\n",
       "      <td>7350.98</td>\n",
       "      <td>56546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "      <td>57</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>4</td>\n",
       "      <td>3904</td>\n",
       "      <td>15616</td>\n",
       "      <td>5500</td>\n",
       "      <td>2030.08</td>\n",
       "      <td>21116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308</td>\n",
       "      <td>199</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>jackets</td>\n",
       "      <td>1</td>\n",
       "      <td>30474</td>\n",
       "      <td>30474</td>\n",
       "      <td>0</td>\n",
       "      <td>3961.62</td>\n",
       "      <td>30474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>shorts</td>\n",
       "      <td>1</td>\n",
       "      <td>13211</td>\n",
       "      <td>13211</td>\n",
       "      <td>3500</td>\n",
       "      <td>1717.43</td>\n",
       "      <td>16711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1490</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>socks</td>\n",
       "      <td>1</td>\n",
       "      <td>5961</td>\n",
       "      <td>5961</td>\n",
       "      <td>3500</td>\n",
       "      <td>774.93</td>\n",
       "      <td>9461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1852</td>\n",
       "      <td>75</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>shorts</td>\n",
       "      <td>4</td>\n",
       "      <td>13457</td>\n",
       "      <td>53828</td>\n",
       "      <td>0</td>\n",
       "      <td>6997.64</td>\n",
       "      <td>53828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1378</td>\n",
       "      <td>77</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>tshirts</td>\n",
       "      <td>2</td>\n",
       "      <td>11994</td>\n",
       "      <td>23988</td>\n",
       "      <td>3500</td>\n",
       "      <td>3118.44</td>\n",
       "      <td>27488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82</td>\n",
       "      <td>421</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>pajamas</td>\n",
       "      <td>1</td>\n",
       "      <td>18720</td>\n",
       "      <td>18720</td>\n",
       "      <td>3500</td>\n",
       "      <td>2433.60</td>\n",
       "      <td>22220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1590</td>\n",
       "      <td>87</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>mercadolibre</td>\n",
       "      <td>tshirts</td>\n",
       "      <td>1</td>\n",
       "      <td>11711</td>\n",
       "      <td>11711</td>\n",
       "      <td>3500</td>\n",
       "      <td>1522.43</td>\n",
       "      <td>15211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id  customer_id transaction_date      platform  product  \\\n",
       "0            681           30       2023-01-01  mercadolibre  pajamas   \n",
       "1            995           54       2023-01-01  mercadolibre  jackets   \n",
       "2           1800           57       2023-01-01  mercadolibre    socks   \n",
       "3            308          199       2023-01-01  mercadolibre  jackets   \n",
       "4            700           18       2023-01-03  mercadolibre   shorts   \n",
       "5           1490           80       2023-01-04  mercadolibre    socks   \n",
       "6           1852           75       2023-01-04  mercadolibre   shorts   \n",
       "7           1378           77       2023-01-05  mercadolibre  tshirts   \n",
       "8             82          421       2023-01-07  mercadolibre  pajamas   \n",
       "9           1590           87       2023-01-07  mercadolibre  tshirts   \n",
       "\n",
       "   quantity  unit_price  subtotal  shipping_cost  platform_fee  total_amount  \n",
       "0         3       22008     66024              0       8583.12         66024  \n",
       "1         2       28273     56546              0       7350.98         56546  \n",
       "2         4        3904     15616           5500       2030.08         21116  \n",
       "3         1       30474     30474              0       3961.62         30474  \n",
       "4         1       13211     13211           3500       1717.43         16711  \n",
       "5         1        5961      5961           3500        774.93          9461  \n",
       "6         4       13457     53828              0       6997.64         53828  \n",
       "7         2       11994     23988           3500       3118.44         27488  \n",
       "8         1       18720     18720           3500       2433.60         22220  \n",
       "9         1       11711     11711           3500       1522.43         15211  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# UNIFY DATA SOURCES USING CONCAT\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Concatenate MercadoLibre and Shopify transactions\n",
    "df_transactions_unified = pd.concat(\n",
    "    [df_ml_std, df_shopify_std], \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Sort by date\n",
    "df_transactions_unified = df_transactions_unified.sort_values('transaction_date').reset_index(drop=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UNIFIED TRANSACTIONS DATAFRAME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal rows: {len(df_transactions_unified)}\")\n",
    "print(f\"  - From MercadoLibre: {len(df_ml_std)}\")\n",
    "print(f\"  - From Shopify: {len(df_shopify_std)}\")\n",
    "\n",
    "print(f\"\\nDate range: {df_transactions_unified['transaction_date'].min()} to {df_transactions_unified['transaction_date'].max()}\")\n",
    "\n",
    "print(\"\\n--- Platform distribution ---\")\n",
    "print(df_transactions_unified['platform'].value_counts())\n",
    "\n",
    "df_transactions_unified.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types ---\n",
      "transaction_id              object\n",
      "customer_id                  int64\n",
      "transaction_date    datetime64[us]\n",
      "platform                       str\n",
      "product                        str\n",
      "quantity                     int64\n",
      "unit_price                   int64\n",
      "subtotal                     int64\n",
      "shipping_cost                int64\n",
      "platform_fee               float64\n",
      "total_amount                 int64\n",
      "dtype: object\n",
      "\n",
      "--- Null Values ---\n",
      "transaction_id      0\n",
      "customer_id         0\n",
      "transaction_date    0\n",
      "platform            0\n",
      "product             0\n",
      "quantity            0\n",
      "unit_price          0\n",
      "subtotal            0\n",
      "shipping_cost       0\n",
      "platform_fee        0\n",
      "total_amount        0\n",
      "dtype: int64\n",
      "\n",
      "--- Descriptive Statistics ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>170.283557</td>\n",
       "      <td>2023-12-10 08:26:10.469798</td>\n",
       "      <td>1.952181</td>\n",
       "      <td>15364.786074</td>\n",
       "      <td>29108.775168</td>\n",
       "      <td>2746.644295</td>\n",
       "      <td>3120.508221</td>\n",
       "      <td>31688.892617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3010.000000</td>\n",
       "      <td>3039.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149.700000</td>\n",
       "      <td>4490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.750000</td>\n",
       "      <td>2023-06-06 18:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10600.000000</td>\n",
       "      <td>12990.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>933.595000</td>\n",
       "      <td>16564.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>2023-11-16 12:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13712.500000</td>\n",
       "      <td>22784.500000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1973.400000</td>\n",
       "      <td>26333.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>294.000000</td>\n",
       "      <td>2024-06-06 06:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19990.000000</td>\n",
       "      <td>39033.500000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>4148.950000</td>\n",
       "      <td>39525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>2025-01-30 00:00:00</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>299900.000000</td>\n",
       "      <td>299900.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>17087.720000</td>\n",
       "      <td>299900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>151.641979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.719224</td>\n",
       "      <td>11220.781024</td>\n",
       "      <td>24177.432748</td>\n",
       "      <td>2063.941469</td>\n",
       "      <td>2999.539522</td>\n",
       "      <td>23050.424057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id            transaction_date     quantity     unit_price  \\\n",
       "count  1192.000000                        1192  1192.000000    1192.000000   \n",
       "mean    170.283557  2023-12-10 08:26:10.469798     1.952181   15364.786074   \n",
       "min       1.000000         2023-01-01 00:00:00     1.000000    3010.000000   \n",
       "25%      44.750000         2023-06-06 18:00:00     1.000000   10600.000000   \n",
       "50%      98.000000         2023-11-16 12:00:00     2.000000   13712.500000   \n",
       "75%     294.000000         2024-06-06 06:00:00     3.000000   19990.000000   \n",
       "max     500.000000         2025-01-30 00:00:00    50.000000  299900.000000   \n",
       "std     151.641979                         NaN     1.719224   11220.781024   \n",
       "\n",
       "            subtotal  shipping_cost  platform_fee   total_amount  \n",
       "count    1192.000000    1192.000000   1192.000000    1192.000000  \n",
       "mean    29108.775168    2746.644295   3120.508221   31688.892617  \n",
       "min      3039.000000       0.000000    149.700000    4490.000000  \n",
       "25%     12990.000000       0.000000    933.595000   16564.750000  \n",
       "50%     22784.500000    3500.000000   1973.400000   26333.500000  \n",
       "75%     39033.500000    3500.000000   4148.950000   39525.000000  \n",
       "max    299900.000000    5500.000000  17087.720000  299900.000000  \n",
       "std     24177.432748    2063.941469   2999.539522   23050.424057  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify data integrity\n",
    "print(\"\\n--- Data Types ---\")\n",
    "print(df_transactions_unified.dtypes)\n",
    "\n",
    "print(\"\\n--- Null Values ---\")\n",
    "print(df_transactions_unified.isnull().sum())\n",
    "\n",
    "print(\"\\n--- Descriptive Statistics ---\")\n",
    "df_transactions_unified.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Save Consolidated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data saved:\n",
      "  - transactions_consolidated.csv (1192 rows)\n",
      "  - marketing_metrics.csv (24 rows)\n",
      "Columns: ['transaction_id', 'customer_id', 'transaction_date', 'platform', 'product', 'quantity', 'unit_price', 'subtotal', 'shipping_cost', 'platform_fee', 'total_amount']\n",
      "customer_id present: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE CONSOLIDATED DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "# Save unified transactions\n",
    "df_transactions_unified.to_csv('../data/raw/transactions_consolidated.csv', index=False)\n",
    "\n",
    "# Save marketing data\n",
    "df_marketing.to_csv('../data/raw/marketing_metrics.csv', index=False)\n",
    "\n",
    "print(\"Consolidated data saved:\")\n",
    "print(f\"  - transactions_consolidated.csv ({len(df_transactions_unified)} rows)\")\n",
    "print(f\"  - marketing_metrics.csv ({len(df_marketing)} rows)\")\n",
    "\n",
    "# Verify that customer_id is in the saved file\n",
    "df_test = pd.read_csv('../data/raw/transactions_consolidated.csv')\n",
    "print(f\"Columns: {list(df_test.columns)}\")\n",
    "print(f\"customer_id present: {'customer_id' in df_test.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Lesson 3 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ Loaded CSV file with `pd.read_csv()` - MercadoLibre transactions\n",
    "2. ‚úÖ Loaded Excel file with `pd.read_excel()` - Shopify orders\n",
    "3. ‚úÖ Loaded HTML table with `pd.read_html()` - Marketing metrics\n",
    "4. ‚úÖ Identified harmonization challenges (column names, date formats, product names, regions)\n",
    "5. ‚úÖ Standardized column names and data formats\n",
    "6. ‚úÖ Unified transaction data using `pd.concat()`\n",
    "7. ‚úÖ Saved consolidated datasets\n",
    "\n",
    "**Challenges encountered:**\n",
    "\n",
    "- Different column naming conventions between platforms\n",
    "- Date format differences (DD/MM/YYYY vs YYYY-MM-DD)\n",
    "- Product names in Spanish (Shopify) vs English (MercadoLibre)\n",
    "- Region codes vs full names\n",
    "- Null values in Shopify data (to be handled in Lesson 4)\n",
    "\n",
    "**Key Pandas methods used:**\n",
    "\n",
    "- `pd.read_csv()` - Load CSV files\n",
    "- `pd.read_excel()` - Load Excel files\n",
    "- `pd.read_html()` - Parse HTML tables\n",
    "- `.rename()` - Rename columns\n",
    "- `.map()` - Map values using dictionary\n",
    "- `pd.to_datetime()` - Convert to datetime\n",
    "- `pd.concat()` - Combine DataFrames vertically\n",
    "\n",
    "**Next step:** Lesson 4 - Handle missing values and outliers in the consolidated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 4: Missing Values and Outliers\n",
    "\n",
    "**Objective:** Apply data cleaning techniques to resolve null values and detect/treat outliers in the consolidated dataset.\n",
    "\n",
    "### Techniques to Apply\n",
    "\n",
    "**For Missing Values:**\n",
    "- Identification with `.isnull()` and `.isna()`\n",
    "- Elimination with `.dropna()`\n",
    "- Imputation with `.fillna()` (mean, median, mode, forward fill)\n",
    "\n",
    "**For Outliers:**\n",
    "- IQR (Interquartile Range) method\n",
    "- Z-score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded for Lesson 4\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "print(\"Libraries loaded for Lesson 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load Consolidated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1192 transactions\n",
      "\n",
      "Columns: ['transaction_id', 'customer_id', 'transaction_date', 'platform', 'product', 'quantity', 'unit_price', 'subtotal', 'shipping_cost', 'platform_fee', 'total_amount']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD CONSOLIDATED DATA FROM LESSON 3\n",
    "# =============================================================================\n",
    "df = pd.read_csv('../data/raw/transactions_consolidated.csv')\n",
    "\n",
    "# Convert date column\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "\n",
    "print(f\"Loaded {len(df)} transactions\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()\n",
    "print('customer_id' in df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Identify Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Null Values Summary ---\n",
      "                  Null Count  Null %\n",
      "transaction_id             0     0.0\n",
      "customer_id                0     0.0\n",
      "transaction_date           0     0.0\n",
      "platform                   0     0.0\n",
      "product                    0     0.0\n",
      "quantity                   0     0.0\n",
      "unit_price                 0     0.0\n",
      "subtotal                   0     0.0\n",
      "shipping_cost              0     0.0\n",
      "platform_fee               0     0.0\n",
      "total_amount               0     0.0\n",
      "\n",
      "Rows with at least one null value: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IDENTIFY NULL VALUES\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count nulls per column\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentages = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "\n",
    "# Create summary DataFrame\n",
    "null_summary = pd.DataFrame({\n",
    "    'Null Count': null_counts,\n",
    "    'Null %': null_percentages\n",
    "})\n",
    "\n",
    "print(\"\\n--- Null Values Summary ---\")\n",
    "print(null_summary)\n",
    "\n",
    "# Total rows with at least one null\n",
    "rows_with_nulls = df.isnull().any(axis=1).sum()\n",
    "print(f\"\\nRows with at least one null value: {rows_with_nulls} ({rows_with_nulls/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample Rows with Null Values ---\n",
      "No null values found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Visualize rows with null values\n",
    "print(\"\\n--- Sample Rows with Null Values ---\")\n",
    "null_rows = df[df.isnull().any(axis=1)]\n",
    "if len(null_rows) > 0:\n",
    "    display(null_rows.head(10))\n",
    "else:\n",
    "    print(\"No null values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MISSING VALUES TREATMENT\n",
      "============================================================\n",
      "\n",
      "No null values to handle.\n",
      "\n",
      "Remaining null values: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HANDLE MISSING VALUES - STRATEGY BY COLUMN\n",
    "# =============================================================================\n",
    "\n",
    "# Create a working copy\n",
    "df_clean =  df.copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES TREATMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Strategy for each column type:\n",
    "# - Numerical: impute with median (robust to outliers)\n",
    "# - Categorical: impute with mode or 'Unknown'\n",
    "# - Critical fields: drop rows if null\n",
    "\n",
    "# Check which columns have nulls\n",
    "columns_with_nulls = df_clean.columns[df_clean.isnull().any()].tolist()\n",
    "\n",
    "if len(columns_with_nulls) > 0:\n",
    "    print(f\"\\nColumns with null values: {columns_with_nulls}\")\n",
    "    \n",
    "    for col in columns_with_nulls:\n",
    "        null_count = df_clean[col].isnull().sum()\n",
    "        \n",
    "        if df_clean[col].dtype in ['int64', 'float64']:\n",
    "            # Numerical: impute with median\n",
    "            median_val = df_clean[col].median()\n",
    "            df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            print(f\"  - {col}: Imputed {null_count} nulls with median ({median_val:.2f})\")\n",
    "        else:\n",
    "            # Categorical: impute with mode\n",
    "            mode_val = df_clean[col].mode()[0] if len(df_clean[col].mode()) > 0 else 'Unknown'\n",
    "            df_clean[col] = df_clean[col].fillna(mode_val)\n",
    "            print(f\"  - {col}: Imputed {null_count} nulls with mode ('{mode_val}')\")\n",
    "else:\n",
    "    print(\"\\nNo null values to handle.\")\n",
    "\n",
    "# Verify no nulls remain\n",
    "print(f\"\\nRemaining null values: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Detect Outliers - IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OUTLIER DETECTION - IQR METHOD\n",
      "============================================================\n",
      "\n",
      "QUANTITY:\n",
      "  Q1: 1.00, Q3: 3.00, IQR: 2.00\n",
      "  Bounds: [-2.00, 6.00]\n",
      "  Outliers found: 1\n",
      "  Values: [50]\n",
      "\n",
      "UNIT_PRICE:\n",
      "  Q1: 10,600.00, Q3: 19,990.00, IQR: 9,390.00\n",
      "  Bounds: [-3,485.00, 34,075.00]\n",
      "  Outliers found: 10\n",
      "  Values: [34235, 34260, 34659, 34209, 34755, 34809, 299900, 34766, 34146, 34274]\n",
      "\n",
      "SUBTOTAL:\n",
      "  Q1: 12,990.00, Q3: 39,033.50, IQR: 26,043.50\n",
      "  Bounds: [-26,075.25, 78,098.75]\n",
      "  Outliers found: 52\n",
      "\n",
      "PLATFORM_FEE:\n",
      "  Q1: 933.60, Q3: 4,148.95, IQR: 3,215.35\n",
      "  Bounds: [-3,889.44, 8,971.98]\n",
      "  Outliers found: 57\n",
      "\n",
      "TOTAL_AMOUNT:\n",
      "  Q1: 16,564.75, Q3: 39,525.00, IQR: 22,960.25\n",
      "  Bounds: [-17,875.62, 73,965.38]\n",
      "  Outliers found: 58\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OUTLIER DETECTION - IQR METHOD\n",
    "# =============================================================================\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"\n",
    "    Detect outliers using the IQR method.\n",
    "    \n",
    "    Outliers are values below Q1 - 1.5*IQR or above Q3 + 1.5*IQR.\n",
    "    \n",
    "    Parameters:\n",
    "        data: DataFrame\n",
    "        column: Column name to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with outlier statistics\n",
    "    \"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_mask = (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "    outliers = data[outliers_mask]\n",
    "    \n",
    "    return {\n",
    "        'column': column,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound,\n",
    "        'n_outliers': len(outliers),\n",
    "        'outlier_indices': outliers.index.tolist(),\n",
    "        'outlier_values': outliers[column].tolist()\n",
    "    }\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OUTLIER DETECTION - IQR METHOD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Numerical columns to check for outliers\n",
    "numerical_cols = ['quantity', 'unit_price', 'subtotal', 'shipping_cost', 'platform_fee', 'total_amount']\n",
    "\n",
    "outlier_results = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    result = detect_outliers_iqr(df_clean, col)\n",
    "    outlier_results.append(result)\n",
    "    \n",
    "    if result['n_outliers'] > 0:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(f\"  Q1: {result['Q1']:,.2f}, Q3: {result['Q3']:,.2f}, IQR: {result['IQR']:,.2f}\")\n",
    "        print(f\"  Bounds: [{result['lower_bound']:,.2f}, {result['upper_bound']:,.2f}]\")\n",
    "        print(f\"  Outliers found: {result['n_outliers']}\")\n",
    "        if result['n_outliers'] <= 10:\n",
    "            print(f\"  Values: {result['outlier_values']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Detect Outliers - Z-Score Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OUTLIER DETECTION - Z-SCORE METHOD (threshold=3)\n",
      "============================================================\n",
      "\n",
      "QUANTITY:\n",
      "  Mean: 1.95, Std: 1.72\n",
      "  Outliers found: 1\n",
      "  Values: [50]\n",
      "  Z-scores: ['27.95']\n",
      "\n",
      "UNIT_PRICE:\n",
      "  Mean: 15,364.79, Std: 11,220.78\n",
      "  Outliers found: 1\n",
      "  Values: [299900]\n",
      "  Z-scores: ['25.36']\n",
      "\n",
      "SUBTOTAL:\n",
      "  Mean: 29,108.78, Std: 24,177.43\n",
      "  Outliers found: 20\n",
      "\n",
      "PLATFORM_FEE:\n",
      "  Mean: 3,120.51, Std: 2,999.54\n",
      "  Outliers found: 25\n",
      "\n",
      "TOTAL_AMOUNT:\n",
      "  Mean: 31,688.89, Std: 23,050.42\n",
      "  Outliers found: 20\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OUTLIER DETECTION - Z-SCORE METHOD\n",
    "# =============================================================================\n",
    "\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect outliers using the Z-score method.\n",
    "    \n",
    "    Outliers are values with |Z-score| > threshold (typically 3).\n",
    "    \n",
    "    Parameters:\n",
    "        data: DataFrame\n",
    "        column: Column name to analyze\n",
    "        threshold: Z-score threshold (default=3)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with outlier statistics\n",
    "    \"\"\"\n",
    "    mean_val = data[column].mean()\n",
    "    std_val = data[column].std()\n",
    "    \n",
    "    z_scores = np.abs((data[column] - mean_val) / std_val)\n",
    "    outliers_mask = z_scores > threshold\n",
    "    outliers = data[outliers_mask]\n",
    "    \n",
    "    return {\n",
    "        'column': column,\n",
    "        'mean': mean_val,\n",
    "        'std': std_val,\n",
    "        'threshold': threshold,\n",
    "        'n_outliers': len(outliers),\n",
    "        'outlier_indices': outliers.index.tolist(),\n",
    "        'outlier_values': outliers[column].tolist(),\n",
    "        'z_scores': z_scores[outliers_mask].tolist()\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER DETECTION - Z-SCORE METHOD (threshold=3)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "zscore_results = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    result = detect_outliers_zscore(df_clean, col)\n",
    "    zscore_results.append(result)\n",
    "    \n",
    "    if result['n_outliers'] > 0:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(f\"  Mean: {result['mean']:,.2f}, Std: {result['std']:,.2f}\")\n",
    "        print(f\"  Outliers found: {result['n_outliers']}\")\n",
    "        if result['n_outliers'] <= 10:\n",
    "            print(f\"  Values: {result['outlier_values']}\")\n",
    "            print(f\"  Z-scores: {[f'{z:.2f}' for z in result['z_scores']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Compare IQR vs Z-Score Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARISON: IQR VS Z-SCORE METHODS\n",
      "============================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>IQR Outliers</th>\n",
       "      <th>Z-Score Outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quantity</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unit_price</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subtotal</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shipping_cost</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>platform_fee</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_amount</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column  IQR Outliers  Z-Score Outliers\n",
       "0       quantity             1                 1\n",
       "1     unit_price            10                 1\n",
       "2       subtotal            52                20\n",
       "3  shipping_cost             0                 0\n",
       "4   platform_fee            57                25\n",
       "5   total_amount            58                20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interpretation ---\n",
      "IQR method is more conservative and detects more outliers in skewed distributions.\n",
      "Z-Score method assumes normal distribution and is more lenient.\n",
      "For business data with potential extreme values, IQR is often preferred.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPARISON: IQR VS Z-SCORE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: IQR VS Z-SCORE METHODS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_data = []\n",
    "for iqr_res, zscore_res in zip(outlier_results, zscore_results):\n",
    "    comparison_data.append({\n",
    "        'Column': iqr_res['column'],\n",
    "        'IQR Outliers': iqr_res['n_outliers'],\n",
    "        'Z-Score Outliers': zscore_res['n_outliers']\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "display(df_comparison)\n",
    "\n",
    "print(\"\\n--- Interpretation ---\")\n",
    "print(\"IQR method is more conservative and detects more outliers in skewed distributions.\")\n",
    "print(\"Z-Score method assumes normal distribution and is more lenient.\")\n",
    "print(\"For business data with potential extreme values, IQR is often preferred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Treat Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OUTLIER TREATMENT STRATEGY\n",
      "============================================================\n",
      "\n",
      "1. Unit prices > 100,000 CLP: 1 found\n",
      "   Capping at 99th percentile: 33,852 CLP\n",
      "\n",
      "2. Bulk orders (quantity > 20): 1 found\n",
      "   Flagged as bulk orders (not removed)\n",
      "\n",
      "3. Rows with negative values: 0 found\n",
      "\n",
      "Final dataset size: 1192 rows\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OUTLIER TREATMENT - BUSINESS DECISION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OUTLIER TREATMENT STRATEGY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Business rules for outlier treatment:\n",
    "# 1. unit_price > 100,000 CLP: Likely data entry error ‚Üí cap at 99th percentile\n",
    "# 2. quantity > 20: Unusual but possible (bulk order) ‚Üí keep but flag\n",
    "# 3. Negative values: Invalid ‚Üí set to 0 or remove\n",
    "\n",
    "df_treated = df_clean.copy()\n",
    "\n",
    "# Convert numeric columns to float for calculations\n",
    "numeric_cols = ['unit_price', 'subtotal', 'shipping_cost', 'platform_fee', 'total_amount']\n",
    "df_treated[numeric_cols] = df_treated[numeric_cols].astype(float)\n",
    "\n",
    "# 1. Cap extreme unit prices\n",
    "price_cap = df_treated['unit_price'].quantile(0.99)\n",
    "extreme_prices = df_treated['unit_price'] > 100000\n",
    "print(f\"\\n1. Unit prices > 100,000 CLP: {extreme_prices.sum()} found\")\n",
    "if extreme_prices.sum() > 0:\n",
    "    print(f\"   Capping at 99th percentile: {price_cap:,.0f} CLP\")\n",
    "    df_treated.loc[extreme_prices, 'unit_price'] = price_cap\n",
    "    # Recalculate dependent columns\n",
    "    df_treated.loc[extreme_prices, 'subtotal'] = df_treated.loc[extreme_prices, 'unit_price'] * df_treated.loc[extreme_prices, 'quantity']\n",
    "    df_treated.loc[extreme_prices, 'total_amount'] = df_treated.loc[extreme_prices, 'subtotal'] + df_treated.loc[extreme_prices, 'shipping_cost']\n",
    "\n",
    "# 2. Flag bulk orders (quantity > 20)\n",
    "bulk_orders = df_treated['quantity'] > 20\n",
    "print(f\"\\n2. Bulk orders (quantity > 20): {bulk_orders.sum()} found\")\n",
    "df_treated['is_bulk_order'] = bulk_orders\n",
    "if bulk_orders.sum() > 0:\n",
    "    print(f\"   Flagged as bulk orders (not removed)\")\n",
    "\n",
    "# 3. Check for negative values\n",
    "negative_amounts = (df_treated[numerical_cols] < 0).any(axis=1)\n",
    "print(f\"\\n3. Rows with negative values: {negative_amounts.sum()} found\")\n",
    "if negative_amounts.sum() > 0:\n",
    "    print(f\"   Removing invalid rows...\")\n",
    "    df_treated = df_treated[~negative_amounts]\n",
    "\n",
    "print(f\"\\nFinal dataset size: {len(df_treated)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Document Cleaning Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY REPORT\n",
      "============================================================\n",
      "\n",
      "--- Before Cleaning ---\n",
      "Total rows: 1192\n",
      "Rows with nulls: 0\n",
      "\n",
      "--- After Cleaning ---\n",
      "Total rows: 1192\n",
      "Rows with nulls: 0\n",
      "Rows removed: 0\n",
      "\n",
      "--- Cleaning Actions Taken ---\n",
      "1. Missing values: Imputed with median (numerical) or mode (categorical)\n",
      "2. Extreme unit prices (>100k): Capped at 99th percentile\n",
      "3. Bulk orders (qty>20): Flagged but retained\n",
      "4. Negative values: Removed\n",
      "\n",
      "--- Final Data Statistics ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>170.283557</td>\n",
       "      <td>2023-12-10 08:26:10.469798</td>\n",
       "      <td>1.952181</td>\n",
       "      <td>15141.591032</td>\n",
       "      <td>28913.979044</td>\n",
       "      <td>2746.644295</td>\n",
       "      <td>3120.508221</td>\n",
       "      <td>31498.710587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3010.000000</td>\n",
       "      <td>3039.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149.700000</td>\n",
       "      <td>4490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.750000</td>\n",
       "      <td>2023-06-06 18:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10600.000000</td>\n",
       "      <td>12990.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>933.595000</td>\n",
       "      <td>16564.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>2023-11-16 12:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13712.500000</td>\n",
       "      <td>22784.500000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1973.400000</td>\n",
       "      <td>26333.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>294.000000</td>\n",
       "      <td>2024-06-06 06:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19990.000000</td>\n",
       "      <td>39033.500000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>4148.950000</td>\n",
       "      <td>39525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>2025-01-30 00:00:00</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>34809.000000</td>\n",
       "      <td>249500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>17087.720000</td>\n",
       "      <td>249500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>151.641979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.719224</td>\n",
       "      <td>7626.682639</td>\n",
       "      <td>22895.252444</td>\n",
       "      <td>2063.941469</td>\n",
       "      <td>2999.539522</td>\n",
       "      <td>21733.205422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id            transaction_date     quantity    unit_price  \\\n",
       "count  1192.000000                        1192  1192.000000   1192.000000   \n",
       "mean    170.283557  2023-12-10 08:26:10.469798     1.952181  15141.591032   \n",
       "min       1.000000         2023-01-01 00:00:00     1.000000   3010.000000   \n",
       "25%      44.750000         2023-06-06 18:00:00     1.000000  10600.000000   \n",
       "50%      98.000000         2023-11-16 12:00:00     2.000000  13712.500000   \n",
       "75%     294.000000         2024-06-06 06:00:00     3.000000  19990.000000   \n",
       "max     500.000000         2025-01-30 00:00:00    50.000000  34809.000000   \n",
       "std     151.641979                         NaN     1.719224   7626.682639   \n",
       "\n",
       "            subtotal  shipping_cost  platform_fee   total_amount  \n",
       "count    1192.000000    1192.000000   1192.000000    1192.000000  \n",
       "mean    28913.979044    2746.644295   3120.508221   31498.710587  \n",
       "min      3039.000000       0.000000    149.700000    4490.000000  \n",
       "25%     12990.000000       0.000000    933.595000   16564.750000  \n",
       "50%     22784.500000    3500.000000   1973.400000   26333.500000  \n",
       "75%     39033.500000    3500.000000   4148.950000   39525.000000  \n",
       "max    249500.000000    5500.000000  17087.720000  249500.000000  \n",
       "std     22895.252444    2063.941469   2999.539522   21733.205422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA QUALITY REPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- Before Cleaning ---\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Rows with nulls: { df_treated.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "print(\"\\n--- After Cleaning ---\")\n",
    "print(f\"Total rows: {len(df_treated)}\")\n",
    "print(f\"Rows with nulls: {df_treated.isnull().any(axis=1).sum()}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_treated)}\")\n",
    "\n",
    "print(\"\\n--- Cleaning Actions Taken ---\")\n",
    "print(\"1. Missing values: Imputed with median (numerical) or mode (categorical)\")\n",
    "print(\"2. Extreme unit prices (>100k): Capped at 99th percentile\")\n",
    "print(\"3. Bulk orders (qty>20): Flagged but retained\")\n",
    "print(\"4. Negative values: Removed\")\n",
    "\n",
    "print(\"\\n--- Final Data Statistics ---\")\n",
    "display(df_treated.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved:\n",
      "  - transactions_cleaned.csv (1192 rows)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE CLEANED DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "# Save to raw folder (still part of the cleaning process)\n",
    "df_treated.to_csv('../data/raw/transactions_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Cleaned data saved:\")\n",
    "print(f\"  - transactions_cleaned.csv ({len(df_treated)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Lesson 4 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ Identified null values using `.isnull()` and created a summary report\n",
    "2. ‚úÖ Applied imputation strategies: median for numerical, mode for categorical\n",
    "3. ‚úÖ Detected outliers using IQR method with bounds [Q1-1.5*IQR, Q3+1.5*IQR]\n",
    "4. ‚úÖ Detected outliers using Z-score method with threshold=3\n",
    "5. ‚úÖ Compared both methods and documented differences\n",
    "6. ‚úÖ Applied business rules for outlier treatment (cap, flag, remove)\n",
    "7. ‚úÖ Created a data quality report documenting all decisions\n",
    "8. ‚úÖ Saved cleaned dataset\n",
    "\n",
    "**Key Pandas/NumPy methods used:**\n",
    "\n",
    "- `.isnull()`, `.isna()` - Identify nulls\n",
    "- `.fillna()` - Impute missing values\n",
    "- `.quantile()` - Calculate percentiles for IQR\n",
    "- `.mean()`, `.std()` - For Z-score calculation\n",
    "- Boolean indexing for filtering outliers\n",
    "\n",
    "**Business decisions documented:**\n",
    "\n",
    "- Extreme prices (>100k CLP): Likely errors ‚Üí capped\n",
    "- Bulk orders (qty>20): Valid but unusual ‚Üí flagged\n",
    "- Negative values: Invalid ‚Üí removed\n",
    "\n",
    "**Impact on data quality:**\n",
    "\n",
    "- Null values eliminated: 100%\n",
    "- Extreme values corrected: preserves data while limiting distortion\n",
    "- New feature created: `is_bulk_order` flag\n",
    "\n",
    "**Next step:** Lesson 5 - Apply Data Wrangling techniques for advanced transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 5: Data Wrangling\n",
    "\n",
    "**Objective:** Apply advanced data transformation techniques including duplicate removal, data type conversion, custom functions, and feature engineering.\n",
    "\n",
    "### Project Evolution - NPS Discovery\n",
    "\n",
    "> *\"During data preparation, exploratory analysis revealed that customer feedback could be consolidated into an NPS metric, which led us to refine the business objective.\"*\n",
    "\n",
    "This lesson incorporates NPS survey data discovered during the project, demonstrating how real-world data science projects evolve iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded for Lesson 5\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"Libraries loaded for Lesson 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1192 transactions\n",
      "Transactions loaded: 1192 rows\n",
      "Customers loaded: 500 rows\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD CLEANED DATA FROM LESSON 4\n",
    "# =============================================================================\n",
    "\n",
    "df_treated = pd.read_csv('../data/raw/transactions_cleaned.csv')\n",
    "df_treated['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "\n",
    "print(f\"Loaded {len(df_treated)} transactions\")\n",
    "\n",
    "# Load customers data\n",
    "df_customers = pd.read_csv('../data/raw/customers_preliminary.csv')\n",
    "df_customers['registration_date'] = pd.to_datetime(df_customers['registration_date'])\n",
    "\n",
    "print(f\"Transactions loaded: {len(df)} rows\")\n",
    "print(f\"Customers loaded: {len(df_customers)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Generate NPS Survey Data (New Discovery)\n",
    "\n",
    "**Business Context:** During exploratory analysis, we discovered that customer satisfaction surveys existed but were not integrated. This data enables NPS calculation and customer-aware strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS Survey data generated: 235 responses\n",
      "\n",
      "NPS Score distribution:\n",
      "nps_score\n",
      "0      7\n",
      "1      6\n",
      "2     10\n",
      "3      7\n",
      "4      4\n",
      "5      6\n",
      "6      7\n",
      "7     34\n",
      "8     36\n",
      "9     63\n",
      "10    55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GENERATE NPS SURVEY DATA\n",
    "# =============================================================================\n",
    "# Simulating discovery of existing survey data\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Get unique customers who made purchases\n",
    "active_customers = df_treated['customer_id'].unique()\n",
    "\n",
    "# Assume 60% of customers responded to NPS survey\n",
    "n_respondents = int(len(active_customers) * 0.6)\n",
    "survey_customers = np.random.choice(active_customers, size=n_respondents, replace=False)\n",
    "\n",
    "# Generate NPS scores (0-10)\n",
    "# Distribution: ~20% Detractors (0-6), ~30% Passives (7-8), ~50% Promoters (9-10)\n",
    "nps_scores = np.concatenate([\n",
    "    np.random.randint(0, 7, size=int(n_respondents * 0.20)),    # Detractors\n",
    "    np.random.randint(7, 9, size=int(n_respondents * 0.30)),    # Passives\n",
    "    np.random.randint(9, 11, size=n_respondents - int(n_respondents * 0.20) - int(n_respondents * 0.30))  # Promoters\n",
    "])\n",
    "np.random.shuffle(nps_scores)\n",
    "\n",
    "# Survey dates (within last 6 months)\n",
    "base_date = datetime(2024, 7, 1)\n",
    "survey_dates = [base_date + timedelta(days=np.random.randint(0, 180)) for _ in range(n_respondents)]\n",
    "\n",
    "# Create NPS DataFrame\n",
    "df_nps = pd.DataFrame({\n",
    "    'customer_id': survey_customers,\n",
    "    'nps_score': nps_scores[:n_respondents],\n",
    "    'survey_date': survey_dates\n",
    "})\n",
    "\n",
    "print(f\"NPS Survey data generated: {len(df_nps)} responses\")\n",
    "print(f\"\\nNPS Score distribution:\")\n",
    "print(df_nps['nps_score'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 NPS Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NPS CALCULATION\n",
      "============================================================\n",
      "\n",
      "Category distribution:\n",
      "nps_category\n",
      "Promoter     118\n",
      "Passive       70\n",
      "Detractor     47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Promoters: 50.2%\n",
      "Detractors: 20.0%\n",
      "\n",
      ">>> NPS Score: 30.2 <<<\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLASSIFY NPS RESPONDENTS\n",
    "# =============================================================================\n",
    "\n",
    "def classify_nps(score):\n",
    "    \"\"\"\n",
    "    Classify customer based on NPS score.\n",
    "    \n",
    "    Parameters:\n",
    "        score: NPS score (0-10)\n",
    "    \n",
    "    Returns:\n",
    "        Classification: Promoter, Passive, or Detractor\n",
    "    \"\"\"\n",
    "    if score >= 9:\n",
    "        return 'Promoter'\n",
    "    elif score >= 7:\n",
    "        return 'Passive'\n",
    "    else:\n",
    "        return 'Detractor'\n",
    "\n",
    "# Apply classification\n",
    "df_nps['nps_category'] = df_nps['nps_score'].apply(classify_nps)\n",
    "\n",
    "# Calculate NPS\n",
    "nps_counts = df_nps['nps_category'].value_counts()\n",
    "promoters_pct = nps_counts.get('Promoter', 0) / len(df_nps) * 100\n",
    "detractors_pct = nps_counts.get('Detractor', 0) / len(df_nps) * 100\n",
    "nps_score_final = promoters_pct - detractors_pct\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NPS CALCULATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCategory distribution:\")\n",
    "print(nps_counts)\n",
    "print(f\"\\nPromoters: {promoters_pct:.1f}%\")\n",
    "print(f\"Detractors: {detractors_pct:.1f}%\")\n",
    "print(f\"\\n>>> NPS Score: {nps_score_final:.1f} <<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Merge NPS with Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers enriched with NPS data\n",
      "\n",
      "NPS Response status:\n",
      "nps_category\n",
      "No Response    265\n",
      "Promoter       118\n",
      "Passive         70\n",
      "Detractor       47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MERGE NPS DATA WITH CUSTOMERS\n",
    "# =============================================================================\n",
    "\n",
    "# Merge NPS with customers\n",
    "df_customers_enriched = df_customers.merge(\n",
    "    df_nps[['customer_id', 'nps_score', 'nps_category']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing NPS (customers who didn't respond)\n",
    "df_customers_enriched['nps_category'] = df_customers_enriched['nps_category'].fillna('No Response')\n",
    "\n",
    "print(\"Customers enriched with NPS data\")\n",
    "print(f\"\\nNPS Response status:\")\n",
    "print(df_customers_enriched['nps_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Data Wrangling - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUPLICATE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Exact duplicate rows: 0\n",
      "Duplicate transaction IDs: 0\n",
      "\n",
      "No duplicates to remove\n",
      "\n",
      "Final transaction count: 1192\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CHECK AND REMOVE DUPLICATES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DUPLICATE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for exact duplicates\n",
    "exact_duplicates =  df_treated.duplicated().sum()\n",
    "print(f\"\\nExact duplicate rows: {exact_duplicates}\")\n",
    "\n",
    "# Check for duplicate transaction IDs\n",
    "duplicate_ids = df['transaction_id'].duplicated().sum()\n",
    "print(f\"Duplicate transaction IDs: {duplicate_ids}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "if exact_duplicates > 0:\n",
    "    df =  df_treated.drop_duplicates()\n",
    "    print(f\"\\nRemoved {exact_duplicates} duplicate rows\")\n",
    "else:\n",
    "    print(\"\\nNo duplicates to remove\")\n",
    "\n",
    "print(f\"\\nFinal transaction count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Data Wrangling - Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA TYPE OPTIMIZATION\n",
      "============================================================\n",
      "\n",
      "Before optimization:\n",
      "transaction_id                 str\n",
      "customer_id                  int64\n",
      "transaction_date    datetime64[us]\n",
      "platform                       str\n",
      "product                        str\n",
      "quantity                     int64\n",
      "unit_price                 float64\n",
      "subtotal                   float64\n",
      "shipping_cost              float64\n",
      "platform_fee               float64\n",
      "total_amount               float64\n",
      "is_bulk_order                 bool\n",
      "dtype: object\n",
      "\n",
      "After optimization:\n",
      "transaction_id                 str\n",
      "customer_id                  int64\n",
      "transaction_date    datetime64[us]\n",
      "platform                  category\n",
      "product                   category\n",
      "quantity                     int64\n",
      "unit_price                 float64\n",
      "subtotal                   float64\n",
      "shipping_cost              float64\n",
      "platform_fee               float64\n",
      "total_amount               float64\n",
      "is_bulk_order                 bool\n",
      "dtype: object\n",
      "\n",
      "Memory usage: 141.0 KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA TYPE OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA TYPE OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nBefore optimization:\")\n",
    "print(df_treated.dtypes)\n",
    "\n",
    "# Convert categorical columns\n",
    "categorical_cols = ['platform', 'product']\n",
    "for col in categorical_cols:\n",
    "    df_treated[col] = df_treated[col].astype('category')\n",
    "\n",
    "# Convert boolean\n",
    "df_treated['is_bulk_order'] = df_treated['is_bulk_order'].astype(bool)\n",
    "\n",
    "print(\"\\nAfter optimization:\")\n",
    "print(df_treated.dtypes)\n",
    "\n",
    "# Memory savings\n",
    "print(f\"\\nMemory usage: {df_treated.memory_usage(deep=True).sum() / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Feature Engineering - Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING - TIME FEATURES\n",
      "============================================================\n",
      "\n",
      "New time features created:\n",
      "  transaction_date  year  month  quarter  day_of_week  is_weekend  season\n",
      "0       2023-01-01  2023      1        1            6        True  Summer\n",
      "1       2023-01-01  2023      1        1            6        True  Summer\n",
      "2       2023-01-01  2023      1        1            6        True  Summer\n",
      "3       2023-01-01  2023      1        1            6        True  Summer\n",
      "4       2023-01-03  2023      1        1            1       False  Summer\n",
      "5       2023-01-04  2023      1        1            2       False  Summer\n",
      "6       2023-01-04  2023      1        1            2       False  Summer\n",
      "7       2023-01-05  2023      1        1            3       False  Summer\n",
      "8       2023-01-07  2023      1        1            5        True  Summer\n",
      "9       2023-01-07  2023      1        1            5        True  Summer\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING - TIME-BASED FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - TIME FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract time components\n",
    "df_treated['year'] = df_treated['transaction_date'].dt.year\n",
    "df_treated['month'] = df_treated['transaction_date'].dt.month\n",
    "df_treated['quarter'] = df_treated['transaction_date'].dt.quarter\n",
    "df_treated['day_of_week'] = df_treated['transaction_date'].dt.dayofweek\n",
    "df_treated['is_weekend'] = df_treated['day_of_week'].isin([5, 6])\n",
    "\n",
    "# Season (Chilean seasons - Southern Hemisphere)\n",
    "def get_season(month):\n",
    "    \"\"\"Get Chilean season based on month.\"\"\"\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Summer'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Fall'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Winter'\n",
    "    else:\n",
    "        return 'Spring'\n",
    "\n",
    "df_treated['season'] = df_treated['month'].apply(get_season)\n",
    "\n",
    "print(\"\\nNew time features created:\")\n",
    "print(df_treated[['transaction_date', 'year', 'month', 'quarter', 'day_of_week', 'is_weekend', 'season']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Feature Engineering - Customer Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING - CUSTOMER METRICS\n",
      "============================================================\n",
      "\n",
      "Customer metrics calculated for 392 customers\n",
      "reference_date usado: 2025-01-30 00:00:00\n",
      "last_purchase max: 2025-01-30 00:00:00\n",
      "Diferencia en d√≠as: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING - CUSTOMER METRICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - CUSTOMER METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate customer-level metrics\n",
    "customer_metrics = df_treated.groupby('customer_id').agg({\n",
    "    'transaction_id': 'count',\n",
    "    'total_amount': ['sum', 'mean'],\n",
    "    'transaction_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "customer_metrics.columns = [\n",
    "    'customer_id', 'total_transactions', 'total_revenue', \n",
    "    'avg_ticket', 'first_purchase', 'last_purchase'\n",
    "]\n",
    "\n",
    "# Calculate days since last purchase (for churn analysis)\n",
    "reference_date = df_treated['transaction_date'].max()\n",
    "customer_metrics['days_since_last_purchase'] = (\n",
    "    reference_date - customer_metrics['last_purchase']\n",
    ").dt.days\n",
    "\n",
    "# Calculate customer tenure\n",
    "customer_metrics['tenure_days'] = (\n",
    "    customer_metrics['last_purchase'] - customer_metrics['first_purchase']\n",
    ").dt.days\n",
    "\n",
    "print(f\"\\nCustomer metrics calculated for {len(customer_metrics)} customers\")\n",
    "customer_metrics.head(10)\n",
    "\n",
    "print(f\"reference_date usado: {df_treated['transaction_date'].max()}\")\n",
    "print(f\"last_purchase max: {customer_metrics['last_purchase'].max()}\")\n",
    "print(f\"Diferencia en d√≠as: {(df_treated['transaction_date'].max() - customer_metrics['last_purchase'].max()).days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Retargeting Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RETARGETING SEGMENTS\n",
      "============================================================\n",
      "\n",
      "Retargeting segment distribution:\n",
      "retargeting_segment\n",
      "Dormant    207\n",
      "Active      97\n",
      "At Risk     88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage:\n",
      "retargeting_segment\n",
      "Dormant    52.8\n",
      "Active     24.7\n",
      "At Risk    22.4\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RETARGETING SEGMENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RETARGETING SEGMENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define segment thresholds\n",
    "DORMANT_DAYS = 180    # 6 months\n",
    "AT_RISK_DAYS = 90     # 3 months\n",
    "\n",
    "def assign_retargeting_segment(row):\n",
    "    \"\"\"\n",
    "    Assign retargeting segment based on purchase recency.\n",
    "    \n",
    "    Segments:\n",
    "    - Active: Purchased within 60 days\n",
    "    - At Risk: 60-90 days since purchase\n",
    "    - Dormant: 90+ days since purchase\n",
    "    \"\"\"\n",
    "    days = row['days_since_last_purchase']\n",
    "    if days <= AT_RISK_DAYS:\n",
    "        return 'Active'\n",
    "    elif days <= DORMANT_DAYS:\n",
    "        return 'At Risk'\n",
    "    else:\n",
    "        return 'Dormant'\n",
    "\n",
    "customer_metrics['retargeting_segment'] = customer_metrics.apply(assign_retargeting_segment, axis=1)\n",
    "\n",
    "print(\"\\nRetargeting segment distribution:\")\n",
    "segment_counts = customer_metrics['retargeting_segment'].value_counts()\n",
    "print(segment_counts)\n",
    "\n",
    "print(\"\\nPercentage:\")\n",
    "print((segment_counts / len(customer_metrics) * 100).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.10 Merge All Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL CUSTOMER DATASET\n",
      "============================================================\n",
      "\n",
      "Total customers: 500\n",
      "Columns: ['customer_id', 'registration_date', 'region', 'acquisition_channel', 'nps_score', 'nps_category', 'total_transactions', 'total_revenue', 'avg_ticket', 'first_purchase', 'last_purchase', 'days_since_last_purchase', 'tenure_days', 'retargeting_segment', 'is_high_value', 'priority_winback']\n",
      "\n",
      "High-value customers: 98\n",
      "Priority win-back targets: 39\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MERGE ALL CUSTOMER DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Merge customer metrics with enriched customer data\n",
    "df_customers_final = df_customers_enriched.merge(\n",
    "    customer_metrics,\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create high-value flag\n",
    "revenue_threshold = df_customers_final['total_revenue'].quantile(0.75)\n",
    "df_customers_final['is_high_value'] = df_customers_final['total_revenue'] >= revenue_threshold\n",
    "\n",
    "# High Value + Dormant = Priority for win-back\n",
    "df_customers_final['priority_winback'] = (\n",
    "    (df_customers_final['is_high_value'] == True) & \n",
    "    (df_customers_final['retargeting_segment'] == 'Dormant')\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL CUSTOMER DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal customers: {len(df_customers_final)}\")\n",
    "print(f\"Columns: {list(df_customers_final.columns)}\")\n",
    "\n",
    "print(f\"\\nHigh-value customers: {df_customers_final['is_high_value'].sum()}\")\n",
    "print(f\"Priority win-back targets: {df_customers_final['priority_winback'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.11 Save Wrangled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrangled data saved:\n",
      "  - transactions_wrangled.csv (1192 rows)\n",
      "  - customers_wrangled.csv (500 rows)\n",
      "  - nps_surveys.csv (235 rows)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE WRANGLED DATAFRAMES\n",
    "# =============================================================================\n",
    "\n",
    "# Save to raw folder\n",
    "df_treated.to_csv('../data/raw/transactions_wrangled.csv', index=False)\n",
    "df_customers_final.to_csv('../data/raw/customers_wrangled.csv', index=False)\n",
    "df_nps.to_csv('../data/raw/nps_surveys.csv', index=False)\n",
    "\n",
    "print(\"Wrangled data saved:\")\n",
    "print(f\"  - transactions_wrangled.csv ({len(df_treated)} rows)\")\n",
    "print(f\"  - customers_wrangled.csv ({len(df_customers_final)} rows)\")\n",
    "print(f\"  - nps_surveys.csv ({len(df_nps)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.12 Lesson 5 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ Discovered and integrated NPS survey data (project evolution)\n",
    "2. ‚úÖ Classified customers by NPS: Promoter, Passive, Detractor\n",
    "3. ‚úÖ Calculated overall NPS score\n",
    "4. ‚úÖ Checked and handled duplicates\n",
    "5. ‚úÖ Optimized data types (categorical, boolean)\n",
    "6. ‚úÖ Created time-based features (year, month, quarter, season)\n",
    "7. ‚úÖ Calculated customer metrics (total transactions, revenue, avg ticket)\n",
    "8. ‚úÖ Created retargeting segments (Active, At Risk, Dormant)\n",
    "9. ‚úÖ Identified high-value customers and priority win-back targets\n",
    "\n",
    "**Key Pandas methods used:**\n",
    "\n",
    "- `.apply()` - Apply custom functions\n",
    "- `.merge()` - Join DataFrames\n",
    "- `.duplicated()`, `.drop_duplicates()` - Handle duplicates\n",
    "- `.astype()` - Convert data types\n",
    "- `.dt` accessor - Extract datetime components\n",
    "- `.groupby().agg()` - Calculate aggregated metrics\n",
    "- `.fillna()` - Handle missing values\n",
    "\n",
    "**Business value created:**\n",
    "\n",
    "- NPS metric enables customer satisfaction tracking\n",
    "- Retargeting segments enable targeted marketing actions\n",
    "- High-value + Dormant identification enables prioritized win-back campaigns\n",
    "\n",
    "**Next step:** Lesson 6 - Apply groupby and pivot operations to calculate final business metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 6: Grouping and Pivoting\n",
    "\n",
    "**Objective:** Apply groupby and pivot operations to calculate final business metrics including NPS by segment, CAC, Customer Churn, and Revenue Churn.\n",
    "\n",
    "### Business Metrics to Calculate\n",
    "\n",
    "| Metric | Formula | Business Use |\n",
    "|--------|---------|-------------|\n",
    "| NPS by Segment | %Promoters - %Detractors | Customer satisfaction tracking |\n",
    "| CAC | Marketing Spend / New Customers | Marketing efficiency |\n",
    "| Customer Churn | Lost Customers / Total Active | Retention health |\n",
    "| Revenue Churn | Lost Revenue / Previous Revenue | Revenue stability |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded for Lesson 6\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries loaded for Lesson 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Load Wrangled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions: 1192 rows\n",
      "Customers: 500 rows\n",
      "NPS Surveys: 235 rows\n",
      "Marketing: 24 rows\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD WRANGLED DATA FROM LESSON 5\n",
    "# =============================================================================\n",
    "\n",
    "df_treated  = pd.read_csv('../data/raw/transactions_wrangled.csv')\n",
    "df_treated['transaction_date'] = pd.to_datetime(df_treated['transaction_date'])\n",
    "\n",
    "df_customers = pd.read_csv('../data/raw/customers_wrangled.csv')\n",
    "\n",
    "df_nps = pd.read_csv('../data/raw/nps_surveys.csv')\n",
    "\n",
    "# Load marketing data\n",
    "df_marketing = pd.read_csv('../data/raw/marketing_metrics.csv')\n",
    "\n",
    "print(f\"Transactions: {len(df_treated )} rows\")\n",
    "print(f\"Customers: {len(df_customers)} rows\")\n",
    "print(f\"NPS Surveys: {len(df_nps)} rows\")\n",
    "print(f\"Marketing: {len(df_marketing)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Revenue Analysis with groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REVENUE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Revenue by Platform ---\n",
      "              Total Revenue  Avg Ticket  Transactions\n",
      "platform                                             \n",
      "mercadolibre     29104160.0     32628.0           892\n",
      "shopify           8442303.0     28141.0           300\n",
      "\n",
      "--- Revenue by Product ---\n",
      "         Total Revenue  Avg Ticket  Transactions  Units Sold\n",
      "product                                                     \n",
      "jackets     10608062.0     48218.0           220         407\n",
      "pajamas      6653822.0     38022.0           175         338\n",
      "shorts       6110060.0     30398.0           201         400\n",
      "tshirts      5533120.0     27257.0           203         390\n",
      "towels       5190358.0     28056.0           185         391\n",
      "socks        3451041.0     16592.0           208         401\n",
      "\n",
      "--- Revenue by Season ---\n",
      "        Total Revenue  Avg Ticket  Transactions\n",
      "season                                         \n",
      "Fall       10051154.0     32955.0           305\n",
      "Spring      8476145.0     30164.0           281\n",
      "Summer      9299674.0     30591.0           304\n",
      "Winter      9719490.0     32184.0           302\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# REVENUE ANALYSIS BY DIMENSIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REVENUE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Revenue by platform\n",
    "revenue_by_platform = df_treated.groupby('platform').agg({\n",
    "    'total_amount': ['sum', 'mean', 'count']\n",
    "}).round(0)\n",
    "revenue_by_platform.columns = ['Total Revenue', 'Avg Ticket', 'Transactions']\n",
    "\n",
    "print(\"\\n--- Revenue by Platform ---\")\n",
    "print(revenue_by_platform)\n",
    "\n",
    "# Revenue by product\n",
    "revenue_by_product = df_treated.groupby('product').agg({\n",
    "    'total_amount': ['sum', 'mean', 'count'],\n",
    "    'quantity': 'sum'\n",
    "}).round(0)\n",
    "revenue_by_product.columns = ['Total Revenue', 'Avg Ticket', 'Transactions', 'Units Sold']\n",
    "revenue_by_product = revenue_by_product.sort_values('Total Revenue', ascending=False)\n",
    "\n",
    "print(\"\\n--- Revenue by Product ---\")\n",
    "print(revenue_by_product)\n",
    "\n",
    "# Revenue by season\n",
    "revenue_by_season = df_treated.groupby('season').agg({\n",
    "    'total_amount': ['sum', 'mean', 'count']\n",
    "}).round(0)\n",
    "revenue_by_season.columns = ['Total Revenue', 'Avg Ticket', 'Transactions']\n",
    "\n",
    "print(\"\\n--- Revenue by Season ---\")\n",
    "print(revenue_by_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 NPS by Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NPS ANALYSIS BY SEGMENT\n",
      "============================================================\n",
      "\n",
      "--- NPS by Acquisition Channel ---\n",
      "acquisition_channel\n",
      "google_ads          40.4\n",
      "organic             39.5\n",
      "instagram_ads       28.6\n",
      "mercadolibre_ads    28.6\n",
      "facebook_ads        11.4\n",
      "dtype: float64\n",
      "\n",
      "--- NPS by Region ---\n",
      "region\n",
      "OHiggins         54.5\n",
      "Maule            53.3\n",
      "Araucania        44.4\n",
      "Biobio           41.4\n",
      "Los Lagos        30.0\n",
      "Metropolitana    25.0\n",
      "Valparaiso       22.2\n",
      "Coquimbo        -10.0\n",
      "dtype: float64\n",
      "\n",
      "--- NPS by Retargeting Segment ---\n",
      "retargeting_segment\n",
      "Active     27.1\n",
      "At Risk    17.0\n",
      "Dormant    37.4\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NPS ANALYSIS BY SEGMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NPS ANALYSIS BY SEGMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Filter customers with NPS response\n",
    "df_with_nps = df_customers[df_customers['nps_category'] != 'No Response'].copy()\n",
    "\n",
    "# NPS by acquisition channel\n",
    "def calculate_nps(group):\n",
    "    \"\"\"Calculate NPS score for a group.\"\"\"\n",
    "    total = len(group)\n",
    "    promoters = (group['nps_category'] == 'Promoter').sum() / total * 100\n",
    "    detractors = (group['nps_category'] == 'Detractor').sum() / total * 100\n",
    "    return promoters - detractors\n",
    "\n",
    "# NPS by channel\n",
    "nps_by_channel = df_with_nps.groupby('acquisition_channel').apply(calculate_nps).round(1)\n",
    "nps_by_channel = nps_by_channel.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- NPS by Acquisition Channel ---\")\n",
    "print(nps_by_channel)\n",
    "\n",
    "# NPS by region\n",
    "nps_by_region = df_with_nps.groupby('region').apply(calculate_nps).round(1)\n",
    "nps_by_region = nps_by_region.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- NPS by Region ---\")\n",
    "print(nps_by_region)\n",
    "\n",
    "# NPS by retargeting segment\n",
    "nps_by_retargeting = df_with_nps.groupby('retargeting_segment').apply(calculate_nps).round(1)\n",
    "\n",
    "print(\"\\n--- NPS by Retargeting Segment ---\")\n",
    "print(nps_by_retargeting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 CAC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUSTOMER ACQUISITION COST (CAC)\n",
      "============================================================\n",
      "\n",
      "--- CAC by Channel ---\n",
      "         Channel  Spend (CLP)  New Customers  CAC (CLP)\n",
      "mercadolibre_ads       760000            138     5507.0\n",
      "      google_ads      2640000            104    25385.0\n",
      "    facebook_ads      3450000            103    33495.0\n",
      "   instagram_ads      3110000             74    42027.0\n",
      "\n",
      ">>> Overall CAC: $23,771 CLP <<<\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CUSTOMER ACQUISITION COST (CAC)\n",
    "# =============================================================================\n",
    "# Note: CAC was estimated using paid media spend only.\n",
    "# A production implementation would include sales team costs,\n",
    "# marketing tools, and attributed overhead.\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOMER ACQUISITION COST (CAC)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Marketing spend by channel\n",
    "marketing_spend = df_marketing.groupby('Channel')['Spend (CLP)'].sum()\n",
    "\n",
    "# Map marketing channels to acquisition channels\n",
    "channel_mapping = {\n",
    "    'Facebook': 'facebook_ads',\n",
    "    'Instagram': 'instagram_ads',\n",
    "    'Google': 'google_ads',\n",
    "    'MercadoLibre': 'mercadolibre_ads'\n",
    "}\n",
    "\n",
    "# Count new customers by channel\n",
    "customers_by_channel = df_customers.groupby('acquisition_channel').size()\n",
    "\n",
    "# Calculate CAC\n",
    "cac_data = []\n",
    "for mkt_channel, acq_channel in channel_mapping.items():\n",
    "    spend = marketing_spend.get(mkt_channel, 0)\n",
    "    customers = customers_by_channel.get(acq_channel, 0)\n",
    "    cac = spend / customers if customers > 0 else 0\n",
    "    cac_data.append({\n",
    "        'Channel': acq_channel,\n",
    "        'Spend (CLP)': spend,\n",
    "        'New Customers': customers,\n",
    "        'CAC (CLP)': round(cac, 0)\n",
    "    })\n",
    "\n",
    "df_cac = pd.DataFrame(cac_data)\n",
    "df_cac = df_cac.sort_values('CAC (CLP)')\n",
    "\n",
    "print(\"\\n--- CAC by Channel ---\")\n",
    "print(df_cac.to_string(index=False))\n",
    "\n",
    "# Overall CAC\n",
    "total_spend = df_cac['Spend (CLP)'].sum()\n",
    "total_customers = df_cac['New Customers'].sum()\n",
    "overall_cac = total_spend / total_customers if total_customers > 0 else 0\n",
    "\n",
    "print(f\"\\n>>> Overall CAC: ${overall_cac:,.0f} CLP <<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Churn Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHURN ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Customer Churn Metrics ---\n",
      "Total Customers: 500\n",
      "Active: 97 (19.4%)\n",
      "At Risk: 88 (17.6%)\n",
      "Dormant (Churned): 207 (41.4%)\n",
      "\n",
      ">>> Customer Churn Rate: 41.4% <<<\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CUSTOMER CHURN ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHURN ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Customer Churn (based on retargeting segments)\n",
    "# Dormant = Churned (no purchase in 90+ days)\n",
    "segment_counts = df_customers['retargeting_segment'].value_counts()\n",
    "\n",
    "total_customers = len(df_customers)\n",
    "dormant_customers = segment_counts.get('Dormant', 0)\n",
    "at_risk_customers = segment_counts.get('At Risk', 0)\n",
    "active_customers = segment_counts.get('Active', 0)\n",
    "\n",
    "customer_churn_rate = dormant_customers / total_customers * 100\n",
    "at_risk_rate = at_risk_customers / total_customers * 100\n",
    "\n",
    "print(\"\\n--- Customer Churn Metrics ---\")\n",
    "print(f\"Total Customers: {total_customers}\")\n",
    "print(f\"Active: {active_customers} ({active_customers/total_customers*100:.1f}%)\")\n",
    "print(f\"At Risk: {at_risk_customers} ({at_risk_rate:.1f}%)\")\n",
    "print(f\"Dormant (Churned): {dormant_customers} ({customer_churn_rate:.1f}%)\")\n",
    "\n",
    "print(f\"\\n>>> Customer Churn Rate: {customer_churn_rate:.1f}% <<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Revenue Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REVENUE CHURN\n",
      "============================================================\n",
      "\n",
      "--- Revenue by Quarter ---\n",
      "year_quarter\n",
      "2023-Q1    5381459.00\n",
      "2023-Q2    5677501.00\n",
      "2023-Q3    5774546.00\n",
      "2023-Q4    4853663.00\n",
      "2024-Q1    3657372.02\n",
      "2024-Q2    4286889.00\n",
      "2024-Q3    3718966.00\n",
      "2024-Q4    3611467.00\n",
      "2025-Q1     584600.00\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "--- Quarter-over-Quarter Revenue Change ---\n",
      "           Period   Previous    Current      Change  Change %\n",
      "2023-Q1 ‚Üí 2023-Q2 5381459.00 5677501.00   296042.00       5.5\n",
      "2023-Q2 ‚Üí 2023-Q3 5677501.00 5774546.00    97045.00       1.7\n",
      "2023-Q3 ‚Üí 2023-Q4 5774546.00 4853663.00  -920883.00     -15.9\n",
      "2023-Q4 ‚Üí 2024-Q1 4853663.00 3657372.02 -1196290.98     -24.6\n",
      "2024-Q1 ‚Üí 2024-Q2 3657372.02 4286889.00   629516.98      17.2\n",
      "2024-Q2 ‚Üí 2024-Q3 4286889.00 3718966.00  -567923.00     -13.2\n",
      "2024-Q3 ‚Üí 2024-Q4 3718966.00 3611467.00  -107499.00      -2.9\n",
      "2024-Q4 ‚Üí 2025-Q1 3611467.00  584600.00 -3026867.00     -83.8\n",
      "\n",
      ">>> Average Revenue Churn (negative quarters): -28.1% <<<\n"
     ]
    }
   ],
   "source": [
    "# 6.6 =============================================================================\n",
    "# REVENUE CHURN ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"REVENUE CHURN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Revenue by quarter\n",
    "df_treated['year_quarter'] = df_treated['year'].astype(str) + '-Q' + df_treated['quarter'].astype(str)\n",
    "revenue_by_quarter = df_treated.groupby('year_quarter')['total_amount'].sum().sort_index()\n",
    "\n",
    "print(\"\\n--- Revenue by Quarter ---\")\n",
    "print(revenue_by_quarter)\n",
    "\n",
    "# Calculate quarter-over-quarter revenue churn\n",
    "revenue_changes = []\n",
    "quarters = revenue_by_quarter.index.tolist()\n",
    "\n",
    "for i in range(1, len(quarters)):\n",
    "    prev_rev = revenue_by_quarter[quarters[i-1]]\n",
    "    curr_rev = revenue_by_quarter[quarters[i]]\n",
    "    change = curr_rev - prev_rev\n",
    "    change_pct = (change / prev_rev * 100) if prev_rev > 0 else 0\n",
    "    \n",
    "    revenue_changes.append({\n",
    "        'Period': f\"{quarters[i-1]} ‚Üí {quarters[i]}\",\n",
    "        'Previous': prev_rev,\n",
    "        'Current': curr_rev,\n",
    "        'Change': change,\n",
    "        'Change %': round(change_pct, 1)\n",
    "    })\n",
    "\n",
    "df_revenue_churn = pd.DataFrame(revenue_changes)\n",
    "print(\"\\n--- Quarter-over-Quarter Revenue Change ---\")\n",
    "print(df_revenue_churn.to_string(index=False))\n",
    "\n",
    "# Identify negative growth quarters (revenue churn)\n",
    "negative_quarters = df_revenue_churn[df_revenue_churn['Change'] < 0]\n",
    "if len(negative_quarters) > 0:\n",
    "    avg_revenue_churn = negative_quarters['Change %'].mean()\n",
    "    print(f\"\\n>>> Average Revenue Churn (negative quarters): {avg_revenue_churn:.1f}% <<<\")\n",
    "else:\n",
    "    print(\"\\n>>> No revenue churn detected (all quarters positive) <<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PIVOT TABLE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Revenue: Platform x Season ---\n",
      "season             Fall     Spring     Summer     Winter\n",
      "platform                                                \n",
      "mercadolibre  7689751.0  6632765.0  6783224.0  7998420.0\n",
      "shopify       2361403.0  1843380.0  2516450.0  1721070.0\n",
      "\n",
      "--- Transactions: Product x Platform ---\n",
      "platform  mercadolibre  shopify\n",
      "product                        \n",
      "jackets            162       58\n",
      "pajamas            135       40\n",
      "shorts             138       63\n",
      "socks              155       53\n",
      "towels             141       44\n",
      "tshirts            161       42\n",
      "\n",
      "--- Average Ticket: Product x Season ---\n",
      "season      Fall   Spring   Summer   Winter\n",
      "product                                    \n",
      "jackets  49953.0  46860.0  46470.0  49359.0\n",
      "pajamas  41588.0  30959.0  34898.0  42882.0\n",
      "shorts   29068.0  30313.0  33506.0  28860.0\n",
      "socks    16371.0  17103.0  16434.0  16566.0\n",
      "towels   32325.0  24343.0  28065.0  27202.0\n",
      "tshirts  25112.0  28109.0  27325.0  28236.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PIVOT TABLES\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"PIVOT TABLE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Revenue by Platform x Season\n",
    "pivot_platform_season = pd.pivot_table(\n",
    "    df_treated,\n",
    "    values='total_amount',\n",
    "    index='platform',\n",
    "    columns='season',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ").round(0)\n",
    "\n",
    "print(\"\\n--- Revenue: Platform x Season ---\")\n",
    "print(pivot_platform_season)\n",
    "\n",
    "# Transactions by Product x Platform\n",
    "pivot_product_platform = pd.pivot_table(\n",
    "    df_treated,\n",
    "    values='transaction_id',\n",
    "    index='product',\n",
    "    columns='platform',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(\"\\n--- Transactions: Product x Platform ---\")\n",
    "print(pivot_product_platform)\n",
    "\n",
    "# Average Ticket by Product x Season\n",
    "pivot_ticket = pd.pivot_table(\n",
    "    df_treated,\n",
    "    values='total_amount',\n",
    "    index='product',\n",
    "    columns='season',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ").round(0)\n",
    "\n",
    "print(\"\\n--- Average Ticket: Product x Season ---\")\n",
    "print(pivot_ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 KPI Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KPI SUMMARY DASHBOARD - PEQUESHOP\n",
      "============================================================\n",
      "\n",
      "üìä CUSTOMER HEALTH\n",
      "   NPS Score: 30.2\n",
      "   Customer Churn Rate: 41.4%\n",
      "   At-Risk Customers: 17.6%\n",
      "\n",
      "üí∞ REVENUE\n",
      "   Total Revenue: $37,773,160 CLP\n",
      "   Total Transactions: 1,192\n",
      "   Average Ticket: $31,689 CLP\n",
      "\n",
      "üéØ ACQUISITION\n",
      "   Total Customers: 500\n",
      "   Overall CAC: $23,771 CLP\n",
      "\n",
      "üîÑ RETARGETING SEGMENTS\n",
      "   Active: 97 (19.4%)\n",
      "   At Risk: 88 (17.6%)\n",
      "   Dormant: 207 (41.4%)\n",
      "\n",
      "üéØ Priority Win-back Targets: 39\n",
      "retargeting_segment\n",
      "Dormant    207\n",
      "Active      97\n",
      "At Risk     88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Days since last purchase - stats:\n",
      "count    392.000000\n",
      "mean     250.127551\n",
      "std      191.620827\n",
      "min        0.000000\n",
      "25%       91.000000\n",
      "50%      201.000000\n",
      "75%      377.000000\n",
      "max      760.000000\n",
      "Name: days_since_last_purchase, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# KPI SUMMARY DASHBOARD\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"KPI SUMMARY DASHBOARD - PEQUESHOP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate final metrics\n",
    "total_revenue = df['total_amount'].sum()\n",
    "total_transactions = len(df)\n",
    "avg_ticket = df['total_amount'].mean()\n",
    "total_customers_active = len(df_customers)\n",
    "\n",
    "# NPS (from earlier calculation)\n",
    "nps_respondents = df_customers[df_customers['nps_category'] != 'No Response']\n",
    "promoters_pct = (nps_respondents['nps_category'] == 'Promoter').sum() / len(nps_respondents) * 100\n",
    "detractors_pct = (nps_respondents['nps_category'] == 'Detractor').sum() / len(nps_respondents) * 100\n",
    "nps_score = promoters_pct - detractors_pct\n",
    "\n",
    "print(\"\\nüìä CUSTOMER HEALTH\")\n",
    "print(f\"   NPS Score: {nps_score:.1f}\")\n",
    "print(f\"   Customer Churn Rate: {customer_churn_rate:.1f}%\")\n",
    "print(f\"   At-Risk Customers: {at_risk_rate:.1f}%\")\n",
    "\n",
    "print(\"\\nüí∞ REVENUE\")\n",
    "print(f\"   Total Revenue: ${total_revenue:,.0f} CLP\")\n",
    "print(f\"   Total Transactions: {total_transactions:,}\")\n",
    "print(f\"   Average Ticket: ${avg_ticket:,.0f} CLP\")\n",
    "\n",
    "print(\"\\nüéØ ACQUISITION\")\n",
    "print(f\"   Total Customers: {total_customers_active}\")\n",
    "print(f\"   Overall CAC: ${overall_cac:,.0f} CLP\")\n",
    "\n",
    "print(\"\\nüîÑ RETARGETING SEGMENTS\")\n",
    "for segment in ['Active', 'At Risk', 'Dormant']:\n",
    "    count = segment_counts.get(segment, 0)\n",
    "    pct = count / total_customers * 100\n",
    "    print(f\"   {segment}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# High-value targets\n",
    "priority_winback = df_customers['priority_winback'].sum() if 'priority_winback' in df_customers.columns else 0\n",
    "print(f\"\\nüéØ Priority Win-back Targets: {priority_winback}\")\n",
    "\n",
    "\n",
    "print(df_customers['retargeting_segment'].value_counts())\n",
    "print(f\"\\nDays since last purchase - stats:\")\n",
    "print(df_customers['days_since_last_purchase'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 Export Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORTING FINAL DATASETS\n",
      "============================================================\n",
      "\n",
      "‚úÖ CSV Files exported to data/processed/:\n",
      "   - transactions_final.csv (1192 rows)\n",
      "   - customers_final.csv (500 rows)\n",
      "\n",
      "‚úÖ Excel workbook exported:\n",
      "   - pequeshop_analytics.xlsx (6 sheets)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXPORT FINAL DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPORTING FINAL DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Export to processed folder (final clean data)\n",
    "df_treated.to_csv('../data/processed/transactions_final.csv', index=False)\n",
    "df_customers.to_csv('../data/processed/customers_final.csv', index=False)\n",
    "\n",
    "# Export to Excel for business stakeholders\n",
    "with pd.ExcelWriter('../data/processed/pequeshop_analytics.xlsx', engine='openpyxl') as writer:\n",
    "    df_treated.to_excel(writer, sheet_name='Transactions', index=False)\n",
    "    df_customers.to_excel(writer, sheet_name='Customers', index=False)\n",
    "    df_nps.to_excel(writer, sheet_name='NPS_Surveys', index=False)\n",
    "    df_cac.to_excel(writer, sheet_name='CAC_Analysis', index=False)\n",
    "    revenue_by_product.to_excel(writer, sheet_name='Revenue_by_Product')\n",
    "    pivot_platform_season.to_excel(writer, sheet_name='Revenue_Platform_Season')\n",
    "\n",
    "print(\"\\n‚úÖ CSV Files exported to data/processed/:\")\n",
    "print(f\"   - transactions_final.csv ({len(df_treated)} rows)\")\n",
    "print(f\"   - customers_final.csv ({len(df_customers)} rows)\")\n",
    "\n",
    "print(\"\\n‚úÖ Excel workbook exported:\")\n",
    "print(f\"   - pequeshop_analytics.xlsx (6 sheets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10 Lesson 6 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ Revenue analysis by platform, product, and season using `groupby()`\n",
    "2. ‚úÖ NPS calculation by acquisition channel, region, and retargeting segment\n",
    "3. ‚úÖ CAC calculation by marketing channel\n",
    "4. ‚úÖ Customer Churn analysis based on purchase recency\n",
    "5. ‚úÖ Revenue Churn analysis (quarter-over-quarter)\n",
    "6. ‚úÖ Pivot tables for multi-dimensional analysis\n",
    "7. ‚úÖ KPI Summary Dashboard\n",
    "8. ‚úÖ Exported final datasets (CSV + Excel)\n",
    "\n",
    "**Key Pandas methods used:**\n",
    "\n",
    "- `.groupby().agg()` - Aggregate by dimensions\n",
    "- `.groupby().apply()` - Custom aggregation functions\n",
    "- `pd.pivot_table()` - Multi-dimensional analysis\n",
    "- `.to_csv()`, `.to_excel()` - Export data\n",
    "- `pd.ExcelWriter()` - Multi-sheet Excel export\n",
    "\n",
    "**Business metrics calculated:**\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|--------|-------|----------------|\n",
    "| NPS | Calculated | Customer satisfaction index |\n",
    "| CAC | By channel | Marketing efficiency |\n",
    "| Customer Churn | % dormant | Retention health |\n",
    "| Revenue Churn | QoQ change | Revenue stability |\n",
    "\n",
    "**Deliverables created:**\n",
    "\n",
    "- `transactions_final.csv` - Clean transaction data\n",
    "- `customers_final.csv` - Enriched customer data with NPS and segments\n",
    "- `pequeshop_analytics.xlsx` - Business-ready Excel workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Project Complete! üéâ\n",
    "\n",
    "### ETL Pipeline Summary\n",
    "\n",
    "```\n",
    "EXTRACT (L1-L3)           TRANSFORM (L4-L5)           LOAD (L6)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "NumPy generation    ‚Üí    Missing values      ‚Üí    CSV exports\n",
    "CSV loading         ‚Üí    Outlier treatment   ‚Üí    Excel workbook\n",
    "Excel loading       ‚Üí    NPS integration     ‚Üí    KPI dashboard\n",
    "HTML parsing        ‚Üí    Feature engineering\n",
    "                    ‚Üí    Retargeting segments\n",
    "```\n",
    "\n",
    "### CRISP-DM Phases Covered\n",
    "\n",
    "- ‚úÖ **Business Understanding:** Problem definition, KPI framework\n",
    "- ‚úÖ **Data Understanding:** Exploratory analysis, data profiling\n",
    "- ‚úÖ **Data Preparation:** Complete ETL pipeline\n",
    "\n",
    "### Business Value Delivered\n",
    "\n",
    "1. **Unified data** from 3 sources (MercadoLibre, Shopify, Marketing)\n",
    "2. **NPS tracking** enables customer satisfaction measurement\n",
    "3. **Retargeting segments** enable targeted marketing actions\n",
    "4. **CAC by channel** enables marketing budget optimization\n",
    "5. **Churn metrics** enable proactive retention strategies\n",
    "\n",
    "### Next Steps (Future Work)\n",
    "\n",
    "- Modeling: Predictive models for churn, CLTV\n",
    "- Evaluation: A/B testing of pricing strategies\n",
    "- Deployment: Dashboard in Power BI / Streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
