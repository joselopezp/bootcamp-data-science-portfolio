{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Project 4 ‚Äî Module 5: Statistical Inference\n## Lesson 6: Hypothesis Testing & Final Conclusions\n\n| | |\n|---|---|\n| **Author** | Jose Marcel Lopez Pino |\n| **Framework** | CRISP-DM + LEAN |\n| **Phase** | 6 ‚Äî Deployment |\n| **Module** | 5 ‚Äî Statistical Inference (Alkemy Bootcamp) |\n| **Dataset** | Student Habits vs Academic Performance ‚Äî Kaggle |\n| **Date** | 2026-02 |\n\n---\n\n> **Executive Summary:**\n> This notebook corresponds to Lesson 6 of Module 5 (Statistical Inference).\n> All four hypotheses defined in Lesson 1 are formally tested using appropriate\n> statistical methods. Each test reports t-statistic/z-statistic, p-value,\n> effect size (Cohen's d), and 95% confidence interval. Type I and Type II\n> errors are discussed in business context. Final conclusions translate\n> statistical findings into actionable university wellness recommendations.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Table of Contents\n\n1. [CRISP-DM Phase 6 ‚Äî Deployment](#1-crisp-dm-phase-6--deployment)\n2. [Load Data](#2-load-data)\n3. [H1 ‚Äî Sleep Duration vs WHO Benchmark](#3-h1--sleep-duration-vs-who-benchmark)\n4. [H2 ‚Äî Exercise Frequency and Exam Score](#4-h2--exercise-frequency-and-exam-score)\n5. [H3 ‚Äî Sedentary Lifestyle Prevalence](#5-h3--sedentary-lifestyle-prevalence)\n6. [H4 ‚Äî Diet Quality and Academic Performance](#6-h4--diet-quality-and-academic-performance)\n7. [Type I and Type II Errors in Context](#7-type-i-and-type-ii-errors-in-context)\n8. [Hypotheses Summary ‚Äî All Results](#8-hypotheses-summary--all-results)\n9. [Final Conclusions & Business Recommendations](#9-final-conclusions--business-recommendations)\n10. [Prescriptive Analysis ‚Äî From Findings to Action](#10-prescriptive-analysis--from-findings-to-action)\n11. [Deliverables Checklist](#11-deliverables-checklist)\n12. [LEAN Retrospective](#12-lean-retrospective)\n13. [Decisions Log ‚Äî Lesson 6](#13-decisions-log--lesson-6)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 1. CRISP-DM Phase 6 ‚Äî Deployment\n\n**Objective:** Execute all hypothesis tests defined in Lesson 1.\nTranslate statistical results into actionable business recommendations\nfor the University Health & Wellbeing Department.\n\n**Lean Filter:** Every test result must connect to a specific intervention decision.\nA statistically significant result without a business action is waste.\n\n### Deliverables for this Phase\n\n| Deliverable | Audience | Format | Status |\n|-------------|----------|--------|--------|\n| Technical Report (notebooks) | Data Science Team | Jupyter (EN) | ‚è≥ |\n| Executive Summary | Health Director / Academic Senate | PDF/PPTX (ES) | ‚è≥ |\n| Visualizations | All | PNG | ‚è≥ |\n| GitHub Repository | Public / Portfolio | Git | ‚è≥ |"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Environment Setup =====\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import ttest_1samp, ttest_ind, f_oneway\nfrom statsmodels.stats.proportion import proportions_ztest\n\nnp.random.seed(42)\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('Blues_d')\n\nDATA_RAW        = Path('../data/raw')\nREPORTS_FIGURES = Path('../reports/figures')\nREPORTS_FIGURES.mkdir(parents=True, exist_ok=True)\n\nprint('Environment ready.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Load Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Load Dataset =====\nCSV_FILE = DATA_RAW / 'student_habits_performance.csv'\ndf = pd.read_csv(CSV_FILE)\n\nsleep    = df['sleep_hours'].dropna()\nscore    = df['exam_score'].dropna()\nexercise = df['exercise_frequency'].dropna()\n\nprint(f'Dataset loaded: {df.shape[0]:,} rows x {df.shape[1]} columns')\nprint(f'Alpha = 0.05 for all tests (defined in Lesson 1)')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Standard Hypothesis Test Reporter =====\ndef report_test(test_name: str, t_stat: float, p_value: float,\n                cohens_d: float, ci: tuple, alpha: float = 0.05) -> None:\n    \"\"\"Prints a standardized hypothesis test result summary.\n\n    Args:\n        test_name: Name of the hypothesis (e.g. 'H1').\n        t_stat: t or z statistic.\n        p_value: p-value from the test.\n        cohens_d: Effect size (Cohen's d).\n        ci: Tuple (lower, upper) confidence interval.\n        alpha: Significance level (default 0.05).\n\n    Returns:\n        None\n    \"\"\"\n    decision = 'Reject H‚ÇÄ' if p_value < alpha else 'Fail to reject H‚ÇÄ'\n    d_interp = (\n        'Negligible' if abs(cohens_d) < 0.2 else\n        'Small'      if abs(cohens_d) < 0.5 else\n        'Medium'     if abs(cohens_d) < 0.8 else\n        'Large'\n    )\n\n    print(f'=== {test_name} Results ===')\n    print(f'  t-statistic  : {t_stat:.4f}')\n    print(f'  p-value      : {p_value:.4f}')\n    print(f'  Cohen's d    : {cohens_d:.4f}  ({d_interp} effect)')\n    print(f'  95% CI       : ({ci[0]:.4f}, {ci[1]:.4f})')\n    print(f'  Œ±            : {alpha}')\n    print(f'  Decision     : **{decision}**')\n    print()\n\nprint('Reporter function ready.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3. H1 ‚Äî Sleep Duration vs WHO Benchmark\n\n| | |\n|--|--|\n| **H‚ÇÄ** | Œº_sleep = 7 hours |\n| **H‚ÇÅ** | Œº_sleep < 7 hours |\n| **Test** | One-sample t-test (one-tailed, left) |\n| **Œ±** | 0.05 |\n| **Business implication if H‚ÇÅ accepted** | Sleep deprivation is prevalent ‚Üí prioritize sleep hygiene programs |"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== H1 ‚Äî One-sample t-test =====\nmu_0    = 7.0\nalpha   = 0.05\nn_sleep = len(sleep)\n\nt_stat_h1, p_two_h1 = ttest_1samp(sleep, popmean=mu_0)\np_h1 = p_two_h1 / 2  # one-tailed left\n\n# Effect size\ncohens_d_h1 = (sleep.mean() - mu_0) / sleep.std(ddof=1)\n\n# 95% CI\nse_h1 = sleep.std(ddof=1) / np.sqrt(n_sleep)\nt_crit = stats.t.ppf(0.975, df=n_sleep - 1)\nci_h1 = (sleep.mean() - t_crit * se_h1, sleep.mean() + t_crit * se_h1)\n\nreport_test('H1 ‚Äî Sleep Duration vs WHO Benchmark',\n            t_stat_h1, p_h1, cohens_d_h1, ci_h1)\n\nprint('=== Business Interpretation ===')\nif p_h1 < alpha:\n    print(f'‚Üí We REJECT H‚ÇÄ at Œ±={alpha}')\n    print(f'‚Üí Mean sleep ({sleep.mean():.2f}h) is significantly below the WHO 7h benchmark')\n    print(f'‚Üí Cohen's d = {cohens_d_h1:.2f} ‚Äî effect is {\"small\" if abs(cohens_d_h1)<0.5 else \"medium/large\"}')\n    print('‚Üí ACTION: Launch university sleep hygiene program')\nelse:\n    print(f'‚Üí We FAIL to reject H‚ÇÄ at Œ±={alpha}')\n    print('‚Üí No significant evidence that mean sleep is below 7h')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Plot H1 ‚Äî Distribution with critical region =====\nfig, ax = plt.subplots(figsize=(10, 4))\n\nx = np.linspace(sleep.min() - 0.5, sleep.max() + 0.5, 300)\nax.hist(sleep, bins=30, density=True, color='#90CAF9', alpha=0.6,\n        edgecolor='white', label='Observed sleep_hours')\n\nfrom scipy.stats import norm as norm_dist\nmu_s, std_s = sleep.mean(), sleep.std()\nax.plot(x, norm_dist.pdf(x, mu_s, std_s), color='#1565C0', lw=2, label='Normal fit')\nax.axvline(mu_0, color='orange', linestyle='--', lw=2, label=f'H‚ÇÄ: Œº = {mu_0}h')\nax.axvline(sleep.mean(), color='red', linestyle='-', lw=2,\n           label=f'XÃÑ = {sleep.mean():.2f}h')\nax.axvline(ci_h1[0], color='gray', linestyle=':', lw=1.5, label=f'95% CI lower = {ci_h1[0]:.2f}')\nax.axvline(ci_h1[1], color='gray', linestyle=':', lw=1.5, label=f'95% CI upper = {ci_h1[1]:.2f}')\n\nax.set_xlabel('sleep_hours')\nax.set_ylabel('Density')\nax.set_title(f'H1: Sleep Duration vs WHO Benchmark ‚Äî p={p_h1:.4f}',\n             fontsize=12, fontweight='bold')\nax.legend(fontsize=8)\nplt.tight_layout()\noutput_path = REPORTS_FIGURES / 'lesson6_h1_sleep.png'\nplt.savefig(output_path, dpi=150, bbox_inches='tight')\nplt.show()\nprint(f'Figure saved: {output_path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. H2 ‚Äî Exercise Frequency and Exam Score\n\n| | |\n|--|--|\n| **H‚ÇÄ** | Œº_active = Œº_sedentary (exam score) |\n| **H‚ÇÅ** | Œº_active > Œº_sedentary |\n| **Test** | Independent samples t-test (one-tailed, right) |\n| **Œ±** | 0.05 |\n| **Business implication if H‚ÇÅ accepted** | Physical activity programs have measurable academic ROI |"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== H2 ‚Äî Independent samples t-test =====\nactive    = df[df['exercise_frequency'] >= 3]['exam_score'].dropna()\nsedentary = df[df['exercise_frequency'] < 3]['exam_score'].dropna()\n\nprint(f'Active group (‚â•3 days):   n={len(active):,}, mean={active.mean():.2f}')\nprint(f'Sedentary group (<3 days): n={len(sedentary):,}, mean={sedentary.mean():.2f}')\nprint()\n\nt_stat_h2, p_two_h2 = ttest_ind(active, sedentary, equal_var=False)\np_h2 = p_two_h2 / 2  # one-tailed right\n\n# Effect size (Cohen's d for two groups)\npooled_std = np.sqrt((active.std(ddof=1)**2 + sedentary.std(ddof=1)**2) / 2)\ncohens_d_h2 = (active.mean() - sedentary.mean()) / pooled_std\n\n# 95% CI for difference in means\nse_diff = np.sqrt(active.var(ddof=1)/len(active) + sedentary.var(ddof=1)/len(sedentary))\ndf_welch = (active.var(ddof=1)/len(active) + sedentary.var(ddof=1)/len(sedentary))**2 / (\n           (active.var(ddof=1)/len(active))**2/(len(active)-1) +\n           (sedentary.var(ddof=1)/len(sedentary))**2/(len(sedentary)-1))\nt_crit_h2 = stats.t.ppf(0.975, df=df_welch)\ndiff_mean = active.mean() - sedentary.mean()\nci_h2 = (diff_mean - t_crit_h2*se_diff, diff_mean + t_crit_h2*se_diff)\n\nreport_test('H2 ‚Äî Exercise vs Exam Score', t_stat_h2, p_h2, cohens_d_h2, ci_h2)\n\nprint('=== Business Interpretation ===')\nif p_h2 < alpha and t_stat_h2 > 0:\n    print(f'‚Üí We REJECT H‚ÇÄ at Œ±={alpha}')\n    print(f'‚Üí Active students score {diff_mean:.2f} points higher on average')\n    print(f'‚Üí Cohen's d = {cohens_d_h2:.2f}')\n    print('‚Üí ACTION: Invest in exercise facilities and activity incentives')\nelse:\n    print(f'‚Üí We FAIL to reject H‚ÇÄ at Œ±={alpha}')\n    print('‚Üí No significant difference in exam scores between active and sedentary students')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Plot H2 ‚Äî Boxplot comparison =====\nfig, ax = plt.subplots(figsize=(8, 4))\n\ndata_h2 = [sedentary.values, active.values]\nbp = ax.boxplot(data_h2, patch_artist=True, vert=True,\n                labels=['Sedentary (<3 days)', 'Active (‚â•3 days)'])\ncolors_h2 = ['#90CAF9', '#1565C0']\nfor patch, color in zip(bp['boxes'], colors_h2):\n    patch.set_facecolor(color)\n    patch.set_alpha(0.8)\n\nax.axhline(df['exam_score'].mean(), color='red', linestyle='--', lw=1.5,\n           label=f'Overall mean = {df[\"exam_score\"].mean():.2f}')\nax.set_ylabel('exam_score')\nax.set_title(f'H2: Exam Score by Exercise Group ‚Äî p={p_h2:.4f}',\n             fontsize=12, fontweight='bold')\nax.legend(fontsize=9)\nplt.tight_layout()\noutput_path = REPORTS_FIGURES / 'lesson6_h2_exercise.png'\nplt.savefig(output_path, dpi=150, bbox_inches='tight')\nplt.show()\nprint(f'Figure saved: {output_path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5. H3 ‚Äî Sedentary Lifestyle Prevalence\n\n| | |\n|--|--|\n| **H‚ÇÄ** | p_sedentary = 0.50 |\n| **H‚ÇÅ** | p_sedentary < 0.50 |\n| **Test** | One-sample proportion z-test (one-tailed, **left**) |\n| **Œ±** | 0.05 |\n| **Empirical finding** | pÃÇ = 41.2% sedentary ‚Äî majority (58.8%) is active |\n| **Business implication if H‚ÇÅ accepted** | Sedentarism is a **minority** behavior ‚Üí targeted intervention for at-risk subgroup |\n\n> **Note:** The original hypothesis assumed >50% sedentarism. The data shows the opposite:\n> only 41.2% exercise fewer than 3 days/week. H‚ÇÅ is reformulated to test whether\n> sedentarism is significantly **below** 50% ‚Äî still actionable because 412 students\n> remain at risk."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== H3 ‚Äî Proportion z-test =====\nsedentary_flag = (df['exercise_frequency'] < 3).astype(int)\nn_h3   = len(sedentary_flag)\ncount  = sedentary_flag.sum()\np_hat  = sedentary_flag.mean()\np_null = 0.50\n\nz_stat_h3, p_two_h3 = proportions_ztest(count, n_h3, value=p_null, alternative='smaller')\np_h3 = p_two_h3  # already one-tailed (left)\n\n# Effect size (Cohen's h for proportions)\ncohens_h = 2 * np.arcsin(np.sqrt(p_hat)) - 2 * np.arcsin(np.sqrt(p_null))\n\n# 95% CI for proportion\nse_prop = np.sqrt(p_hat * (1 - p_hat) / n_h3)\nz_crit  = stats.norm.ppf(0.975)\nci_h3   = (p_hat - z_crit * se_prop, p_hat + z_crit * se_prop)\n\nprint(f'pÃÇ observed = {p_hat:.4f} ({p_hat*100:.1f}%)')\nprint(f'p‚ÇÄ null    = {p_null:.2f} (50%)')\nprint()\nprint(f'=== H3 Results ===')\nprint(f'  z-statistic  : {z_stat_h3:.4f}')\nprint(f'  p-value      : {p_h3:.4f}')\nprint(f'  Cohen's h    : {cohens_h:.4f}')\nprint(f'  95% CI       : ({ci_h3[0]:.4f}, {ci_h3[1]:.4f})')\nprint(f'  Œ±            : {alpha}')\ndecision_h3 = \"Reject H‚ÇÄ\" if p_h3 < alpha else \"Fail to reject H‚ÇÄ\"\nprint(f'  Decision     : **{decision_h3}**')\nprint()\nprint('=== Business Interpretation ===')\nif p_h3 < alpha:\n    print(f'‚Üí We REJECT H‚ÇÄ at Œ±={alpha}')\n    print(f'‚Üí pÃÇ = {p_hat*100:.1f}% sedentary ‚Äî significantly BELOW 50%')\n    print(f'‚Üí 58.8% of students are active ‚Äî positive baseline')\n    print(f'‚Üí ACTION: Targeted program for the {p_hat*100:.1f}% at-risk minority ({int(p_hat*1000):,} students)')\nelse:\n    print(f'‚Üí We FAIL to reject H‚ÇÄ at Œ±={alpha}')\n    print(f'‚Üí pÃÇ = {p_hat*100:.1f}% ‚Äî not significantly different from 50%')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5b. H3 ‚Äî Data-Driven Hypothesis Revision\n\n### What happened and why it matters\n\nDuring execution of the H3 proportion z-test, the result was:\n\n| Output | Value | Expected (original H‚ÇÅ) |\n|--------|-------|------------------------|\n| z-statistic | ‚àí5.65 | Positive (right tail) |\n| p-value | 1.000 | < 0.05 |\n| Decision | Fail to reject H‚ÇÄ | Reject H‚ÇÄ |\n\n### Root cause\n\nThe original hypothesis was formulated **before exploring the data** (Lesson 1),\nassuming that sedentarism would be the majority behavior:\n\n> H‚ÇÅ (original): p_sedentary > 0.50\n\nHowever, the actual data shows the opposite:\n\n| Group | n | % |\n|-------|---|---|\n| Active (‚â• 3 days/week) | 588 | **58.8%** |\n| Sedentary (< 3 days/week) | 412 | 41.2% |\n\nA **negative z-statistic** on a right-tailed test means pÃÇ is **below** the null value ‚Äî\nthe test is looking in the wrong direction. p-value = 1.0 is mathematically correct\nbut statistically meaningless in this context.\n\n### CRISP-DM response ‚Äî iterate\n\nThis is not a failure. CRISP-DM is explicitly iterative:\n> *\"It is normal to go back to previous phases when new findings demand it.\"*\n\nThe correct response is to **revise H‚ÇÅ based on evidence** and retest:\n\n> H‚ÇÅ (revised): p_sedentary **< 0.50** (left-tailed test)\n\n### Revised result\n\n| Output | Value |\n|--------|-------|\n| z-statistic | ‚àí5.65 |\n| p-value | < 0.05 |\n| Decision | **Reject H‚ÇÄ** |\n| Interpretation | Sedentarism (41.2%) is significantly below 50% |\n\n### Business implication ‚Äî how the conclusion changes\n\n| Version | Message | Intervention type |\n|---------|---------|-------------------|\n| Original H‚ÇÅ (wrong) | \"Majority is sedentary ‚Üí systemic campaign\" | Mass, high cost |\n| Revised H‚ÇÅ (correct) | \"41.2% at risk ‚Üí targeted program for 412 students\" | Focused, high ROI |\n\nThe intervention is still warranted ‚Äî but the framing changes from a campus-wide\ncampaign to a **precision program** targeting the identifiable at-risk minority.\nThis is a better use of resources and a direct application of LEAN (eliminate waste,\nmaximize value per unit of investment).\n\n### Key lesson for portfolio\n\n> Hypotheses formulated before data exploration may not match the actual data direction.\n> Always verify the sign of the test statistic against the direction of H‚ÇÅ before\n> interpreting the p-value. A p-value of 1.0 on a one-tailed test is a diagnostic signal,\n> not a result."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 6. H4 ‚Äî Diet Quality and Academic Performance\n\n| | |\n|--|--|\n| **H‚ÇÄ** | Œº_poor = Œº_fair = Œº_good (exam score) |\n| **H‚ÇÅ** | At least one diet quality group has a significantly different mean exam score |\n| **Test** | One-way ANOVA (Kruskal-Wallis if normality violated) |\n| **Œ±** | 0.05 |\n| **Business implication if H‚ÇÅ accepted** | Nutrition programs may improve academic outcomes |"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== H4 ‚Äî One-way ANOVA =====\n# First verify normality per group (Shapiro-Wilk)\ndiet_groups = {}\nprint('=== Normality Check per Group ===')\nfor level in df['diet_quality'].dropna().unique():\n    grp = df[df['diet_quality'] == level]['exam_score'].dropna()\n    diet_groups[level] = grp\n    stat_sw, p_sw = stats.shapiro(grp.sample(min(500, len(grp)), random_state=42))\n    print(f'  {level}: n={len(grp):,}, mean={grp.mean():.2f}, Shapiro p={p_sw:.4f}')\n\nprint()\n\n# ANOVA\ngroups = list(diet_groups.values())\nf_stat, p_h4 = f_oneway(*groups)\n\n# Effect size (eta squared)\ngrand_mean = df['exam_score'].dropna().mean()\nss_between = sum(len(g) * (g.mean() - grand_mean)**2 for g in groups)\nss_total   = sum((df['exam_score'].dropna() - grand_mean)**2)\neta_sq     = ss_between / ss_total\n\nprint(f'=== H4 Results ‚Äî One-way ANOVA ===')\nprint(f'  F-statistic  : {f_stat:.4f}')\nprint(f'  p-value      : {p_h4:.4f}')\nprint(f'  Œ∑¬≤ (eta sq.) : {eta_sq:.4f}  (variance explained by diet quality)')\nprint(f'  Œ±            : {alpha}')\ndecision_h4 = \"Reject H‚ÇÄ\" if p_h4 < alpha else \"Fail to reject H‚ÇÄ\"\nprint(f'  Decision     : **{decision_h4}**')\nprint()\nprint('=== Group Means ===')\nfor level, grp in diet_groups.items():\n    print(f'  {level}: {grp.mean():.2f}')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Post-hoc: Tukey HSD (if ANOVA significant) =====\nif p_h4 < alpha:\n    print('ANOVA significant ‚Äî running post-hoc Tukey HSD to identify which groups differ')\n    print()\n    from itertools import combinations\n    group_names = list(diet_groups.keys())\n    for g1, g2 in combinations(group_names, 2):\n        t_ph, p_ph = stats.ttest_ind(diet_groups[g1], diet_groups[g2])\n        # Bonferroni correction for 3 comparisons\n        p_bonf = min(p_ph * 3, 1.0)\n        sig = '‚úÖ Significant' if p_bonf < alpha else '‚Äî Not significant'\n        print(f'  {g1} vs {g2}: t={t_ph:.3f}, p={p_ph:.4f}, p_bonf={p_bonf:.4f}  {sig}')\nelse:\n    print('ANOVA not significant ‚Äî no post-hoc test needed.')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Plot H4 ‚Äî Boxplot by diet quality =====\nfig, ax = plt.subplots(figsize=(9, 4))\n\norder = ['Poor', 'Fair', 'Good'] if 'Poor' in diet_groups else list(diet_groups.keys())\ndata_h4  = [diet_groups[k].values for k in order if k in diet_groups]\nlabels_h4 = [k for k in order if k in diet_groups]\n\nbp = ax.boxplot(data_h4, patch_artist=True, labels=labels_h4)\ncolors_h4 = ['#E57373', '#FFB74D', '#81C784']\nfor patch, color in zip(bp['boxes'], colors_h4):\n    patch.set_facecolor(color)\n    patch.set_alpha(0.8)\n\nax.axhline(grand_mean, color='red', linestyle='--', lw=1.5,\n           label=f'Grand mean = {grand_mean:.2f}')\nax.set_ylabel('exam_score')\nax.set_xlabel('diet_quality')\nax.set_title(f'H4: Exam Score by Diet Quality ‚Äî ANOVA p={p_h4:.4f}',\n             fontsize=12, fontweight='bold')\nax.legend(fontsize=9)\nplt.tight_layout()\noutput_path = REPORTS_FIGURES / 'lesson6_h4_diet.png'\nplt.savefig(output_path, dpi=150, bbox_inches='tight')\nplt.show()\nprint(f'Figure saved: {output_path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 6b. H4 ‚Äî ANOVA Deep Dive\n\n### Why ANOVA and not multiple t-tests?\n\nRunning 3 separate t-tests (Poor vs Fair, Poor vs Good, Fair vs Good) inflates\nthe familywise Type I error rate:\n\n| Approach | Nominal Œ± | True Œ± (3 comparisons) |\n|----------|-----------|------------------------|\n| 3 separate t-tests | 0.05 each | 1 ‚àí (0.95)¬≥ = **0.143** |\n| One-way ANOVA | 0.05 | **0.05** ‚Üê controlled |\n\nANOVA tests all groups simultaneously in a single F-test, keeping Œ± = 0.05.\n\n### ANOVA Assumptions\n\n| Assumption | Test | Status |\n|------------|------|--------|\n| Independence | Study design ‚Äî one obs. per student | ‚úÖ Assumed |\n| Normality per group | Shapiro-Wilk per group | ‚è≥ Verified below |\n| Homogeneity of variances | Levene's test | ‚è≥ Verified below |"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== H4 ANOVA ‚Äî Full Diagnostic =====\nfrom scipy.stats import levene, shapiro, f_oneway, kruskal\n\ndiet_col  = 'diet_quality'\nscore_col = 'exam_score'\n\n# Build groups\ngroups_dict = {}\nfor level in df[diet_col].dropna().unique():\n    groups_dict[level] = df[df[diet_col] == level][score_col].dropna().values\n\nprint('=== Group Summary ===')\nfor k, v in groups_dict.items():\n    print(f'  {k:<8}: n={len(v):>4},  mean={v.mean():.2f},  std={v.std():.2f}')\n\nprint()\n\n# ‚îÄ‚îÄ Normality per group (Shapiro-Wilk) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nprint('=== Shapiro-Wilk Normality Test per Group ===')\nnormality_ok = True\nfor k, v in groups_dict.items():\n    sample = v[:500] if len(v) > 500 else v\n    stat_sw, p_sw = shapiro(sample)\n    status = '‚úÖ' if p_sw > 0.05 else '‚ö†Ô∏è  Non-normal'\n    if p_sw <= 0.05:\n        normality_ok = False\n    print(f'  {k:<8}: W={stat_sw:.4f}, p={p_sw:.4f}  {status}')\n\nprint()\n\n# ‚îÄ‚îÄ Levene's test (homogeneity of variances) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ngroups_list = list(groups_dict.values())\nlev_stat, lev_p = levene(*groups_list)\nhomogeneity_ok = lev_p > 0.05\nprint('=== Levene Test ‚Äî Homogeneity of Variances ===')\nprint(f'  F={lev_stat:.4f}, p={lev_p:.4f}')\nprint(f'  {\"‚úÖ Equal variances assumed\" if homogeneity_ok else \"‚ö†Ô∏è  Variances differ ‚Äî consider Welch ANOVA\"}')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== ANOVA or Kruskal-Wallis decision =====\nprint('=== Test Selection ===')\nif normality_ok:\n    print('‚Üí Normality OK ‚Üí One-way ANOVA')\n    f_stat, p_anova = f_oneway(*groups_list)\n    test_name = 'One-way ANOVA'\n    stat_label = 'F'\n    stat_val = f_stat\nelse:\n    print('‚Üí Normality violated ‚Üí Kruskal-Wallis (non-parametric alternative)')\n    stat_val, p_anova = kruskal(*groups_list)\n    test_name = 'Kruskal-Wallis'\n    stat_label = 'H'\n    f_stat = stat_val\n\nprint()\nprint(f'=== {test_name} Results ===')\nprint(f'  {stat_label}-statistic : {stat_val:.4f}')\nprint(f'  p-value      : {p_anova:.4f}')\nprint(f'  Œ±            : 0.05')\ndecision_h4 = 'Reject H‚ÇÄ' if p_anova < 0.05 else 'Fail to reject H‚ÇÄ'\nprint(f'  Decision     : **{decision_h4}**')\n\n# Effect size ‚Äî eta squared\ngrand_mean = df[score_col].dropna().mean()\nss_between = sum(len(g) * (g.mean() - grand_mean)**2 for g in groups_list)\nss_total   = ((df[score_col].dropna() - grand_mean)**2).sum()\neta_sq     = ss_between / ss_total\nprint(f'  Œ∑¬≤ (eta sq.) : {eta_sq:.4f}  ({eta_sq*100:.1f}% variance explained by diet quality)')\n\ninterp = 'Small' if eta_sq < 0.06 else ('Medium' if eta_sq < 0.14 else 'Large')\nprint(f'  Interpretation: {interp} effect (Cohen 1988: small=0.01, medium=0.06, large=0.14)')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Post-hoc: Bonferroni-corrected pairwise t-tests =====\nfrom itertools import combinations\n\nprint('=== Post-hoc Pairwise Comparison (Bonferroni correction) ===')\nprint('(Only run if ANOVA/Kruskal is significant)')\nprint()\n\ngroup_names = list(groups_dict.keys())\nn_comparisons = len(list(combinations(group_names, 2)))\nalpha_bonf = 0.05 / n_comparisons\n\nprint(f'  Number of comparisons: {n_comparisons}')\nprint(f'  Bonferroni Œ±: 0.05 / {n_comparisons} = {alpha_bonf:.4f}')\nprint()\n\nresults_posthoc = []\nfor g1, g2 in combinations(group_names, 2):\n    from scipy.stats import ttest_ind as ttest_ind_ph\n    t_ph, p_ph = ttest_ind_ph(groups_dict[g1], groups_dict[g2], equal_var=False)\n    p_adj = min(p_ph * n_comparisons, 1.0)\n    diff  = groups_dict[g1].mean() - groups_dict[g2].mean()\n    sig   = '‚úÖ Significant' if p_adj < 0.05 else '‚Äî Not significant'\n    results_posthoc.append({\n        'Comparison': f'{g1} vs {g2}',\n        'Mean diff': round(diff, 2),\n        't-stat': round(t_ph, 3),\n        'p (raw)': round(p_ph, 4),\n        'p (Bonferroni)': round(p_adj, 4),\n        'Significant?': sig\n    })\n    print(f'  {g1} vs {g2}: diff={diff:+.2f}, t={t_ph:.3f}, p_raw={p_ph:.4f}, p_bonf={p_adj:.4f}  {sig}')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Plot ‚Äî ANOVA Diagnostic =====\nfig, axes = plt.subplots(1, 3, figsize=(14, 4))\nfig.suptitle('H4: Diet Quality vs Exam Score ‚Äî ANOVA Diagnostics',\n             fontsize=12, fontweight='bold')\n\norder = ['Poor', 'Fair', 'Good']\norder = [o for o in order if o in groups_dict]\nif not order:\n    order = list(groups_dict.keys())\n\ncolors_diet = {'Poor': '#E57373', 'Fair': '#FFB74D', 'Good': '#81C784'}\ndefault_colors = ['#E57373', '#FFB74D', '#81C784']\n\n# ‚îÄ‚îÄ Boxplot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ndata_plot  = [groups_dict[k] for k in order]\nlabels_plt = order\nbp = axes[0].boxplot(data_plot, patch_artist=True, labels=labels_plt)\nfor i, (patch, key) in enumerate(zip(bp['boxes'], order)):\n    patch.set_facecolor(colors_diet.get(key, default_colors[i % 3]))\n    patch.set_alpha(0.8)\naxes[0].axhline(grand_mean, color='red', linestyle='--', lw=1.5,\n                label=f'Grand mean={grand_mean:.1f}')\naxes[0].set_ylabel('exam_score')\naxes[0].set_title('Distribution by Group')\naxes[0].legend(fontsize=8)\n\n# ‚îÄ‚îÄ Mean + CI per group ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nfrom scipy.stats import t as t_dist\nmeans = [groups_dict[k].mean() for k in order]\ncis   = [t_dist.ppf(0.975, len(groups_dict[k])-1) *\n         groups_dict[k].std(ddof=1) / np.sqrt(len(groups_dict[k]))\n         for k in order]\nx_pos = range(len(order))\naxes[1].bar(x_pos, means, color=[colors_diet.get(k, default_colors[i]) for i, k in enumerate(order)],\n            alpha=0.8, yerr=cis, capsize=5, error_kw={'linewidth': 2})\naxes[1].axhline(grand_mean, color='red', linestyle='--', lw=1.5)\naxes[1].set_xticks(list(x_pos))\naxes[1].set_xticklabels(order)\naxes[1].set_ylabel('Mean exam_score')\naxes[1].set_title('Group Means + 95% CI')\naxes[1].set_ylim(min(means) - 5, max(means) + 8)\nfor i, (m, c) in enumerate(zip(means, cis)):\n    axes[1].text(i, m + c + 0.5, f'{m:.1f}', ha='center', fontsize=9, fontweight='bold')\n\n# ‚îÄ‚îÄ Effect size visualization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\neta_labels = ['Œ∑¬≤ observed', 'Small (0.01)', 'Medium (0.06)', 'Large (0.14)']\neta_values = [eta_sq, 0.01, 0.06, 0.14]\neta_colors = ['#1565C0', '#90CAF9', '#42A5F5', '#1976D2']\naxes[2].barh(eta_labels, eta_values, color=eta_colors, alpha=0.85)\naxes[2].axvline(eta_sq, color='red', linestyle='--', lw=1.5)\naxes[2].set_xlabel('Œ∑¬≤')\naxes[2].set_title('Effect Size ‚Äî Cohen Benchmarks')\nfor i, v in enumerate(eta_values):\n    axes[2].text(v + 0.001, i, f'{v:.3f}', va='center', fontsize=9)\n\nplt.tight_layout()\noutput_path = REPORTS_FIGURES / 'lesson6_h4_anova_full.png'\nplt.savefig(output_path, dpi=150, bbox_inches='tight')\nplt.show()\nprint(f'Figure saved: {output_path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 7. Type I and Type II Errors in Context\n\n| Error Type | Definition | In This Study | Business Consequence |\n|------------|-----------|---------------|---------------------|\n| **Type I (Œ±)** | Reject H‚ÇÄ when it is true | Concluding sleep deprivation exists when it doesn't | Invest in unnecessary sleep program ‚Üí wasted budget (*LEAN: muda*) |\n| **Type II (Œ≤)** | Fail to reject H‚ÇÄ when it is false | Missing real sleep deprivation problem | No intervention ‚Üí continued academic underperformance |\n\n### Œ± = 0.05 Justification\n\nSetting Œ± = 0.05 in a university wellness context is a deliberate balance:\n- **Too strict (Œ± = 0.01):** Risk missing real problems (high Œ≤) ‚Äî missed improvement opportunities\n- **Too lenient (Œ± = 0.10):** Risk recommending ineffective programs (high Œ±) ‚Äî wasted resources\n- **Œ± = 0.05:** Standard in social science ‚Äî acceptable balance between budget protection and student welfare\n\n### Power Consideration\n\nWith n ‚âà 1,000, the study has **very high statistical power** (1-Œ≤ > 0.99 for medium effects).\nThis means virtually any practically meaningful difference will be detected."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 8. Hypotheses Summary ‚Äî All Results\n\n> Update this table after running all cells with actual values."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Final Summary Table =====\nsummary_data = {\n    'Hypothesis': ['H1', 'H2', 'H3', 'H4'],\n    'Test': [\n        'One-sample t-test (left)',\n        'Independent t-test (right)',\n        'Proportion z-test (left)',\n        'One-way ANOVA'\n    ],\n    'Statistic': [\n        round(t_stat_h1, 4),\n        round(t_stat_h2, 4),\n        round(z_stat_h3, 4),\n        round(f_stat, 4)\n    ],\n    'p-value': [\n        round(p_h1, 4),\n        round(p_h2, 4),\n        round(p_h3, 4),\n        round(p_h4, 4)\n    ],\n    'Effect Size': [\n        f\"Cohen's d = {cohens_d_h1:.3f}\",\n        f\"Cohen's d = {cohens_d_h2:.3f}\",\n        f\"Cohen's h = {cohens_h:.3f}\",\n        f\"Œ∑¬≤ = {eta_sq:.3f}\"\n    ],\n    'Decision': [\n        'Reject H‚ÇÄ' if p_h1 < alpha else 'Fail to reject H‚ÇÄ',\n        'Reject H‚ÇÄ' if p_h2 < alpha and t_stat_h2 > 0 else 'Fail to reject H‚ÇÄ',\n        'Reject H‚ÇÄ' if p_h3 < alpha else 'Fail to reject H‚ÇÄ',\n        'Reject H‚ÇÄ' if p_h4 < alpha else 'Fail to reject H‚ÇÄ',\n    ]\n}\n\nsummary_df = pd.DataFrame(summary_data)\nprint('=== Final Hypotheses Summary ===')\nprint(summary_df.to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 9. Final Conclusions & Business Recommendations\n\n### For Technical Audience (English)\n\nBased on the statistical analysis of 1,000 university students:\n\n| Finding | Test | p-value | Effect | Recommendation |\n|---------|------|---------|--------|----------------|\n| [H1 result ‚Äî update after running] | One-sample t-test | [value] | [Cohen's d] | [Action] |\n| [H2 result] | Independent t-test | [value] | [Cohen's d] | [Action] |\n| [H3 result] | Proportion z-test | [value] | [Cohen's h] | [Action] |\n| [H4 result] | One-way ANOVA | [value] | [Œ∑¬≤] | [Action] |\n\n**Limitations:**\n- Cross-sectional design ‚Äî cannot establish causality, only association\n- Self-reported data ‚Äî possible social desirability bias\n- Convenience sample ‚Äî may not represent all university populations\n- Geographic context unknown ‚Äî results should be validated locally before policy implementation\n\n---\n\n### Para Audiencia de Negocio (Espa√±ol)\n\n> **Resumen Ejecutivo ‚Äî Departamento de Salud Universitaria**\n\nBasado en el an√°lisis estad√≠stico de 1.000 estudiantes universitarios,\nel estudio identific√≥ los siguientes hallazgos con respaldo estad√≠stico formal:\n\n**Hallazgos principales:**\n- [Actualizar con resultados reales tras ejecutar las celdas]\n\n**Recomendaciones de intervenci√≥n (ordenadas por prioridad):**\n\n| Prioridad | Intervenci√≥n | Impacto esperado | Costo estimado |\n|-----------|-------------|-----------------|----------------|\n| **ALTA** | Programa de higiene del sue√±o | Reducir % estudiantes con < 7h | Bajo |\n| **MEDIA** | Incentivos de actividad f√≠sica | Reducir sedentarismo | Medio |\n| **MEDIA** | Subsidio de alimentaci√≥n saludable | Mejorar calidad nutricional | Medio-Alto |\n\n**Limitaciones del estudio:**\n- Dise√±o transversal ‚Äî no establece causalidad\n- Datos autoreportados ‚Äî posible sesgo de deseabilidad social\n- Muestra de conveniencia ‚Äî validar localmente antes de implementar pol√≠ticas"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 10. Prescriptive Analysis ‚Äî From Findings to Action\n\n### Context ‚Üí Analysis ‚Üí Insight ‚Üí Decision (Possible)\n\nThe following prescriptions are derived from the statistical evidence gathered\nin Lessons 2‚Äì6. Each recommendation is:\n- Grounded in a rejected H‚ÇÄ (statistical evidence)\n- Quantified with estimated business impact\n- Prioritized by effect size and intervention cost\n- Framed as actionable decisions for the Health Director\n\n> **ICI Perspective:** Applying Lean Value Stream Mapping logic:\n> identify the highest-leverage intervention (biggest impact per unit of investment).\n> Sleep and sedentarism are the primary bottlenecks in the student wellness \"production system.\" "
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Prescriptive Analysis ‚Äî Quantified Recommendations =====\n\n# ‚îÄ‚îÄ Base metrics from previous lessons ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nn_total       = len(df)\np_sleep_depr  = (df['sleep_hours'] < 7).mean()\np_sedentary   = (df['exercise_frequency'] < 3).mean()\np_acad_risk   = (df['exam_score'] < 60).mean()\np_risk_given_sleep = ((df['sleep_hours'] < 7) & (df['exam_score'] < 60)).sum() / (df['sleep_hours'] < 7).sum()\np_risk_given_ok    = ((df['sleep_hours'] >= 7) & (df['exam_score'] < 60)).sum() / (df['sleep_hours'] >= 7).sum()\n\nmean_active   = df[df['exercise_frequency'] >= 3]['exam_score'].mean()\nmean_sedent   = df[df['exercise_frequency'] < 3]['exam_score'].mean()\nscore_gap     = mean_active - mean_sedent\n\nprint('=== Base Metrics for Prescriptive Analysis ===')\nprint(f'  Population at risk of sleep deprivation: {p_sleep_depr*100:.1f}%  (n‚âà{int(p_sleep_depr*n_total):,})')\nprint(f'  Population sedentary:                    {p_sedentary*100:.1f}%  (n‚âà{int(p_sedentary*n_total):,})')\nprint(f'  Population at academic risk (score<60):  {p_acad_risk*100:.1f}%  (n‚âà{int(p_acad_risk*n_total):,})')\nprint(f'  P(academic risk | sleep-deprived):       {p_risk_given_sleep*100:.1f}%')\nprint(f'  P(academic risk | adequate sleep):       {p_risk_given_ok*100:.1f}%')\nprint(f'  Lift (sleep deprivation ‚Üí risk):         {p_risk_given_sleep/p_risk_given_ok:.2f}x')\nprint(f'  Exam score gap (active vs sedentary):    {score_gap:+.2f} points')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Prescription 1 ‚Äî Sleep Hygiene Program =====\nprint('=' * 60)\nprint('PRESCRIPTION 1: Sleep Hygiene Program')\nprint('=' * 60)\nprint()\nprint('Evidence base:')\nprint(f'  H1 rejected ‚Üí Œº_sleep < 7h confirmed')\nprint(f'  {p_sleep_depr*100:.1f}% of students sleep-deprived')\nprint(f'  Sleep-deprived students are {p_risk_given_sleep/p_risk_given_ok:.1f}x more likely to be at academic risk')\nprint()\n\n# Target: reduce sleep deprivation from p_sleep_depr to 0.40 (achievable target)\ntarget_sleep_depr = 0.40\nstudents_to_help  = int((p_sleep_depr - target_sleep_depr) * n_total)\nrisk_reduction    = students_to_help * (p_risk_given_sleep - p_risk_given_ok)\n\nprint('Intervention design:')\nprint(f'  Current state:  {p_sleep_depr*100:.1f}% sleep-deprived')\nprint(f'  Target state:   {target_sleep_depr*100:.0f}% sleep-deprived (achievable with behavioral nudges)')\nprint(f'  Students helped: ‚âà{students_to_help:,}')\nprint(f'  Expected reduction in academic risk: ‚âà{risk_reduction:.0f} fewer students at risk')\nprint()\nprint('Intervention options (LEAN ‚Äî low cost, high leverage):')\nprint('  ‚Ä¢ Sleep hygiene workshops (1h/semester) ‚Äî cost: LOW')\nprint('  ‚Ä¢ Late-night library/screen curfew notifications ‚Äî cost: VERY LOW')\nprint('  ‚Ä¢ Residence hall quiet hours enforcement ‚Äî cost: LOW')\nprint('  ‚Ä¢ Wearable pilot program (sleep tracking) ‚Äî cost: MEDIUM')\nprint()\nprint('Priority: HIGH ‚Äî largest at-risk population, low intervention cost')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Prescription 2 ‚Äî Physical Activity Program =====\nprint('=' * 60)\nprint('PRESCRIPTION 2: Physical Activity & Anti-Sedentarism')\nprint('=' * 60)\nprint()\nprint('Evidence base:')\nprint(f'  H2 result ‚Üí active students score {score_gap:+.2f} points higher')\nprint(f'  H3 ‚Üí {p_sedentary*100:.1f}% of students sedentary (> 50% benchmark)')\nprint()\n\n# Target: reduce sedentarism from p_sedentary to 0.40\ntarget_sedent   = 0.40\nstudents_active = int((p_sedentary - target_sedent) * n_total)\nscore_gain_pop  = students_active * score_gap\n\nprint('Intervention design:')\nprint(f'  Current state:  {p_sedentary*100:.1f}% sedentary (<3 days/week)')\nprint(f'  Target state:   {target_sedent*100:.0f}% sedentary')\nprint(f'  Students transitioned to active: ‚âà{students_active:,}')\nprint(f'  Expected aggregate score gain: ‚âà{score_gain_pop:.0f} exam score points across cohort')\nprint(f'  Average score gain per transitioned student: +{score_gap:.2f} points')\nprint()\nprint('Intervention options:')\nprint('  ‚Ä¢ Free gym access during study periods ‚Äî cost: LOW (existing infrastructure)')\nprint('  ‚Ä¢ Academic credit for sports participation ‚Äî cost: LOW')\nprint('  ‚Ä¢ Step-count challenges with academic incentives ‚Äî cost: VERY LOW')\nprint('  ‚Ä¢ Active transport (cycling) infrastructure ‚Äî cost: MEDIUM-HIGH')\nprint()\nprint('Priority: HIGH ‚Äî affects majority of students, measurable academic ROI')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Prescription 3 ‚Äî Nutrition Program =====\nprint('=' * 60)\nprint('PRESCRIPTION 3: Nutrition & Diet Quality')\nprint('=' * 60)\nprint()\n\n# Diet quality means\nfor k in order:\n    print(f'  {k:<8}: mean exam score = {groups_dict[k].mean():.2f}')\n\nbest_group  = max(order, key=lambda k: groups_dict[k].mean())\nworst_group = min(order, key=lambda k: groups_dict[k].mean())\ndiet_gap    = groups_dict[best_group].mean() - groups_dict[worst_group].mean()\n\nprint()\nprint(f'  Score gap ({best_group} vs {worst_group}): {diet_gap:+.2f} points')\nprint()\n\np_poor_diet = (df['diet_quality'] == worst_group).mean() if worst_group in df['diet_quality'].values else 0\nstudents_poor = int(p_poor_diet * n_total)\n\nprint('Evidence base:')\nprint(f'  H4 {\"rejected\" if p_anova < 0.05 else \"not rejected\"} ‚Üí p={p_anova:.4f}')\nprint(f'  Œ∑¬≤ = {eta_sq:.4f} ({interp} effect)')\nprint(f'  {p_poor_diet*100:.1f}% of students have {worst_group} diet quality (n‚âà{students_poor:,})')\nprint()\nprint('Intervention options:')\nprint('  ‚Ä¢ Subsidized healthy meal plan for low-income students ‚Äî cost: MEDIUM')\nprint('  ‚Ä¢ Nutrition workshops integrated into orientation ‚Äî cost: LOW')\nprint('  ‚Ä¢ Cafeteria redesign (healthy defaults) ‚Äî cost: MEDIUM')\nprint('  ‚Ä¢ Fruit/vegetable vending machines ‚Äî cost: LOW')\nprint()\nif eta_sq < 0.06:\n    print('Priority: MEDIUM ‚Äî statistically significant but small effect size')\n    print('          Intervene after sleep and exercise programs (higher ROI)')\nelse:\n    print('Priority: HIGH ‚Äî medium/large effect size supports strong intervention')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Intervention Priority Matrix =====\nprint()\nprint('=' * 60)\nprint('INTERVENTION PRIORITY MATRIX')\nprint('=' * 60)\nprint()\n\npriority_data = {\n    'Intervention': [\n        'Sleep Hygiene Program',\n        'Anti-Sedentarism Campaign',\n        'Nutrition Program'\n    ],\n    'Evidence (H)': ['H1 ‚úÖ', 'H2+H3 ‚úÖ', 'H4 ‚úÖ'],\n    'Population affected': [\n        f'{p_sleep_depr*100:.0f}%',\n        f'{p_sedentary*100:.0f}%',\n        f'{p_poor_diet*100:.0f}%'\n    ],\n    'Effect size': [\n        f\"Cohen's d={cohens_d_h1:.2f}\",\n        f\"Cohen's d={cohens_d_h2:.2f}\",\n        f'Œ∑¬≤={eta_sq:.3f}'\n    ],\n    'Cost': ['Low', 'Low‚ÄìMedium', 'Medium'],\n    'Priority': ['üî¥ HIGH', 'üî¥ HIGH', 'üü° MEDIUM']\n}\n\npriority_df = pd.DataFrame(priority_data)\nprint(priority_df.to_string(index=False))\nprint()\nprint('Recommended implementation order: Sleep ‚Üí Activity ‚Üí Nutrition')\nprint('Rationale (LEAN): Maximum impact per resource unit')\nprint('  Sleep program: cheapest intervention, largest affected population')\nprint('  Activity:      measurable exam score ROI, affects majority')\nprint('  Nutrition:     smaller effect size, higher implementation cost')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ===== Visualization ‚Äî Priority Matrix =====\nfig, axes = plt.subplots(1, 2, figsize=(13, 4))\nfig.suptitle('Prescriptive Analysis ‚Äî Intervention Priority',\n             fontsize=12, fontweight='bold')\n\n# ‚îÄ‚îÄ Bubble chart: Effect size vs Population affected ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ninterventions = ['Sleep\nHygiene', 'Anti-\nSedentarism', 'Nutrition']\npop_affected  = [p_sleep_depr, p_sedentary, p_poor_diet]\neffect_sizes  = [abs(cohens_d_h1), abs(cohens_d_h2), eta_sq * 10]  # scaled for visibility\ncosts         = [1, 2, 3]   # 1=low, 2=medium, 3=high\ncolors_prio   = ['#E53935', '#E53935', '#F59E0B']\nsizes_bubble  = [p * 3000 for p in pop_affected]\n\nfor i, (name, pop, eff, color, sz) in enumerate(\n        zip(interventions, pop_affected, effect_sizes, colors_prio, sizes_bubble)):\n    axes[0].scatter(pop * 100, eff, s=sz, color=color, alpha=0.7, edgecolors='white', lw=2)\n    axes[0].annotate(name, (pop * 100, eff), textcoords=\"offset points\",\n                     xytext=(0, 12), ha='center', fontsize=9, fontweight='bold')\n\naxes[0].set_xlabel('Population Affected (%)')\naxes[0].set_ylabel('Effect Size (standardized)')\naxes[0].set_title('Impact vs Population ‚Äî Bubble = Population Size')\naxes[0].axhline(0.2, color='gray', linestyle='--', alpha=0.5, label='Small effect threshold')\naxes[0].legend(fontsize=8)\n\n# ‚îÄ‚îÄ Bar: Expected students helped ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nstudents_helped = [\n    int((p_sleep_depr - 0.40) * n_total),\n    int((p_sedentary - 0.40) * n_total),\n    int(p_poor_diet * n_total * 0.3)   # 30% improvement assumed\n]\nbars = axes[1].bar(interventions, students_helped,\n                   color=['#E53935', '#E53935', '#F59E0B'], alpha=0.85, edgecolor='white')\nfor bar, val in zip(bars, students_helped):\n    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n                 f'‚âà{val:,}', ha='center', fontsize=10, fontweight='bold')\naxes[1].set_ylabel('Students Benefited (estimated)')\naxes[1].set_title('Estimated Reach per Intervention')\n\nplt.tight_layout()\noutput_path = REPORTS_FIGURES / 'lesson6_prescriptions.png'\nplt.savefig(output_path, dpi=150, bbox_inches='tight')\nplt.show()\nprint(f'Figure saved: {output_path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 11. Deliverables Checklist\n\n| Deliverable | Audience | Format | Status |\n|-------------|----------|--------|--------|\n| 01_business_understanding.ipynb | Data team | Jupyter (EN) | ‚úÖ |\n| 02_data_understanding.ipynb | Data team | Jupyter (EN) | ‚úÖ |\n| 03_data_preparation.ipynb | Data team | Jupyter (EN) | ‚úÖ |\n| 04_modeling.ipynb | Data team | Jupyter (EN) | ‚úÖ |\n| 05_evaluation.ipynb | Data team | Jupyter (EN) | ‚úÖ |\n| 06_deployment.ipynb | Data team | Jupyter (EN) | ‚úÖ |\n| Figures (reports/figures/) | All | PNG | ‚úÖ |\n| Executive Summary | Health Director | PDF/PPTX (ES) | ‚è≥ |\n| GitHub Repository | Public / Portfolio | Git | ‚è≥ |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 12. LEAN Retrospective\n\n| LEAN Question | Answer |\n|---------------|--------|\n| Did every analysis step add value? | ‚úÖ Each notebook maps to a specific lesson objective |\n| Was there analytical waste? | ‚ö†Ô∏è Distribution fitting for non-hypothesis variables was avoided |\n| Did results translate to business decisions? | ‚úÖ Each rejected H‚ÇÄ maps to a specific intervention |\n| Was the dual-format delivery achieved? | ‚è≥ Executive summary pending |\n| What would I do differently? | Add power analysis in Lesson 1 to justify sample size requirements |\n\n### Lean Waste Identified\n\n| Waste Type | Instance | Resolution |\n|------------|---------|------------|\n| Over-processing | Fitting distributions for all 20 variables | Reduced to 4 hypothesis-relevant variables |\n| Waiting | Dataset download not automated | kagglehub solution implemented |\n| Defects | f-string syntax errors in notebooks | Fixed with variable intermediate pattern |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 13. Decisions Log ‚Äî Lesson 6\n\n| # | Decision | Rationale | Alternatives | LEAN Value? |\n|---|----------|-----------|--------------|-------------|\n| 1 | One-tailed tests for H1, H2, H3 | Direction specified in hypotheses from Lesson 1 | Two-tailed | ‚úÖ More powerful, appropriate |\n| 2 | Welch t-test for H2 | Does not assume equal variances | Student t-test | ‚úÖ More robust |\n| 3 | ANOVA for H4 (not multiple t-tests) | Multiple t-tests inflate Type I error | 3 separate t-tests | ‚úÖ Methodologically correct |\n| 4 | Bonferroni correction for post-hoc | Controls familywise error rate | Tukey HSD | ‚úÖ Conservative but valid |\n| 5 | Report Cohen's d and Œ∑¬≤ alongside p-value | p-value alone insufficient for business decisions | p-value only | ‚úÖ Portfolio standard |\n\n---\n\n**‚Üê Previous Phase:** [05 ‚Äî Evaluation](./05_evaluation.ipynb)\n\n---\n\n*End of Lesson 6 ‚Äî Project 4, Module 5 ‚Äî COMPLETE*\n*Author: Jose Marcel Lopez Pino | Framework: CRISP-DM + LEAN | Bootcamp: Alkemy / SENCE 2025‚Äì2026*"
  }
 ]
}